{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imodels.util import data_util\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []\n",
    "metadata_columns = ['Name', 'Patients', 'Outcome', '% Outcome', 'Features']\n",
    "feature_data = []\n",
    "featuredata_columns = ['Feature Name', '% Missing or N/A', '% Nonzero']#, 'Imputation']\n",
    "for dset_name in ['tbi', 'iai', 'csi']:\n",
    "    X, y, feat_names = data_util.get_clean_dataset(f'{dset_name}_pecarn_pred.csv', data_source='imodels')\n",
    "    X_df = pd.DataFrame(X, columns=feat_names)\n",
    "\n",
    "    X_prop, y_prop, feature_names_prop = data_util.get_clean_dataset(f'{dset_name}_pecarn_prop.csv', data_source='imodels')\n",
    "    X_df_prop = pd.DataFrame(X_prop, columns=feature_names_prop)\n",
    "\n",
    "    if dset_name == 'tbi':\n",
    "        X_df_clean = X_df.drop(columns=['AgeinYears', 'AgeTwoPlus'])\n",
    "    elif dset_name == 'iai':\n",
    "        X_df_clean = X_df.drop(columns=['Age<2_no', 'Age<2_yes'])\n",
    "    else:\n",
    "        X_df_clean = X_df\n",
    "    \n",
    "    shape = X.shape\n",
    "    class_counts = np.unique(y, return_counts=True)[1]\n",
    "    unique_feats = np.unique(['_'.join(name.split('_')[:-1]) if len(name.split('_')) > 1 else name \n",
    "        for name in X_df_clean.columns])\n",
    "\n",
    "    metadata.append([dset_name.capitalize(), shape[0], class_counts[1], \n",
    "        np.round(class_counts[1] * 100 / np.sum(class_counts), decimals=1), unique_feats.shape[0]])\n",
    "    \n",
    "    for feat in unique_feats:\n",
    "        missing = 0\n",
    "        # Values that represent missing or not applicable \n",
    "        for suffix in ['nan', '91.0', '92', '92.0', 'unknown']:\n",
    "            if f'{feat}_{suffix}' in X_df_prop.columns:\n",
    "                missing += X_df_prop[f'{feat}_{suffix}'].value_counts()[1.0] * 100 / X_df.shape[0]\n",
    "        missing = np.round(missing, decimals=2)\n",
    "\n",
    "        \n",
    "        nonzero = 0\n",
    "        for suffix in ['yes', '1.0', 'Yes']:\n",
    "            if f'{feat}_{suffix}' in X_df.columns:\n",
    "                nonzero += X_df[f'{feat}_{suffix}'].value_counts()[1.0] * 100 / X_df.shape[0]\n",
    "        if feat in X_df.columns and X_df[feat].unique().shape[0] < 3:\n",
    "            nonzero += X_df[feat].value_counts()[1.0] * 100 / X_df.shape[0]\n",
    "        \n",
    "        if nonzero != 0:\n",
    "            nonzero = np.round(nonzero, decimals=2)\n",
    "        else:\n",
    "            nonzero = 'N/A'\n",
    "\n",
    "        feature_data.append([feat, missing, nonzero])\n",
    "\n",
    "\n",
    "metadata = pd.DataFrame(metadata, columns=metadata_columns)#.sort_values(by=['Patients'])  #.set_index('Name')\n",
    "feature_data = pd.DataFrame(feature_data, columns=featuredata_columns)#.sort_values(by=['Patients'])  #.set_index('Name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrr}\n",
      "\\toprule\n",
      "Name &  Patients &  Outcome &  \\% Outcome &  Features \\\\\n",
      "\\midrule\n",
      " Tbi &     42428 &      376 &        0.9 &        61 \\\\\n",
      " Iai &     12044 &      203 &        1.7 &        21 \\\\\n",
      " Csi &      3313 &      540 &       16.3 &        35 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metadata.to_latex(index=False, escape=False).replace('%', '\\%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd_left = feature_data[:61].reset_index()\n",
    "fd_right = feature_data[62:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{rlrl}\n",
      "\\toprule\n",
      " index &       Feature Name &  % Missing or N/A & % Nonzero \\\\\n",
      "\\midrule\n",
      "     0 &                AMS &              0.74 &     12.95 \\\\\n",
      "     1 &        AMSAgitated &             87.05 &      1.79 \\\\\n",
      "     2 &             AMSOth &             87.05 &      1.82 \\\\\n",
      "     3 &          AMSRepeat &             87.05 &      1.04 \\\\\n",
      "     4 &           AMSSleep &             87.05 &      6.67 \\\\\n",
      "     5 &            AMSSlow &             87.05 &      3.22 \\\\\n",
      "     6 &            ActNorm &              7.09 &     85.38 \\\\\n",
      "     7 &         AgeInMonth &              0.00 &       N/A \\\\\n",
      "     8 &       Amnesia_verb &             38.41 &     10.45 \\\\\n",
      "     9 &               Clav &              0.30 &     64.38 \\\\\n",
      "    10 &           ClavFace &             35.92 &     29.99 \\\\\n",
      "    11 &            ClavFro &             35.92 &     20.48 \\\\\n",
      "    12 &           ClavNeck &             35.92 &      1.38 \\\\\n",
      "    13 &            ClavOcc &             35.92 &      9.62 \\\\\n",
      "    14 &            ClavPar &             35.92 &      7.79 \\\\\n",
      "    15 &            ClavTem &             35.92 &      3.39 \\\\\n",
      "    16 &              Drugs &              4.19 &      0.87 \\\\\n",
      "    17 &           FontBulg &              0.37 &      0.06 \\\\\n",
      "    18 &             Gender &              0.01 &       N/A \\\\\n",
      "    19 &         HASeverity &              2.38 &       N/A \\\\\n",
      "    20 &            HAStart &              3.09 &       N/A \\\\\n",
      "    21 &            HA_verb &             32.76 &     29.94 \\\\\n",
      "    22 &               Hema &              0.69 &     39.42 \\\\\n",
      "    23 &            HemaLoc &              0.47 &       N/A \\\\\n",
      "    24 &           HemaSize &              1.67 &       N/A \\\\\n",
      "    25 & High_impact_InjSev &              0.74 &       N/A \\\\\n",
      "    26 &         InjuryMech &              0.67 &       N/A \\\\\n",
      "    27 &          Intubated &              0.73 &      0.01 \\\\\n",
      "    28 &        LOCSeparate &              4.05 &     10.37 \\\\\n",
      "    29 &             LocLen &              5.39 &       N/A \\\\\n",
      "    30 &             NeuroD &              0.85 &       1.3 \\\\\n",
      "    31 &      NeuroDCranial &             98.70 &      0.18 \\\\\n",
      "    32 &        NeuroDMotor &             98.70 &      0.28 \\\\\n",
      "    33 &          NeuroDOth &             98.70 &      0.71 \\\\\n",
      "    34 &       NeuroDReflex &             98.70 &      0.03 \\\\\n",
      "    35 &      NeuroDSensory &             98.70 &      0.26 \\\\\n",
      "    36 &                OSI &              0.43 &     10.07 \\\\\n",
      "    37 &         OSIAbdomen &             89.93 &      1.25 \\\\\n",
      "    38 &          OSICspine &             89.93 &      1.37 \\\\\n",
      "    39 &             OSICut &             89.93 &      0.12 \\\\\n",
      "    40 &       OSIExtremity &             89.93 &      5.49 \\\\\n",
      "    41 &           OSIFlank &             89.93 &      1.56 \\\\\n",
      "    42 &             OSIOth &             89.93 &      1.65 \\\\\n",
      "    43 &          OSIPelvis &             89.93 &      0.44 \\\\\n",
      "    44 &          Paralyzed &              0.75 &      0.01 \\\\\n",
      "    45 &             SFxBas &              0.99 &      0.68 \\\\\n",
      "    46 &          SFxBasHem &             99.32 &      0.35 \\\\\n",
      "    47 &          SFxBasOto &             99.32 &      0.04 \\\\\n",
      "    48 &          SFxBasPer &             99.32 &      0.19 \\\\\n",
      "    49 &          SFxBasRet &             99.32 &      0.08 \\\\\n",
      "    50 &          SFxBasRhi &             99.32 &      0.03 \\\\\n",
      "    51 &            SFxPalp &              0.24 &      0.38 \\\\\n",
      "    52 &     SFxPalpDepress &             99.69 &      0.18 \\\\\n",
      "    53 &            Sedated &              0.76 &      0.08 \\\\\n",
      "    54 &               Seiz &              1.70 &      1.17 \\\\\n",
      "    55 &            SeizLen &              0.18 &       N/A \\\\\n",
      "    56 &          SeizOccur &              0.12 &       N/A \\\\\n",
      "    57 &              Vomit &              0.71 &      13.1 \\\\\n",
      "    58 &          VomitLast &             89.04 &       N/A \\\\\n",
      "    59 &           VomitNbr &              0.60 &       N/A \\\\\n",
      "    60 &         VomitStart &              0.87 &       N/A \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(fd_left.to_latex(index=False, escape=False))#.replace('%', '\\%'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y, feature_names = data_util.get_clean_dataset(f'tbi_pecarn_pred.csv', data_source='imodels')\n",
    "# X_df = pd.DataFrame(X, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_prop, y_prop, feature_names_prop = data_util.get_clean_dataset(f'tbi_pecarn_prop.csv', data_source='imodels')\n",
    "# X_df_prop = pd.DataFrame(X_prop, columns=feature_names_prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df_prop.columns.tolist()\n",
    "# # X_df_prop.columns.tolist()\n",
    "# # (X_df['subinj_Head2'] + X_df['subinj_Face2']).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in [ X_df_prop[col].value_counts()[1.0] for col in X_df.columns if 'OSI' in col]:\n",
    "#     X_df_prop[col].value_counts()[1.0]\n",
    "# (X_df[[col for col in X_df.columns if 'OSI' in col]].sum(axis=1) > 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [col for col in X_df.columns if 'OSI' in col][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df['OSI'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [col for col in X_df_prop.columns if 'Amnesia' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique_feats = np.unique([''.join(name.split('_')[:-1]) if len(name.split('_')) > 1 and 'subinj' not in name else name for name in X_df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feat in unique_feats:\n",
    "#     if f'{feat}_nan' in X_df_prop.columns:\n",
    "#         print(f'{feat}_nan', X_df_prop[f'{feat}_nan'].value_counts()[1.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df_prop['Vomit_nan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d833dc0779f0f050568351c83cfa2f037bffe4d045df2adc54e8a65e73ce0016"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
