{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'imodels.importance'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mensemble\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestRegressor, RandomForestClassifier\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m r2_score, mean_absolute_error, accuracy_score, roc_auc_score, mean_squared_error\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimportance\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomForestPlusRegressor, RandomForestPlusClassifier, \\\n\u001b[1;32m     33\u001b[0m     RidgeRegressorPPM, LassoRegressorPPM, IdentityTransformer\n\u001b[1;32m     34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimodels\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mimportance\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mrf_plus\u001b[39;00m \u001b[39mimport\u001b[39;00m _fast_r2_score\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'imodels.importance'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import glob\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import time\n",
    "import warnings\n",
    "from scipy import stats\n",
    "import dask\n",
    "from dask.distributed import Client\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from typing import Callable, List, Tuple\n",
    "import itertools\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, mean_squared_error\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../../imodels/\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Bins whose width\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, accuracy_score, roc_auc_score, mean_squared_error\n",
    "\n",
    "from imodels.importance import RandomForestPlusRegressor, RandomForestPlusClassifier, \\\n",
    "    RidgeRegressorPPM, LassoRegressorPPM, IdentityTransformer\n",
    "from imodels.importance.rf_plus import _fast_r2_score\n",
    "import seaborn as sns\n",
    "from util import ModelConfig, FIModelConfig, tp, fp, neg, pos, specificity_score, auroc_score, auprc_score, compute_nsg_feat_corr_w_sig_subspace, apply_splitting_strategy\n",
    "from scripts.competing_methods_local import *\n",
    "from scripts.simulations_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_shuffle(data, seed):\n",
    "    \"\"\"\n",
    "    Randomly shuffle each column of the data.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    return np.array([np.random.permutation(data[:, i]) for i in range(data.shape[1])]).T\n",
    "\n",
    "\n",
    "def ablation(data, feature_importance, mode, num_features, seed):\n",
    "    \"\"\"\n",
    "    Replace the top num_features max feature importance data with random shuffle for each sample\n",
    "    \"\"\"\n",
    "    assert mode in [\"max\", \"min\"]\n",
    "    fi = feature_importance.to_numpy()\n",
    "    shuffle = generate_random_shuffle(data.copy(), seed)\n",
    "    if mode == \"max\":\n",
    "        indices = np.argsort(-fi)\n",
    "    else:\n",
    "        indices = np.argsort(fi)\n",
    "    data_copy = data.copy()\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(num_features):\n",
    "            data_copy[i, indices[i,j]] = shuffle[i, indices[i,j]]\n",
    "    return data_copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo of Getting LFI on synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "n = 200\n",
    "d = 10\n",
    "mean = [[0]*5 + [0]*5, [10]*5 + [0]*5]\n",
    "scale = [[1]*10,[1]*10]\n",
    "s = 5\n",
    "X = sample_normal_X_subgroups(n, d, mean, scale)\n",
    "beta = np.concatenate((np.ones(s), np.zeros(d-s)))\n",
    "y = np.matmul(X, beta)\n",
    "split_seed = 0\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.802318</td>\n",
       "      <td>-4.855034</td>\n",
       "      <td>-6.534856</td>\n",
       "      <td>-6.303020</td>\n",
       "      <td>-5.666409</td>\n",
       "      <td>0.003367</td>\n",
       "      <td>-0.115584</td>\n",
       "      <td>-0.005208</td>\n",
       "      <td>-0.054205</td>\n",
       "      <td>-0.105709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.235663</td>\n",
       "      <td>4.058804</td>\n",
       "      <td>7.247494</td>\n",
       "      <td>4.568692</td>\n",
       "      <td>3.723577</td>\n",
       "      <td>0.240077</td>\n",
       "      <td>-0.173623</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>-0.103587</td>\n",
       "      <td>-0.024177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.427314</td>\n",
       "      <td>4.358826</td>\n",
       "      <td>7.265487</td>\n",
       "      <td>4.922750</td>\n",
       "      <td>4.078967</td>\n",
       "      <td>0.022970</td>\n",
       "      <td>-0.032465</td>\n",
       "      <td>-0.048909</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>-0.033833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-6.390700</td>\n",
       "      <td>-4.386212</td>\n",
       "      <td>-8.782353</td>\n",
       "      <td>-2.667173</td>\n",
       "      <td>-2.487387</td>\n",
       "      <td>-0.038786</td>\n",
       "      <td>-0.009141</td>\n",
       "      <td>-0.010059</td>\n",
       "      <td>0.058067</td>\n",
       "      <td>-0.004545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.855409</td>\n",
       "      <td>4.314597</td>\n",
       "      <td>7.098136</td>\n",
       "      <td>4.671592</td>\n",
       "      <td>3.572662</td>\n",
       "      <td>-0.121405</td>\n",
       "      <td>0.386412</td>\n",
       "      <td>-0.018923</td>\n",
       "      <td>-0.095826</td>\n",
       "      <td>-0.019706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-4.678110</td>\n",
       "      <td>-4.993524</td>\n",
       "      <td>-7.039339</td>\n",
       "      <td>-6.902901</td>\n",
       "      <td>-1.957546</td>\n",
       "      <td>0.027181</td>\n",
       "      <td>-0.043465</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>0.014384</td>\n",
       "      <td>0.062693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4.235663</td>\n",
       "      <td>4.058804</td>\n",
       "      <td>7.085392</td>\n",
       "      <td>4.551293</td>\n",
       "      <td>4.100747</td>\n",
       "      <td>-0.109350</td>\n",
       "      <td>0.015101</td>\n",
       "      <td>0.056478</td>\n",
       "      <td>-0.103587</td>\n",
       "      <td>-0.087515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-2.773373</td>\n",
       "      <td>-5.546139</td>\n",
       "      <td>-5.455163</td>\n",
       "      <td>-6.975617</td>\n",
       "      <td>-5.273687</td>\n",
       "      <td>0.089041</td>\n",
       "      <td>-0.023757</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>0.095483</td>\n",
       "      <td>-0.144661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3.250866</td>\n",
       "      <td>4.433513</td>\n",
       "      <td>7.279385</td>\n",
       "      <td>4.623573</td>\n",
       "      <td>4.017007</td>\n",
       "      <td>-0.134517</td>\n",
       "      <td>0.015101</td>\n",
       "      <td>-0.021426</td>\n",
       "      <td>0.024746</td>\n",
       "      <td>0.013218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-4.702458</td>\n",
       "      <td>-5.727406</td>\n",
       "      <td>-7.211222</td>\n",
       "      <td>-5.302868</td>\n",
       "      <td>-1.991175</td>\n",
       "      <td>0.117658</td>\n",
       "      <td>0.021233</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>-0.103969</td>\n",
       "      <td>-0.031982</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -2.802318 -4.855034 -6.534856 -6.303020 -5.666409  0.003367 -0.115584   \n",
       "1   4.235663  4.058804  7.247494  4.568692  3.723577  0.240077 -0.173623   \n",
       "2   3.427314  4.358826  7.265487  4.922750  4.078967  0.022970 -0.032465   \n",
       "3  -6.390700 -4.386212 -8.782353 -2.667173 -2.487387 -0.038786 -0.009141   \n",
       "4   3.855409  4.314597  7.098136  4.671592  3.572662 -0.121405  0.386412   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "61 -4.678110 -4.993524 -7.039339 -6.902901 -1.957546  0.027181 -0.043465   \n",
       "62  4.235663  4.058804  7.085392  4.551293  4.100747 -0.109350  0.015101   \n",
       "63 -2.773373 -5.546139 -5.455163 -6.975617 -5.273687  0.089041 -0.023757   \n",
       "64  3.250866  4.433513  7.279385  4.623573  4.017007 -0.134517  0.015101   \n",
       "65 -4.702458 -5.727406 -7.211222 -5.302868 -1.991175  0.117658  0.021233   \n",
       "\n",
       "           7         8         9  \n",
       "0  -0.005208 -0.054205 -0.105709  \n",
       "1   0.056478 -0.103587 -0.024177  \n",
       "2  -0.048909  0.003921 -0.033833  \n",
       "3  -0.010059  0.058067 -0.004545  \n",
       "4  -0.018923 -0.095826 -0.019706  \n",
       "..       ...       ...       ...  \n",
       "61  0.000381  0.014384  0.062693  \n",
       "62  0.056478 -0.103587 -0.087515  \n",
       "63 -0.001291  0.095483 -0.144661  \n",
       "64 -0.021426  0.024746  0.013218  \n",
       "65  0.002649 -0.103969 -0.031982  \n",
       "\n",
       "[66 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=331)\n",
    "rf_plus_model = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf_regressor), include_raw=False)\n",
    "rf_plus_model.fit(X_train, y_train)\n",
    "score = rf_plus_model.get_mdi_plus_scores(X_test, y_test, lfi=True, lfi_abs = \"none\", sample_split=None, train_or_test = \"test\")\n",
    "score[\"lfi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.666780</td>\n",
       "      <td>-4.573905</td>\n",
       "      <td>-6.975479</td>\n",
       "      <td>-6.084630</td>\n",
       "      <td>-6.224678</td>\n",
       "      <td>0.006328</td>\n",
       "      <td>-0.035066</td>\n",
       "      <td>0.005080</td>\n",
       "      <td>-0.014931</td>\n",
       "      <td>-0.016010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.237603</td>\n",
       "      <td>3.885691</td>\n",
       "      <td>6.807192</td>\n",
       "      <td>4.577892</td>\n",
       "      <td>6.923594</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>-0.011022</td>\n",
       "      <td>-0.013137</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>-0.007547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.138463</td>\n",
       "      <td>5.116393</td>\n",
       "      <td>7.990031</td>\n",
       "      <td>4.345799</td>\n",
       "      <td>3.765652</td>\n",
       "      <td>0.011890</td>\n",
       "      <td>0.007317</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.018744</td>\n",
       "      <td>-0.016710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.701403</td>\n",
       "      <td>-4.654211</td>\n",
       "      <td>-7.689046</td>\n",
       "      <td>-3.572961</td>\n",
       "      <td>-5.217060</td>\n",
       "      <td>-0.022063</td>\n",
       "      <td>0.010813</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>-0.010876</td>\n",
       "      <td>-0.019078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.779464</td>\n",
       "      <td>4.193490</td>\n",
       "      <td>6.045288</td>\n",
       "      <td>5.470785</td>\n",
       "      <td>4.547649</td>\n",
       "      <td>-0.018626</td>\n",
       "      <td>0.028545</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>0.019167</td>\n",
       "      <td>-0.007963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-3.969411</td>\n",
       "      <td>-6.326621</td>\n",
       "      <td>-6.232090</td>\n",
       "      <td>-6.912097</td>\n",
       "      <td>-4.267484</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>0.001136</td>\n",
       "      <td>0.010596</td>\n",
       "      <td>-0.010539</td>\n",
       "      <td>-0.010633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>4.086002</td>\n",
       "      <td>3.851585</td>\n",
       "      <td>6.274630</td>\n",
       "      <td>3.956496</td>\n",
       "      <td>6.276763</td>\n",
       "      <td>-0.008485</td>\n",
       "      <td>-0.008097</td>\n",
       "      <td>-0.017143</td>\n",
       "      <td>0.022414</td>\n",
       "      <td>-0.011498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>-3.666791</td>\n",
       "      <td>-5.238759</td>\n",
       "      <td>-5.150104</td>\n",
       "      <td>-6.139017</td>\n",
       "      <td>-5.913825</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>-0.015721</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.003138</td>\n",
       "      <td>0.013493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>3.123538</td>\n",
       "      <td>3.543525</td>\n",
       "      <td>6.164842</td>\n",
       "      <td>3.341763</td>\n",
       "      <td>6.544530</td>\n",
       "      <td>0.036032</td>\n",
       "      <td>-0.009216</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>-0.006303</td>\n",
       "      <td>-0.014579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-3.809364</td>\n",
       "      <td>-5.763980</td>\n",
       "      <td>-6.015097</td>\n",
       "      <td>-5.307659</td>\n",
       "      <td>-4.176998</td>\n",
       "      <td>0.032404</td>\n",
       "      <td>-0.000510</td>\n",
       "      <td>0.004747</td>\n",
       "      <td>-0.006950</td>\n",
       "      <td>0.016796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6  \\\n",
       "0  -3.666780 -4.573905 -6.975479 -6.084630 -6.224678  0.006328 -0.035066   \n",
       "1   3.237603  3.885691  6.807192  4.577892  6.923594  0.014024 -0.011022   \n",
       "2   4.138463  5.116393  7.990031  4.345799  3.765652  0.011890  0.007317   \n",
       "3  -4.701403 -4.654211 -7.689046 -3.572961 -5.217060 -0.022063  0.010813   \n",
       "4   3.779464  4.193490  6.045288  5.470785  4.547649 -0.018626  0.028545   \n",
       "..       ...       ...       ...       ...       ...       ...       ...   \n",
       "61 -3.969411 -6.326621 -6.232090 -6.912097 -4.267484  0.026549  0.001136   \n",
       "62  4.086002  3.851585  6.274630  3.956496  6.276763 -0.008485 -0.008097   \n",
       "63 -3.666791 -5.238759 -5.150104 -6.139017 -5.913825  0.024400 -0.015721   \n",
       "64  3.123538  3.543525  6.164842  3.341763  6.544530  0.036032 -0.009216   \n",
       "65 -3.809364 -5.763980 -6.015097 -5.307659 -4.176998  0.032404 -0.000510   \n",
       "\n",
       "           7         8         9  \n",
       "0   0.005080 -0.014931 -0.016010  \n",
       "1  -0.013137  0.013587 -0.007547  \n",
       "2   0.003906  0.018744 -0.016710  \n",
       "3   0.006639 -0.010876 -0.019078  \n",
       "4   0.010906  0.019167 -0.007963  \n",
       "..       ...       ...       ...  \n",
       "61  0.010596 -0.010539 -0.010633  \n",
       "62 -0.017143  0.022414 -0.011498  \n",
       "63  0.013183  0.003138  0.013493  \n",
       "64  0.000239 -0.006303 -0.014579  \n",
       "65  0.004747 -0.006950  0.016796  \n",
       "\n",
       "[66 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=331)\n",
    "rf_plus_model = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf_regressor), include_raw=True)\n",
    "rf_plus_model.fit(X_train, y_train)\n",
    "score = rf_plus_model.get_mdi_plus_scores(X_test, y_test, lfi=True, lfi_abs = \"none\", sample_split=None, train_or_test = \"test\")\n",
    "score[\"lfi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo of Getting LFI on real dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X= sample_real_data(X_fpath=\"../data/classification_data/Diabetes/X_diabetes.csv\", return_data=\"X\")\n",
    "y,_,_ = sample_real_data(y_fpath=\"../data/classification_data/Diabetes/y_diabetes.csv\", return_data=\"y\")\n",
    "split_seed = 0\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", split_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features='sqrt', random_state=42)\n",
    "rf_plus_model = RandomForestPlusClassifier(rf_model=copy.deepcopy(rf_regressor), include_raw=False)\n",
    "rf_plus_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(514, 8) (254, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df3ba7a4c24146118a70a5b84aaad804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/254 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Must pass 2-d input. shape=(2, 254, 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m kernel_shap_test_evaluation_RF_plus(X_train, y_train, X_test, y_test, rf_plus_model)\n",
      "File \u001b[1;32md:\\local_MDI+\\imodels-experiments\\feature_importance\\scripts\\competing_methods_local.py:341\u001b[0m, in \u001b[0;36mkernel_shap_test_evaluation_RF_plus\u001b[1;34m(X_train, y_train, X_test, y_test, fit)\u001b[0m\n\u001b[0;32m    339\u001b[0m kernel_shap_scores \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(kernel_shap_scores)\n\u001b[0;32m    340\u001b[0m \u001b[39m# print(kernel_shap_scores.shape)\u001b[39;00m\n\u001b[1;32m--> 341\u001b[0m result_table \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mDataFrame(kernel_shap_scores, columns\u001b[39m=\u001b[39;49m[\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mFeature_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(num_features)])\n\u001b[0;32m    343\u001b[0m \u001b[39mreturn\u001b[39;00m result_table\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\frame.py:722\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    712\u001b[0m         mgr \u001b[39m=\u001b[39m dict_to_mgr(\n\u001b[0;32m    713\u001b[0m             \u001b[39m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[0;32m    714\u001b[0m             \u001b[39m# attribute \"name\"\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    719\u001b[0m             typ\u001b[39m=\u001b[39mmanager,\n\u001b[0;32m    720\u001b[0m         )\n\u001b[0;32m    721\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 722\u001b[0m         mgr \u001b[39m=\u001b[39m ndarray_to_mgr(\n\u001b[0;32m    723\u001b[0m             data,\n\u001b[0;32m    724\u001b[0m             index,\n\u001b[0;32m    725\u001b[0m             columns,\n\u001b[0;32m    726\u001b[0m             dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[0;32m    727\u001b[0m             copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[0;32m    728\u001b[0m             typ\u001b[39m=\u001b[39;49mmanager,\n\u001b[0;32m    729\u001b[0m         )\n\u001b[0;32m    731\u001b[0m \u001b[39m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[0;32m    732\u001b[0m \u001b[39melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:329\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[1;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[0;32m    324\u001b[0m         values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    327\u001b[0m     \u001b[39m# by definition an array here\u001b[39;00m\n\u001b[0;32m    328\u001b[0m     \u001b[39m# the dtypes will be coerced to a single dtype\u001b[39;00m\n\u001b[1;32m--> 329\u001b[0m     values \u001b[39m=\u001b[39m _prep_ndarraylike(values, copy\u001b[39m=\u001b[39;49mcopy_on_sanitize)\n\u001b[0;32m    331\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_dtype_equal(values\u001b[39m.\u001b[39mdtype, dtype):\n\u001b[0;32m    332\u001b[0m     \u001b[39m# GH#40110 see similar check inside sanitize_array\u001b[39;00m\n\u001b[0;32m    333\u001b[0m     rcf \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m (is_integer_dtype(dtype) \u001b[39mand\u001b[39;00m values\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Anaconda\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:583\u001b[0m, in \u001b[0;36m_prep_ndarraylike\u001b[1;34m(values, copy)\u001b[0m\n\u001b[0;32m    581\u001b[0m     values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((values\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m1\u001b[39m))\n\u001b[0;32m    582\u001b[0m \u001b[39melif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m--> 583\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMust pass 2-d input. shape=\u001b[39m\u001b[39m{\u001b[39;00mvalues\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    585\u001b[0m \u001b[39mreturn\u001b[39;00m values\n",
      "\u001b[1;31mValueError\u001b[0m: Must pass 2-d input. shape=(2, 254, 8)"
     ]
    }
   ],
   "source": [
    "kernel_shap_test_evaluation_RF_plus(X_train, y_train, X_test, y_test, rf_plus_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n",
      "The `ipykernel.comm.Comm` class has been deprecated. Please use the `comm` module instead.For creating comms, use the function `from comm import create_comm`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c85df56c9874af7b06479c98228ed65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kernel_shap_scores = rf_plus_model.get_kernel_shap_scores(X_train, X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if two arrays are the same kernel_shap_scores[0], -1*kernel_shap_scores[1]\n",
    "assert np.allclose(kernel_shap_scores[0], -1*kernel_shap_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10403001, 0.89596999],\n",
       "       [0.28298555, 0.71701445],\n",
       "       [0.22117321, 0.77882679],\n",
       "       [0.41769101, 0.58230899],\n",
       "       [0.81401824, 0.18598176]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_plus_model.predict_proba(X_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00059938, -0.00273772, -0.18238558, -0.20979838,  0.00102012,\n",
       "         0.00128874, -0.00096814, -0.03520979,  0.        , -0.0027872 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_shap_scores[0][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0014229 , -0.02722811, -0.13815625, -0.16263109, -0.00464371,\n",
       "        -0.00148758,  0.00354948,  0.04096752,  0.        ,  0.00128256]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_shap_scores[1][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00127492,  0.03643567,  0.35294341,  0.41919286,  0.00479383,\n",
       "         0.00234458, -0.00275117, -0.00450702,  0.        ,  0.00211675]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kernel_shap_scores[2][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_shap_scores = np.abs(kernel_shap_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=331)\n",
    "rf_plus_model = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf_regressor), include_raw=False)\n",
    "rf_plus_model.fit(X_train, y_train)\n",
    "score = rf_plus_model.get_mdi_plus_scores(X_test, y_test, lfi=True, lfi_abs = \"none\", sample_split=None, train_or_test = \"test\")\n",
    "score[\"lfi\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_regressor = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=331)\n",
    "rf_plus_model = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf_regressor), include_raw=True)\n",
    "rf_plus_model.fit(X_train, y_train)\n",
    "score = rf_plus_model.get_mdi_plus_scores(X_test, y_test, lfi=True, lfi_abs = \"none\", sample_split=None, train_or_test = \"test\")\n",
    "score[\"lfi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo of Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data\n",
    "# X= sample_real_data(X_fpath=\"../data/regression_data/Diabetes_regression/X_diabetes_regression.csv\", return_data=\"X\")\n",
    "# y,_,_ = sample_real_data(y_fpath=\"../data/regression_data/Diabetes_regression/y_diabetes_regression.csv\", return_data=\"y\")\n",
    "X,y = sklearn.datasets.make_classification(n_samples=200, n_features=10, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=1, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=42)\n",
    "split_seed = 0\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", split_seed)\n",
    "\n",
    "#Define the model and fit\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=331)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_LFI = {}\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "metric_results_LFI['MSE_before_ablation'] = mean_squared_error(y_test, y_pred)\n",
    "local_fi_score = LFI_ablation_test_evaluation(X_train, y_train, X_test, y_test, rf_regressor, include_raw=False)\n",
    "ascending = True\n",
    "imp_vals = copy.deepcopy(local_fi_score)\n",
    "imp_vals[imp_vals == float(\"-inf\")] = -sys.maxsize - 1\n",
    "imp_vals[imp_vals == float(\"inf\")] = sys.maxsize - 1\n",
    "for i in range(X_test.shape[1]):\n",
    "    if ascending:\n",
    "        ablation_X_test = ablation(X_test, imp_vals, \"max\", i+1, seed)\n",
    "    else:\n",
    "        ablation_X_test = ablation(X_test, imp_vals, \"min\", i+1, seed)\n",
    "    metric_results_LFI[f'MSE_after_ablation_{i+1}'] = mean_squared_error(y_test, rf_regressor.predict(ablation_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_shap = {}\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "metric_results_shap['MSE_before_ablation'] = mean_squared_error(y_test, y_pred)\n",
    "local_fi_score = tree_shap_local(X_test, y_test, rf_regressor)\n",
    "ascending = True\n",
    "imp_vals = copy.deepcopy(local_fi_score)\n",
    "imp_vals[imp_vals == float(\"-inf\")] = -sys.maxsize - 1\n",
    "imp_vals[imp_vals == float(\"inf\")] = sys.maxsize - 1\n",
    "seed = np.random.randint(0, 100000)\n",
    "for i in range(X_test.shape[1]):\n",
    "    if ascending:\n",
    "        ablation_X_test = ablation(X_test, imp_vals, \"max\", i+1, seed)\n",
    "    else:\n",
    "        ablation_X_test = ablation(X_test, imp_vals, \"min\", i+1, seed)\n",
    "    metric_results_shap[f'MSE_after_ablation_{i+1}'] = mean_squared_error(y_test, rf_regressor.predict(ablation_X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_LFI = [metric_results_LFI['MSE_before_ablation']] + [metric_results_LFI[f'MSE_after_ablation_{i+1}'] for i in range(X_test.shape[1])]\n",
    "mse_SHAP =[metric_results_LFI['MSE_before_ablation']] + [metric_results_shap[f'MSE_after_ablation_{i+1}'] for i in range(X_test.shape[1])]\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(mse_LFI)), mse_LFI, label='LFI')\n",
    "plt.plot(range(len(mse_SHAP)), mse_SHAP, label='SHAP')\n",
    "plt.xlabel('Number of Features Ablated')\n",
    "plt.ylabel('MSE')\n",
    "plt.title('MSE After Ablation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
