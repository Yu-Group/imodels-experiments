{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "import imodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import RandomForestPlusRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, mean_squared_error, r2_score, average_precision_score\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from feature_importance.scripts.simulations_util import *\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from scripts.competing_methods_local import *\n",
    "from rbo_implementation import rbo_dict\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "sys.path.append('.')\n",
    "sys.path.append('./scripts')\n",
    "from competing_methods_local import *\n",
    "from simulations_util import *\n",
    "from imodels.importance import RandomForestPlusRegressor as RandomForestPlusRegressorMDIPlus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V63</th>\n",
       "      <th>V64</th>\n",
       "      <th>V65</th>\n",
       "      <th>V66</th>\n",
       "      <th>V67</th>\n",
       "      <th>V68</th>\n",
       "      <th>V69</th>\n",
       "      <th>V70</th>\n",
       "      <th>V71</th>\n",
       "      <th>V72</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.50000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>10.670000</td>\n",
       "      <td>-1.560000</td>\n",
       "      <td>5795.000000</td>\n",
       "      <td>-12.100000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>10330.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.50000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>8.390000</td>\n",
       "      <td>3.840000</td>\n",
       "      <td>5805.000000</td>\n",
       "      <td>14.050000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>10275.000000</td>\n",
       "      <td>-55.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-15.90000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6.940000</td>\n",
       "      <td>9.800000</td>\n",
       "      <td>5790.000000</td>\n",
       "      <td>17.900000</td>\n",
       "      <td>41.300000</td>\n",
       "      <td>10235.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-16.80000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>8.730000</td>\n",
       "      <td>10.540000</td>\n",
       "      <td>5775.000000</td>\n",
       "      <td>31.150000</td>\n",
       "      <td>51.700000</td>\n",
       "      <td>10195.000000</td>\n",
       "      <td>-40.000000</td>\n",
       "      <td>2.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.51141</td>\n",
       "      <td>0.304716</td>\n",
       "      <td>9.872418</td>\n",
       "      <td>0.830116</td>\n",
       "      <td>5818.821222</td>\n",
       "      <td>10.511051</td>\n",
       "      <td>37.388335</td>\n",
       "      <td>10164.198442</td>\n",
       "      <td>-0.119949</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.40000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>-4.410000</td>\n",
       "      <td>5800.000000</td>\n",
       "      <td>-25.600000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>10295.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>...</td>\n",
       "      <td>-12.00000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>5.950000</td>\n",
       "      <td>-1.140000</td>\n",
       "      <td>5845.000000</td>\n",
       "      <td>-19.400000</td>\n",
       "      <td>19.100000</td>\n",
       "      <td>10310.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.80000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>7.800000</td>\n",
       "      <td>-0.640000</td>\n",
       "      <td>5845.000000</td>\n",
       "      <td>-9.600000</td>\n",
       "      <td>35.200000</td>\n",
       "      <td>10275.000000</td>\n",
       "      <td>-35.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2532</th>\n",
       "      <td>1.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.80000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>7.720000</td>\n",
       "      <td>-0.890000</td>\n",
       "      <td>5845.000000</td>\n",
       "      <td>-19.600000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>10245.000000</td>\n",
       "      <td>-30.000000</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2533</th>\n",
       "      <td>1.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.90000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>13.070000</td>\n",
       "      <td>9.150000</td>\n",
       "      <td>5820.000000</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>39.350000</td>\n",
       "      <td>10220.000000</td>\n",
       "      <td>-25.000000</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2534 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       V1   V2   V3   V4   V5   V6   V7   V8   V9  V10  ...       V63  \\\n",
       "0     0.8  1.8  2.4  2.1  2.0  2.1  1.5  1.7  1.9  2.3  ... -15.50000   \n",
       "1     2.8  3.2  3.3  2.7  3.3  3.2  2.9  2.8  3.1  3.4  ... -14.50000   \n",
       "2     2.9  2.8  2.6  2.1  2.2  2.5  2.5  2.7  2.2  2.5  ... -15.90000   \n",
       "3     4.7  3.8  3.7  3.8  2.9  3.1  2.8  2.5  2.4  3.1  ... -16.80000   \n",
       "4     2.6  2.1  1.6  1.4  0.9  1.5  1.2  1.4  1.3  1.4  ... -10.51141   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...       ...   \n",
       "2529  0.3  0.4  0.5  0.5  0.2  0.3  0.4  0.4  1.3  2.2  ... -12.40000   \n",
       "2530  1.0  1.4  1.1  1.7  1.5  1.7  1.8  1.5  2.1  2.4  ... -12.00000   \n",
       "2531  0.8  0.8  1.2  0.9  0.4  0.6  0.8  1.1  1.5  1.5  ... -11.80000   \n",
       "2532  1.3  0.9  1.5  1.2  1.6  1.8  1.1  1.0  1.9  2.0  ... -10.80000   \n",
       "2533  1.5  1.3  1.8  1.4  1.2  1.7  1.6  1.4  1.6  3.0  ... -11.90000   \n",
       "\n",
       "           V64        V65        V66          V67        V68        V69  \\\n",
       "0     0.150000  10.670000  -1.560000  5795.000000 -12.100000  17.900000   \n",
       "1     0.480000   8.390000   3.840000  5805.000000  14.050000  29.000000   \n",
       "2     0.600000   6.940000   9.800000  5790.000000  17.900000  41.300000   \n",
       "3     0.490000   8.730000  10.540000  5775.000000  31.150000  51.700000   \n",
       "4     0.304716   9.872418   0.830116  5818.821222  10.511051  37.388335   \n",
       "...        ...        ...        ...          ...        ...        ...   \n",
       "2529  0.070000   7.930000  -4.410000  5800.000000 -25.600000  21.800000   \n",
       "2530  0.040000   5.950000  -1.140000  5845.000000 -19.400000  19.100000   \n",
       "2531  0.060000   7.800000  -0.640000  5845.000000  -9.600000  35.200000   \n",
       "2532  0.250000   7.720000  -0.890000  5845.000000 -19.600000  34.200000   \n",
       "2533  0.540000  13.070000   9.150000  5820.000000   1.950000  39.350000   \n",
       "\n",
       "               V70        V71   V72  \n",
       "0     10330.000000 -55.000000  0.00  \n",
       "1     10275.000000 -55.000000  0.00  \n",
       "2     10235.000000 -40.000000  0.00  \n",
       "3     10195.000000 -40.000000  2.08  \n",
       "4     10164.198442  -0.119949  0.58  \n",
       "...            ...        ...   ...  \n",
       "2529  10295.000000  65.000000  0.00  \n",
       "2530  10310.000000  15.000000  0.00  \n",
       "2531  10275.000000 -35.000000  0.00  \n",
       "2532  10245.000000 -30.000000  0.05  \n",
       "2533  10220.000000 -25.000000  0.00  \n",
       "\n",
       "[2534 rows x 47 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_9978.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1059, 72)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_9978 = pd.read_csv(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_361243.csv\")\n",
    "X_9978.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original number of features: 72\n",
      "Reduced number of features: 47\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.95  # Adjust to 0.95 if needed\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = X_9978.corr()\n",
    "\n",
    "# Identify features with high correlation\n",
    "upper_triangle = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))\n",
    "high_correlation_features = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "\n",
    "# Drop highly correlated features\n",
    "X_9978_reduced = X_9978.drop(columns=high_correlation_features)\n",
    "X_9978_reduced.to_csv(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_9978.csv\", index=False)\n",
    "\n",
    "print(f\"Original number of features: {X_9978.shape[1]}\")\n",
    "print(f\"Reduced number of features: {X_9978_reduced.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Find duplicate columns by comparing values\n",
    "duplicate_columns = []\n",
    "columns_checked = set()\n",
    "\n",
    "for col1 in df.columns:\n",
    "    for col2 in df.columns:\n",
    "        if col1 != col2 and col2 not in columns_checked:\n",
    "            if df[col1].equals(df[col2]):\n",
    "                duplicate_columns.append((col1, col2))\n",
    "    columns_checked.add(col1)\n",
    "\n",
    "# Print result\n",
    "if duplicate_columns:\n",
    "    print(\"Columns with identical values:\")\n",
    "    for col1, col2 in duplicate_columns:\n",
    "        print(f\"{col1} and {col2}\")\n",
    "else:\n",
    "    print(\"No columns with identical values found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are identical columns in df\n",
    "df = pd.read_csv(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_361243_original.csv\")\n",
    "\n",
    "# Find duplicate column names\n",
    "duplicate_columns = df.columns[df.columns.duplicated()].tolist()\n",
    "\n",
    "# Print result\n",
    "if duplicate_columns:\n",
    "    print(\"Duplicate columns found:\")\n",
    "    for col in duplicate_columns:\n",
    "        print(col)\n",
    "else:\n",
    "    print(\"No duplicate columns found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def apply_splitting_strategy(X: np.ndarray,\n",
    "                             y: np.ndarray,\n",
    "                             splitting_strategy: str,\n",
    "                             split_seed: str):\n",
    "    if splitting_strategy in {'train-test-lowdata', 'train-tune-test-lowdata'}:\n",
    "        test_size = 0.90  # X.shape[0] - X.shape[0] * 0.1\n",
    "    elif splitting_strategy == \"train-test\":\n",
    "        test_size = 0.33\n",
    "    else:\n",
    "        test_size = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=split_seed)\n",
    "    X_tune = None\n",
    "    y_tune = None\n",
    "\n",
    "    if splitting_strategy in {'train-tune-test', 'train-tune-test-lowdata'}:\n",
    "        X_train, X_tune, y_train, y_tune = model_selection.train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=split_seed)\n",
    "\n",
    "    return X_train, X_tune, X_test, y_train, y_tune, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_real_data_X(source=\"openml\",task_id=43)\n",
    "y_1 = logistic_linear_model_random_feature(beta=1, s=5, frac_label_corruption=0.05, X=X, error_seed=42, feature_seed=1)\n",
    "X_train, X_tune, X_test, y_train_1, y_tune, y_test_1 = apply_splitting_strategy(X, y_1, \"train-test\", 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2 = logistic_linear_model_random_feature(beta=1, s=5, frac_label_corruption=0.25, X=X, error_seed=42, feature_seed=1)\n",
    "X_train, X_tune, X_test, y_train_2, y_tune, y_test_2 = apply_splitting_strategy(X, y_2, \"train-test\", 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(y_train_1 == y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(y_test_1 == y_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_test.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, sample_indices = sample_real_data_X(source=\"openml\", task_id=9978, sample_row_n=2000, seed = 0, return_sample_indices=True)\n",
    "y,_,_ = sample_real_data_y(source=\"openml\", task_id=9978, sample_row_n=2000, sample_indices=sample_indices, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imodels.importance import RandomForestPlusRegressor\n",
    "\n",
    "# rf_plus_model = RandomForestPlusRegressor()\n",
    "# rf_plus_model.fit(X, y)\n",
    "# mdi_plus_scores = rf_plus_model.get_mdi_plus_scores(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def apply_splitting_strategy(X: np.ndarray,\n",
    "                             y: np.ndarray,\n",
    "                             splitting_strategy: str,\n",
    "                             split_seed: str):\n",
    "    if splitting_strategy in {'train-test-lowdata', 'train-tune-test-lowdata'}:\n",
    "        test_size = 0.90  # X.shape[0] - X.shape[0] * 0.1\n",
    "    elif splitting_strategy == \"train-test\":\n",
    "        test_size = 0.33\n",
    "    else:\n",
    "        test_size = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=split_seed)\n",
    "    X_tune = None\n",
    "    y_tune = None\n",
    "\n",
    "    if splitting_strategy in {'train-tune-test', 'train-tune-test-lowdata'}:\n",
    "        X_train, X_tune, y_train, y_tune = model_selection.train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=split_seed)\n",
    "\n",
    "    return X_train, X_tune, X_test, y_train, y_tune, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_unimportant_features(X, sorted_feature, mask, mask_values):\n",
    "    array = copy.deepcopy(X)\n",
    "    num_features = array.shape[1]\n",
    "    num_masked = int(np.ceil(num_features * mask))\n",
    "    \n",
    "    # Select the least important features for each sample\n",
    "    selected_indices = sorted_feature[:, num_masked:]\n",
    "\n",
    "    for row_idx in range(array.shape[0]):\n",
    "        for col_idx in selected_indices[row_idx]:\n",
    "            if isinstance(mask_values[col_idx], (int, float, np.integer, np.floating)):\n",
    "                array[row_idx, col_idx] = mask_values[col_idx]  # Replace with mean\n",
    "            else:\n",
    "                unique_vals = mask_values[col_idx]\n",
    "                array[row_idx, col_idx] = unique_vals[1] if array[row_idx, col_idx] == unique_vals[0] else unique_vals[0]  # Replace with alternative value\n",
    "    \n",
    "    return num_masked, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 0)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_values = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    unique_values = np.unique(X_train[:, i])\n",
    "    if len(unique_values) > 2:\n",
    "        mask_values[i] = np.mean(X_train[:, i])\n",
    "    else:\n",
    "        mask_values[i] = list(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features=\"sqrt\", random_state=0)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_elastic = RandomForestPlusClassifier(rf_model=est, prediction_model=LogisticRegressionCV(penalty='elasticnet', l1_ratios=[0.1,0.5,0.99], solver = 'saga', cv=3, n_jobs=-1, tol=5e-4, max_iter=2000, random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=1)\n",
    "# est.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "# rf_plus_elastic.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_inbag = RandomForestPlusRegressor(rf_model=est, include_raw=False, fit_on=\"inbag\", prediction_model=LinearRegression())\n",
    "# rf_plus_inbag.fit(X_train, y_train, n_jobs=None)\n",
    "\n",
    "# rf_plus_mdi_plus = RandomForestPlusRegressorMDIPlus(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "# rf_plus_mdi_plus.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_lmdi, _ = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic, mode=\"absolute\")\n",
    "local_fi_score_train_shap, _ = tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=est, mode=\"absolute\")\n",
    "# local_fi_score_train_mdi_plus, _ = mdi_plus_evaluation_RF_retrain(X_train, y_train, X_test, fit=rf_plus_mdi_plus, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_train_lmdi = np.argsort(-local_fi_score_train_lmdi)\n",
    "sorted_feature_train_shap = np.argsort(-local_fi_score_train_shap)\n",
    "# sorted_feature_train_mdi_plus = np.argsort(-local_fi_score_train_mdi_plus)\n",
    "\n",
    "# ablation_models = {\"RF_Regressor\": RandomForestRegressor(random_state=0)}\n",
    "ablation_models = {\"RF_Classifier\": RandomForestClassifier(random_state=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = [0.1, 0.2, 0.3, 0.4]#, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for mask in mask_ratio:\n",
    "    num_features_masked, X_train_masked = mask_unimportant_features(X_train, sorted_feature_train_lmdi, mask, mask_values)\n",
    "    for a_model in ablation_models:\n",
    "        ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "        y_pred = ablation_models[a_model].predict_proba(X_test)[:, 1]\n",
    "        print(log_loss(y_test, y_pred))\n",
    "        print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = [0.1, 0.2, 0.3, 0.4]#, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for mask in mask_ratio:\n",
    "    num_features_masked, X_train_masked = mask_unimportant_features(X_train, sorted_feature_train_shap, mask, mask_values)\n",
    "    for a_model in ablation_models:\n",
    "        ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "        y_pred = ablation_models[a_model].predict_proba(X_test)[:, 1]\n",
    "        print(log_loss(y_test, y_pred))\n",
    "        print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_pred, n_bins=10)\n",
    "plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray', label='Perfectly Calibrated')\n",
    "plt.xlabel('Predicted Probability')\n",
    "plt.ylabel('True Probability')\n",
    "plt.title('Calibration Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for mask in mask_ratio:\n",
    "    num_features_masked, X_train_masked = mask_unimportant_features(X_train, sorted_feature_train_mdi_plus, mask, mask_values)\n",
    "    for a_model in ablation_models:\n",
    "        ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "        y_pred = ablation_models[a_model].predict(X_test)\n",
    "        print(log_loss(y_test, y_pred))\n",
    "        print(roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_models[a_model].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_train_mdi_plus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_masked[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_values = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    unique_values = np.unique(X_train[:, i])\n",
    "    if len(unique_values) > 2:\n",
    "        mask_values[i] = np.mean(X_train[:, i])\n",
    "    else:\n",
    "        mask_values[i] = list(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=1)\n",
    "est.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV  \n",
    "rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    assert isinstance(fit, RandomForestPlusRegressor) or isinstance(fit, RandomForestPlusClassifier)\n",
    "    rf_plus_mdi = RFPlusMDI(fit, mode = 'only_k', evaluate_on=\"all\")\n",
    "    local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "    local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test\n",
    "\n",
    "local_fi_score_train, _ = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_train = np.argsort(-local_fi_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_unimportant_features(X, sorted_feature, mask, mask_values):\n",
    "    array = copy.deepcopy(X)\n",
    "    num_features = array.shape[1]\n",
    "    num_selected = int(np.ceil(num_features * mask))\n",
    "    \n",
    "    # Select the least important features for each sample\n",
    "    selected_indices = sorted_feature[:, -1*num_selected:]\n",
    "\n",
    "    for row_idx in range(array.shape[0]):\n",
    "        for col_idx in selected_indices[row_idx]:\n",
    "            if isinstance(mask_values[col_idx], (int, float)):\n",
    "                array[row_idx, col_idx] = mask_values[col_idx]  # Replace with mean\n",
    "            else:\n",
    "                unique_vals = mask_values[col_idx]\n",
    "                array[row_idx, col_idx] = unique_vals[1] if array[row_idx, col_idx] == unique_vals[0] else unique_vals[0]  # Replace with alternative value\n",
    "    \n",
    "    return num_selected, array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = 0\n",
    "num_features_selected, X_train_masked = mask_unimportant_features(X_train, sorted_feature_train, mask_ratio, mask_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_masked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0] == X_train_masked[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the number of unique values in each column\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debug the differences yielded by AUROC and RBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_361622.csv')\n",
    "y = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/y_361622.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def apply_splitting_strategy(X: np.ndarray,\n",
    "                             y: np.ndarray,\n",
    "                             splitting_strategy: str,\n",
    "                             split_seed: str):\n",
    "    if splitting_strategy in {'train-test-lowdata', 'train-tune-test-lowdata'}:\n",
    "        test_size = 0.90  # X.shape[0] - X.shape[0] * 0.1\n",
    "    elif splitting_strategy == \"train-test\":\n",
    "        test_size = 0.33\n",
    "    else:\n",
    "        test_size = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=split_seed)\n",
    "    X_tune = None\n",
    "    y_tune = None\n",
    "\n",
    "\n",
    "    return X_train, X_tune, X_test, y_train, y_tune, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Fitting Models\")\n",
    "# fit RF model\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=1)\n",
    "est.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_elastic_no_parallel = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "rf_plus_elastic_no_parallel.fit(X_train, y_train,n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    assert isinstance(fit, RandomForestPlusRegressor) or isinstance(fit, RandomForestPlusClassifier)\n",
    "    rf_plus_mdi = RFPlusMDI(fit, mode = 'only_k', evaluate_on=\"all\")\n",
    "    local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "    local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test\n",
    "\n",
    "lmdi_train, lmdi_test = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_train_no_parallel, lmdi_test_no_parallel = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic_no_parallel, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(lmdi_test, lmdi_test_no_parallel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_test_no_parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def apply_splitting_strategy(X: np.ndarray,\n",
    "                             y: np.ndarray,\n",
    "                             splitting_strategy: str,\n",
    "                             split_seed: str):\n",
    "    if splitting_strategy in {'train-test-lowdata', 'train-tune-test-lowdata'}:\n",
    "        test_size = 0.90  # X.shape[0] - X.shape[0] * 0.1\n",
    "    elif splitting_strategy == \"train-test\":\n",
    "        test_size = 0.33\n",
    "    else:\n",
    "        test_size = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=split_seed)\n",
    "    X_tune = None\n",
    "    y_tune = None\n",
    "\n",
    "\n",
    "    return X_train, X_tune, X_test, y_train, y_tune, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_real_data_X(source=\"openml\", task_id=146819)\n",
    "y,_,_ = sample_real_data_y(source=\"openml\", task_id=146819)\n",
    "# y, support, beta = linear_model(X, sigma=None, s=5, beta=1, heritability=0.999999999999, return_support=True, seed=42)\n",
    "# make y 0/1\n",
    "# y = (y > 0).astype(int)\n",
    "# y, support, beta = lss_model(X, m=3, r=2, beta=1, sigma=None, tau=0.5, heritability=0.99999999, return_support=True)\n",
    "# y, support, beta = hierarchical_poly(X, m=3, r=2, beta=1, heritability=0.999999, return_support=True)\n",
    "#y, support, beta = partial_linear_lss_model(X, s=1, m=3, r=2, beta=1, sigma=None, tau=0.5, heritability=0.99999999, return_support=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_real_data_X(source=\"openml\", task_id=9978, normalize=True)\n",
    "y, support,_ = logistic_poly_random_feature(X, m=3,r=2, beta=1,frac_label_corruption=0,error_seed=3, feature_seed=1, return_support=True)\n",
    "\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Fitting Models\")\n",
    "# fit RF model\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=0)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_baseline = RandomForestPlusRegressor(rf_model=est,\n",
    "                                             prediction_model=LinearRegression(),\n",
    "                                             fit_on=\"inbag\",\n",
    "                                             include_raw=False)\n",
    "# rf_plus_baseline.fit(X_train, y_train)\n",
    "# assert np.allclose(rf_plus_baseline.predict(X_train),est.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNetCV\n",
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features='sqrt', random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_elastic = RandomForestPlusClassifier(rf_model=est, prediction_model=LogisticRegressionCV(penalty='elasticnet', l1_ratios=[0.1,0.5,0.9,0.99], solver = 'saga', cv=3, n_jobs=-1, tol=5e-4, max_iter=2000, random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    assert isinstance(fit, RandomForestPlusRegressor) or isinstance(fit, RandomForestPlusClassifier)\n",
    "    rf_plus_mdi = RFPlusMDI(fit, mode = 'only_k', evaluate_on=\"all\")\n",
    "    local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "    local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test\n",
    "\n",
    "lmdi_train, lmdi_test = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Compute average treeshap value across observations.\n",
    "    Larger absolute values indicate more important features.\n",
    "    :param X: design matrix\n",
    "    :param y: response\n",
    "    :param fit: fitted model of interest (tree-based)\n",
    "    :return: dataframe of shape: (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(fit)\n",
    "    local_fi_score_train = explainer.shap_values(X_train, check_additivity=False)\n",
    "    local_fi_score_test = explainer.shap_values(X_test, check_additivity=False)\n",
    "    if sklearn.base.is_classifier(fit):\n",
    "        if mode == \"absolute\":\n",
    "            return np.abs(local_fi_score_train[:,:,1]), np.abs(local_fi_score_test[:,:,1])\n",
    "        else:\n",
    "            return local_fi_score_train[:,:,1], local_fi_score_test[:,:,1]\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_train, lmdi_test = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_train, shap_test = tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=est, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in range(lmdi_test.shape[0]):\n",
    "    temp.append(roc_auc_score(support, lmdi_test[i, :]))\n",
    "print(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = []\n",
    "for i in range(shap_test.shape[0]):\n",
    "    temp.append(roc_auc_score(support, shap_test[i, :]))\n",
    "print(np.mean(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_train, lasso_test ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.ceil(0.05*len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=0)\n",
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=3, max_features='sqrt', random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=est)\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "# rf_plus_base_oob = RandomForestPlusRegressor(rf_model=est, fit_on=\"oob\")\n",
    "# rf_plus_base_oob.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = RFPlusLime(rf_plus_base)\n",
    "local_fi_score_train_subset = explainer.explain(X_train, X_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_fi_derivation(X, support, dgp):\n",
    "    fi = np.zeros_like(X)\n",
    "    assert dgp == \"linear\"\n",
    "    fi = np.abs(X) \n",
    "    fi[:, support == 0] = 0\n",
    "    return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = ground_truth_fi_derivation(X_train, support, \"linear\")[0]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_largest_k(arr, k):\n",
    "    indices = np.argpartition(arr, -k)[-k:]\n",
    "    encoded_array = np.zeros_like(arr)\n",
    "    encoded_array[indices] = 1\n",
    "    return encoded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encode_largest_k(temp, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_subset[:,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_subset[:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_subset[:,:,1][1]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(local_fi_score_train_subset[1]),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_kernel_shap = RFPlusKernelSHAP(rf_plus_base)\n",
    "local_fi_score_train = None\n",
    "local_fi_score_train_subset = rf_plus_kernel_shap.explain(X_train=X_train, X_test=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.abs(local_fi_score_train_subset),axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_subset[:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_subset[:,:,1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alo_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"oob\")\n",
    "rf_plus_lime = RFPlusLime(rf_plus_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_l2_norm_sign = np.abs(alo_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True))\n",
    "local_fi_score_train_l2_norm = np.abs(alo_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True))\n",
    "local_fi_score_train = np.abs(alo_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=False))\n",
    "lime_train = np.abs(rf_plus_lime.explain(X_train=X_train, X_test=X_train).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_norm_sign= []\n",
    "for i in range(local_fi_score_train.shape[0]):       \n",
    "    auroc_lmdi_norm_sign.append(roc_auc_score([1]*5+[0]*5, local_fi_score_train_l2_norm_sign[i]))\n",
    "print(np.mean(auroc_lmdi_norm_sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_norm= []\n",
    "for i in range(local_fi_score_train.shape[0]):       \n",
    "    auroc_lmdi_norm.append(roc_auc_score([1]*5+[0]*5, local_fi_score_train_l2_norm[i]))\n",
    "print(np.mean(auroc_lmdi_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi= []\n",
    "for i in range(local_fi_score_train.shape[0]):       \n",
    "    auroc_lmdi.append(roc_auc_score([1]*5+[0]*5, local_fi_score_train[i]))\n",
    "print(np.mean(auroc_lmdi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lime= []\n",
    "for i in range(local_fi_score_train.shape[0]):       \n",
    "    auroc_lime.append(roc_auc_score([1]*5+[0]*5, lime_train[i]))\n",
    "print(np.mean(auroc_lime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIME assessment\n",
    "temp_lime = []\n",
    "for i in range(5):\n",
    "    indices_correct = np.argwhere(np.array(auroc_lime) == 1.0).flatten()\n",
    "    indices = np.argwhere((-1 * lime_train).argsort() == i)[:,1][indices_correct]\n",
    "    values = X_train[indices_correct][np.arange(indices_correct.shape[0]), indices]\n",
    "    mean_abs_values = np.mean(np.abs(values))\n",
    "    temp_lime.append(mean_abs_values)\n",
    "print(temp_lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_lmdi = []\n",
    "for i in range(5):\n",
    "    indices_correct = np.argwhere(np.array(auroc_lmdi_norm) == 1.0).flatten()\n",
    "    indices = np.argwhere((-1 * local_fi_score_train_l2_norm).argsort() == i)[:,1][indices_correct]\n",
    "    values = X_train[indices_correct][np.arange(indices_correct.shape[0]), indices]\n",
    "    mean_abs_values = np.mean(np.abs(values))\n",
    "    temp_lmdi.append(mean_abs_values)\n",
    "print(temp_lmdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot temp_lmdi and temp_lime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(temp_lmdi, label=\"lmdi\")\n",
    "plt.plot(temp_lime, label=\"lime\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere((-1 * local_fi_score_train).argsort() == 0)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 0)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 1)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 2)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 3)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 4)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices_correct:\n",
    "    print(tuple(indices[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere(np.array(auroc_lmdi) == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*local_fi_score_train_l2_norm).argsort() == 1)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*local_fi_score_train_l2_norm).argsort() == 2)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*local_fi_score_train_l2_norm).argsort() == 3)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*local_fi_score_train_l2_norm).argsort() == 4)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 0)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 1)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 2)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 3)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 4)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean of X_train of all index with 0 in lime_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi_train = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"all\")\n",
    "rf_plus_mdi_test = RFPlusMDI(rf_plus_base_oob, evaluate_on=\"all\")\n",
    "local_fi_score_train_lmdi_plus_method2 = np.abs(rf_plus_mdi_train.explain_linear_partial(X=X_train, y=y_train, leaf_average=False))\n",
    "local_fi_score_test_lmdi_plus_method2 = np.abs(rf_plus_mdi_test.explain_linear_partial(X=X_test, y=None))\n",
    "local_fi_score_train_lmdi_plus_method2_l2_norm = np.abs(rf_plus_mdi_train.explain_linear_partial(X=X_train, y=y_train, l2norm=True, leaf_average=False))\n",
    "local_fi_score_test_lmdi_plus_method2_l2_norm = np.abs(rf_plus_mdi_test.explain_linear_partial(X=X_test, y=None, l2norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(est)\n",
    "local_fi_score_train_shap = np.abs(explainer.shap_values(X_train, check_additivity=False))\n",
    "local_fi_score_test_shap = np.abs(explainer.shap_values(X_test, check_additivity=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_shap = []\n",
    "rbo_lst_09_shap = []\n",
    "num_captured_shap = []\n",
    "for i in range(local_fi_score_train_shap.shape[0]):\n",
    "    fi_data_i = local_fi_score_train_shap[i]\n",
    "    ground_truth_fi_i = np.abs(X_train)[i]\n",
    "    ground_truth_fi_i[support == 0] = 0\n",
    "    dict_predictions = dict(enumerate(fi_data_i))\n",
    "    dict_ground_truth = dict(enumerate(ground_truth_fi_i))      \n",
    "    num_signal_features = int(np.sum(support))            \n",
    "    auroc_shap.append(roc_auc_score(support, fi_data_i))\n",
    "    rbo_lst_09_shap.append(rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=0.9)[2])\n",
    "    sorted_indices = np.argsort(-fi_data_i)\n",
    "    top_indices = sorted_indices[:num_signal_features]\n",
    "    actual_signal_features = np.sum(support[top_indices])\n",
    "    num_captured_shap.append(actual_signal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_plus= []\n",
    "rbo_lst_09_lmdi_plus = []\n",
    "num_captured_lmdi_plus = []\n",
    "for i in range(local_fi_score_train_lmdi_plus_method2.shape[0]):\n",
    "    fi_data_i = local_fi_score_train_lmdi_plus_method2[i]\n",
    "    ground_truth_fi_i = np.abs(X_train)[i]\n",
    "    ground_truth_fi_i[support == 0] = 0\n",
    "    dict_predictions = dict(enumerate(fi_data_i))\n",
    "    dict_ground_truth = dict(enumerate(ground_truth_fi_i))      \n",
    "    num_signal_features = int(np.sum(support))            \n",
    "    auroc_lmdi_plus.append(roc_auc_score(support, fi_data_i))\n",
    "    rbo_lst_09_lmdi_plus.append(rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=0.9)[2])\n",
    "    sorted_indices = np.argsort(-fi_data_i)\n",
    "    top_indices = sorted_indices[:num_signal_features]\n",
    "    actual_signal_features = np.sum(support[top_indices])\n",
    "    num_captured_lmdi_plus.append(actual_signal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_plus_avg= []\n",
    "rbo_lst_09_lmdi_plus_avg = []\n",
    "num_captured_lmdi_plus_avg = []\n",
    "for i in range(local_fi_score_train_lmdi_plus_method2_l2_norm.shape[0]):\n",
    "    fi_data_i = local_fi_score_train_lmdi_plus_method2_l2_norm[i]\n",
    "    ground_truth_fi_i = np.abs(X_train)[i]\n",
    "    ground_truth_fi_i[support == 0] = 0\n",
    "    dict_predictions = dict(enumerate(fi_data_i))\n",
    "    dict_ground_truth = dict(enumerate(ground_truth_fi_i))      \n",
    "    num_signal_features = int(np.sum(support))            \n",
    "    auroc_lmdi_plus_avg.append(roc_auc_score(support, fi_data_i))\n",
    "    rbo_lst_09_lmdi_plus_avg.append(rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=0.9)[2])\n",
    "    sorted_indices = np.argsort(-fi_data_i)\n",
    "    top_indices = sorted_indices[:num_signal_features]\n",
    "    actual_signal_features = np.sum(support[top_indices])\n",
    "    num_captured_lmdi_plus_avg.append(actual_signal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(auroc_shap).mean(), np.array(rbo_lst_09_shap).mean(), np.array(num_captured_shap).mean())\n",
    "print(np.array(auroc_lmdi_plus).mean(), np.array(rbo_lst_09_lmdi_plus).mean(), np.array(num_captured_lmdi_plus).mean())\n",
    "print(np.array(auroc_lmdi_plus_avg).mean(), np.array(rbo_lst_09_lmdi_plus_avg).mean(), np.array(num_captured_lmdi_plus_avg).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_shap[5], rbo_lst_09_shap[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_plus[5], rbo_lst_09_lmdi_plus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_fi_i = np.abs(X_test)[5]\n",
    "ground_truth_fi_i[support == 0] = 0\n",
    "ground_truth_fi_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predictions = dict(enumerate(local_fi_score_test_shap[5]))\n",
    "dict_ground_truth = dict(enumerate(ground_truth_fi_i))\n",
    "rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=p, verbose=True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_test_lmdi_plus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predictions = dict(enumerate(local_fi_score_test_lmdi_plus[5]))\n",
    "dict_ground_truth = dict(enumerate(ground_truth_fi_i))\n",
    "rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=p, verbose=True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([0.30647695  , 0.17410994, 0.816055, 0.17842848, 0.10012125,\n",
    "       0.26276102, 0.26671546, 0.28039733, 0.23719995, 0.25739759])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predictions = dict(enumerate(temp))#local_fi_score_test_lmdi_plus[5]))\n",
    "dict_ground_truth = dict(enumerate(ground_truth_fi_i))\n",
    "rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=p, verbose=True)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debug two group setting with intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_normal_X_subgroups(n = 500, d=10, mean= [[0]*10,[0]*5+[0]*5], scale =[[1]*10,[1]*10])\n",
    "temp = linear_model(X, beta=1, sigma=None, heritability=0.6, s=5, return_support=True)\n",
    "y = temp[0]\n",
    "support = temp[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model(X, beta=1, sigma=None, heritability=0.2, s=5, return_support=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base = RandomForestPlusRegressor(rf_model=rf)\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_base_oob = RandomForestPlusRegressor(rf_model=rf, fit_on=\"oob\")\n",
    "# rf_plus_base_oob.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_base_inbag = RandomForestPlusRegressor(rf_model=rf, include_raw=False, fit_on=\"inbag\", prediction_model=Ridge(alpha=1e-6))\n",
    "# rf_plus_base_inbag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "if X_train.shape[0] > 100:\n",
    "    indices_train = np.random.choice(X_train.shape[0], 100, replace=False)\n",
    "    X_train_subset = X_train[indices_train]\n",
    "    y_train_subset = y_train[indices_train]\n",
    "else:\n",
    "    indices_train = np.arange(X_train.shape[0])\n",
    "    X_train_subset = X_train\n",
    "    y_train_subset = y_train\n",
    "\n",
    "if X_test.shape[0] > 100:\n",
    "    indices_test = np.random.choice(X_test.shape[0], 100, replace=False)\n",
    "    X_test_subset = X_test[indices_test]\n",
    "    y_test_subset = y_test[indices_test]\n",
    "else:\n",
    "    indices_test = np.arange(X_test.shape[0])\n",
    "    X_test_subset = X_test\n",
    "    y_test_subset = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train_0 = np.where(X_train_subset[:, -1] == 0)[0]\n",
    "indices_test_0 = np.where(X_test_subset[:, -1] == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train_1 = np.where(X_train_subset[:, -1] == 1)[0]\n",
    "indices_test_1 = np.where(X_test_subset[:, -1] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train, local_fi_score_train_subset, local_fi_score_test, local_fi_score_test_subset = tree_shap_evaluation_RF(X_train=X_train, y_train=y_train, X_train_subset = X_train_subset, y_train_subset=y_train_subset,X_test=X_test, y_test=y_test, X_test_subset=X_test_subset, y_test_subset=y_test_subset,fit=rf, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_support_train = np.abs(X_train_subset)\n",
    "new_support_test = np.abs(X_test)\n",
    "new_support_train[:, -5:] = 0\n",
    "new_support_test[:, -5:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset\n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(\"Treeshap Test\")\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_biased_overlap(list1, list2, p=0.9):\n",
    "    \"\"\"\n",
    "    Compute the Rank-Biased Overlap (RBO) between two ranked lists.\n",
    "\n",
    "    Parameters:\n",
    "    - list1: numpy array or list of the first ranked list\n",
    "    - list2: numpy array or list of the second ranked list\n",
    "    - p: the discount factor (default is 0.9, which is commonly used)\n",
    "\n",
    "    Returns:\n",
    "    - rbo: the Rank-Biased Overlap score\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert lists to numpy arrays if they're not already\n",
    "    list1 = np.asarray(list1)\n",
    "    list2 = np.asarray(list2)\n",
    "\n",
    "    # Get the indices that would sort the arrays in descending order\n",
    "    sorted_indices1 = np.argsort(-list1)\n",
    "    sorted_indices2 = np.argsort(-list2)\n",
    "\n",
    "    # Rank lists based on sorted indices\n",
    "    ranked_list1 = sorted_indices1\n",
    "    ranked_list2 = sorted_indices2\n",
    "\n",
    "    # Initialize the overlap\n",
    "    overlap = 0.0\n",
    "    min_len = min(len(ranked_list1), len(ranked_list2))\n",
    "    \n",
    "    # Compute the RBO\n",
    "    for i in range(min_len):\n",
    "        # Calculate the overlap at rank i\n",
    "        rank_i_overlap = len(set(ranked_list1[:i+1]) & set(ranked_list2[:i+1]))\n",
    "        \n",
    "        # Add the discounted overlap to the total\n",
    "        overlap += (rank_i_overlap / (i + 1)) * (p ** (i + 1))\n",
    "    \n",
    "    # Normalize the score\n",
    "    normalization = (1 - p) / (1 - p ** (min_len + 1))\n",
    "    rbo = overlap * normalization\n",
    "    \n",
    "    return rbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset\n",
    "rbo = []\n",
    "for i in range(data.shape[0]):\n",
    "        rbo.append(rank_biased_overlap(new_support_train[i], data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(rbo).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test\n",
    "rbo = []\n",
    "for i in range(data.shape[0]):\n",
    "        rbo.append(rank_biased_overlap(new_support_test[i], data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(rbo).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi_train = AloRFPlusMDI(rf_plus_base, evaluate_on=\"oob\")\n",
    "rf_plus_mdi_test = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "local_fi_score_train = np.abs(rf_plus_mdi_train.explain_subtract_intercept(X=X_train, y=y_train))\n",
    "local_fi_score_test = np.abs(rf_plus_mdi_test.explain_subtract_intercept(X=X_test, y=None))\n",
    "local_fi_score_test_subset = np.abs(rf_plus_mdi_test.explain_subtract_intercept(X=X_test_subset, y=None))\n",
    "local_fi_score_train_subset = local_fi_score_train[indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_support_train = np.abs(X_train_subset)\n",
    "new_support_test = np.abs(X_test)\n",
    "new_support_train[:, -5:] = 0\n",
    "new_support_test[:, -5:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset\n",
    "rbo = []\n",
    "for i in range(data.shape[0]):\n",
    "        rbo.append(rank_biased_overlap(new_support_train[i], data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(rbo).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test\n",
    "rbo_lst = []\n",
    "for i in range(data.shape[0]):\n",
    "        rbo_lst.append(rbo.RankingSimilarity(new_support_test[i], data[i]).rbo())#rbo.append(rank_biased_overlap(new_support_test[i], data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(rbo).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_support_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbo.RankingSimilarity(S, T).rbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi_train = AloRFPlusMDI(rf_plus_base, evaluate_on=\"oob\")\n",
    "rf_plus_mdi_test = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "local_fi_score_train = np.abs(rf_plus_mdi_train.explain(X=X_train, y=y_train)[1])\n",
    "local_fi_score_test = np.abs(rf_plus_mdi_test.explain(X=X_test, y=None)[1])\n",
    "local_fi_score_test_subset = np.abs(rf_plus_mdi_test.explain(X=X_test_subset, y=None)[1])\n",
    "local_fi_score_train_subset = local_fi_score_train[indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
