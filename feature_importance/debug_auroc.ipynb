{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "import imodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import RandomForestPlusRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, mean_squared_error, r2_score, average_precision_score\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from feature_importance.scripts.simulations_util import *\n",
    "from scripts.competing_methods_local import *\n",
    "from rbo_implementation import rbo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_fi_derivation(X, support, dgp):\n",
    "    fi = np.zeros_like(X)  # Initialize feature importance array\n",
    "    \n",
    "    if dgp == \"linear\":\n",
    "        fi = np.abs(X)  # Use absolute values for linear case\n",
    "        fi[:, support == 0] = 0  # Set non-supported features to 0\n",
    "    \n",
    "    elif dgp == \"polynomial\":\n",
    "        for j in range(X.shape[1]):\n",
    "            if support[j] == 1:\n",
    "                if j in [0, 2, 4]:\n",
    "                    fi[:, j] = np.abs(X[:, j] + X[:, j] * X[:, j + 1])\n",
    "                else:\n",
    "                    fi[:, j] = np.abs(X[:, j] * X[:, j - 1])\n",
    "    \n",
    "    elif dgp == \"lss\":\n",
    "        for j in range(X.shape[1]):\n",
    "            if support[j] == 1:\n",
    "                if j in [0, 2, 4]:\n",
    "                    fi[:, j] = np.abs((X[:, j] > 0) * (X[:, j + 1] > 0) - 0.5 * (X[:, j + 1] > 0))\n",
    "                else:\n",
    "                    fi[:, j] = np.abs((X[:, j] > 0) * (X[:, j - 1] > 0) - 0.5 * (X[:, j - 1] > 0))\n",
    "    \n",
    "    elif dgp == \"linear_lss\":\n",
    "        for j in range(X.shape[1]):\n",
    "            if support[j] == 1:\n",
    "                if j in [0, 2, 4]:\n",
    "                    fi[:, j] = np.abs(X[:, j] + X[:, j] * X[:, j + 1] + ((X[:, j] > 0) * (X[:, j + 1] > 0) - 0.5 * (X[:, j + 1] > 0)))\n",
    "                else:\n",
    "                    fi[:, j] = np.abs(X[:, j] + ((X[:, j] > 0) * (X[:, j - 1] > 0) - 0.5 * (X[:, j - 1] > 0)))\n",
    "    return fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debug the differences yielded by AUROC and RBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_normal_X(n_train=100, n_test=100, d=10, seed=42)\n",
    "y, support, beta = linear_model(X, sigma=None, s=5, beta=1, heritability=0.999999999999, return_support=True, seed=42)\n",
    "# make y 0/1\n",
    "y = (y > 0).astype(int)\n",
    "# y, support, beta = lss_model(X, m=3, r=2, beta=1, sigma=None, tau=0.5, heritability=0.99999999, return_support=True)\n",
    "# y, support, beta = hierarchical_poly(X, m=3, r=2, beta=1, heritability=0.999999, return_support=True)\n",
    "#y, support, beta = partial_linear_lss_model(X, s=1, m=3, r=2, beta=1, sigma=None, tau=0.5, heritability=0.99999999, return_support=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   14.3s finished\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=100, random_state=0)\n",
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=3, max_features='sqrt', random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=est)\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "# rf_plus_base_oob = RandomForestPlusRegressor(rf_model=est, fit_on=\"oob\")\n",
    "# rf_plus_base_oob.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = RFPlusLime(rf_plus_base)\n",
    "local_fi_score_train_subset = explainer.explain(X_train, X_train[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_fi_derivation(X, support, dgp):\n",
    "    fi = np.zeros_like(X)\n",
    "    assert dgp == \"linear\"\n",
    "    fi = np.abs(X) \n",
    "    fi[:, support == 0] = 0\n",
    "    return fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.2005692 ,  1.14863735, -1.01582182,  0.06167985,  0.4288165 ,\n",
       "        0.69310561,  0.17644156, -0.36702784, -0.82759022,  0.08614388])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2005692 , 1.14863735, 1.01582182, 0.06167985, 0.4288165 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = ground_truth_fi_derivation(X_train, support, \"linear\")[0]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_largest_k(arr, k):\n",
    "    indices = np.argpartition(arr, -k)[-k:]\n",
    "    encoded_array = np.zeros_like(arr)\n",
    "    encoded_array[indices] = 1\n",
    "    return encoded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode_largest_k(temp, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_0</th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.042939</td>\n",
       "      <td>0.313872</td>\n",
       "      <td>-0.278004</td>\n",
       "      <td>-0.072298</td>\n",
       "      <td>0.071858</td>\n",
       "      <td>0.001796</td>\n",
       "      <td>-0.002037</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.051954</td>\n",
       "      <td>0.016916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.128044</td>\n",
       "      <td>0.309360</td>\n",
       "      <td>0.298556</td>\n",
       "      <td>0.088216</td>\n",
       "      <td>-0.196329</td>\n",
       "      <td>0.003211</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>-0.005707</td>\n",
       "      <td>0.002099</td>\n",
       "      <td>0.004099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.128975</td>\n",
       "      <td>0.300358</td>\n",
       "      <td>-0.286637</td>\n",
       "      <td>0.092595</td>\n",
       "      <td>-0.216878</td>\n",
       "      <td>-0.000919</td>\n",
       "      <td>-0.014500</td>\n",
       "      <td>-0.011689</td>\n",
       "      <td>-0.015093</td>\n",
       "      <td>-0.002838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031202</td>\n",
       "      <td>-0.092956</td>\n",
       "      <td>0.300951</td>\n",
       "      <td>0.264616</td>\n",
       "      <td>-0.073096</td>\n",
       "      <td>-0.003058</td>\n",
       "      <td>0.014221</td>\n",
       "      <td>-0.021825</td>\n",
       "      <td>0.013697</td>\n",
       "      <td>0.002225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.142722</td>\n",
       "      <td>0.127125</td>\n",
       "      <td>0.297740</td>\n",
       "      <td>-0.052867</td>\n",
       "      <td>0.205676</td>\n",
       "      <td>-0.022843</td>\n",
       "      <td>-0.025235</td>\n",
       "      <td>-0.003849</td>\n",
       "      <td>0.013926</td>\n",
       "      <td>0.002184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.128965</td>\n",
       "      <td>-0.379115</td>\n",
       "      <td>0.282897</td>\n",
       "      <td>-0.053190</td>\n",
       "      <td>0.216716</td>\n",
       "      <td>-0.009724</td>\n",
       "      <td>0.027204</td>\n",
       "      <td>-0.003624</td>\n",
       "      <td>0.018411</td>\n",
       "      <td>0.017139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.016295</td>\n",
       "      <td>0.129708</td>\n",
       "      <td>-0.310517</td>\n",
       "      <td>0.252410</td>\n",
       "      <td>-0.061308</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>0.025644</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>-0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.031261</td>\n",
       "      <td>0.323186</td>\n",
       "      <td>-0.079017</td>\n",
       "      <td>-0.276703</td>\n",
       "      <td>-0.062329</td>\n",
       "      <td>0.010259</td>\n",
       "      <td>-0.021847</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>0.017011</td>\n",
       "      <td>0.002881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.024168</td>\n",
       "      <td>-0.066039</td>\n",
       "      <td>-0.105093</td>\n",
       "      <td>-0.292647</td>\n",
       "      <td>0.212371</td>\n",
       "      <td>-0.012728</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>0.002272</td>\n",
       "      <td>-0.046477</td>\n",
       "      <td>-0.018832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.119871</td>\n",
       "      <td>-0.376929</td>\n",
       "      <td>-0.281069</td>\n",
       "      <td>0.250905</td>\n",
       "      <td>0.056492</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>0.008817</td>\n",
       "      <td>0.018102</td>\n",
       "      <td>-0.051789</td>\n",
       "      <td>0.011734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.029601</td>\n",
       "      <td>0.309561</td>\n",
       "      <td>-0.304045</td>\n",
       "      <td>0.088166</td>\n",
       "      <td>0.057674</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.011819</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.057474</td>\n",
       "      <td>-0.002475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.017178</td>\n",
       "      <td>0.301599</td>\n",
       "      <td>0.087535</td>\n",
       "      <td>-0.277703</td>\n",
       "      <td>0.209890</td>\n",
       "      <td>0.005492</td>\n",
       "      <td>-0.031396</td>\n",
       "      <td>0.009367</td>\n",
       "      <td>0.036044</td>\n",
       "      <td>-0.021671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.028058</td>\n",
       "      <td>-0.379708</td>\n",
       "      <td>-0.296975</td>\n",
       "      <td>-0.051079</td>\n",
       "      <td>-0.201828</td>\n",
       "      <td>-0.021665</td>\n",
       "      <td>-0.005464</td>\n",
       "      <td>0.002068</td>\n",
       "      <td>-0.048962</td>\n",
       "      <td>0.011168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.119517</td>\n",
       "      <td>-0.071244</td>\n",
       "      <td>-0.071057</td>\n",
       "      <td>0.269233</td>\n",
       "      <td>0.194014</td>\n",
       "      <td>0.014276</td>\n",
       "      <td>-0.005563</td>\n",
       "      <td>-0.004784</td>\n",
       "      <td>0.008854</td>\n",
       "      <td>0.003792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.119886</td>\n",
       "      <td>-0.094282</td>\n",
       "      <td>-0.300573</td>\n",
       "      <td>0.079922</td>\n",
       "      <td>-0.215158</td>\n",
       "      <td>0.000859</td>\n",
       "      <td>-0.003451</td>\n",
       "      <td>-0.010027</td>\n",
       "      <td>-0.028751</td>\n",
       "      <td>-0.016988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.021971</td>\n",
       "      <td>-0.389857</td>\n",
       "      <td>0.277861</td>\n",
       "      <td>-0.046905</td>\n",
       "      <td>-0.058231</td>\n",
       "      <td>0.011873</td>\n",
       "      <td>0.011555</td>\n",
       "      <td>0.001418</td>\n",
       "      <td>0.003535</td>\n",
       "      <td>0.004855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.143329</td>\n",
       "      <td>0.131210</td>\n",
       "      <td>0.068458</td>\n",
       "      <td>-0.269135</td>\n",
       "      <td>0.204198</td>\n",
       "      <td>0.016600</td>\n",
       "      <td>-0.026526</td>\n",
       "      <td>0.011625</td>\n",
       "      <td>0.041831</td>\n",
       "      <td>0.015975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.033556</td>\n",
       "      <td>0.141116</td>\n",
       "      <td>0.289052</td>\n",
       "      <td>-0.291965</td>\n",
       "      <td>0.202833</td>\n",
       "      <td>-0.016299</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>-0.013817</td>\n",
       "      <td>0.048549</td>\n",
       "      <td>-0.009979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.126349</td>\n",
       "      <td>-0.397578</td>\n",
       "      <td>0.080365</td>\n",
       "      <td>0.077055</td>\n",
       "      <td>-0.200733</td>\n",
       "      <td>-0.008595</td>\n",
       "      <td>-0.001617</td>\n",
       "      <td>0.007530</td>\n",
       "      <td>0.033261</td>\n",
       "      <td>-0.002497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.028854</td>\n",
       "      <td>0.147636</td>\n",
       "      <td>0.283100</td>\n",
       "      <td>0.255617</td>\n",
       "      <td>-0.198569</td>\n",
       "      <td>-0.025120</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>-0.007497</td>\n",
       "      <td>0.024461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Feature_0  Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  \\\n",
       "0    0.042939   0.313872  -0.278004  -0.072298   0.071858   0.001796   \n",
       "1    0.128044   0.309360   0.298556   0.088216  -0.196329   0.003211   \n",
       "2    0.128975   0.300358  -0.286637   0.092595  -0.216878  -0.000919   \n",
       "3    0.031202  -0.092956   0.300951   0.264616  -0.073096  -0.003058   \n",
       "4   -0.142722   0.127125   0.297740  -0.052867   0.205676  -0.022843   \n",
       "5    0.128965  -0.379115   0.282897  -0.053190   0.216716  -0.009724   \n",
       "6   -0.016295   0.129708  -0.310517   0.252410  -0.061308   0.000620   \n",
       "7   -0.031261   0.323186  -0.079017  -0.276703  -0.062329   0.010259   \n",
       "8   -0.024168  -0.066039  -0.105093  -0.292647   0.212371  -0.012728   \n",
       "9    0.119871  -0.376929  -0.281069   0.250905   0.056492  -0.016494   \n",
       "10  -0.029601   0.309561  -0.304045   0.088166   0.057674   0.000508   \n",
       "11  -0.017178   0.301599   0.087535  -0.277703   0.209890   0.005492   \n",
       "12  -0.028058  -0.379708  -0.296975  -0.051079  -0.201828  -0.021665   \n",
       "13  -0.119517  -0.071244  -0.071057   0.269233   0.194014   0.014276   \n",
       "14  -0.119886  -0.094282  -0.300573   0.079922  -0.215158   0.000859   \n",
       "15  -0.021971  -0.389857   0.277861  -0.046905  -0.058231   0.011873   \n",
       "16  -0.143329   0.131210   0.068458  -0.269135   0.204198   0.016600   \n",
       "17  -0.033556   0.141116   0.289052  -0.291965   0.202833  -0.016299   \n",
       "18  -0.126349  -0.397578   0.080365   0.077055  -0.200733  -0.008595   \n",
       "19   0.028854   0.147636   0.283100   0.255617  -0.198569  -0.025120   \n",
       "\n",
       "    Feature_6  Feature_7  Feature_8  Feature_9  \n",
       "0   -0.002037   0.000888   0.051954   0.016916  \n",
       "1    0.001649  -0.005707   0.002099   0.004099  \n",
       "2   -0.014500  -0.011689  -0.015093  -0.002838  \n",
       "3    0.014221  -0.021825   0.013697   0.002225  \n",
       "4   -0.025235  -0.003849   0.013926   0.002184  \n",
       "5    0.027204  -0.003624   0.018411   0.017139  \n",
       "6    0.025644   0.006252   0.001251  -0.004184  \n",
       "7   -0.021847  -0.000049   0.017011   0.002881  \n",
       "8    0.030731   0.002272  -0.046477  -0.018832  \n",
       "9    0.008817   0.018102  -0.051789   0.011734  \n",
       "10   0.011819   0.000034  -0.057474  -0.002475  \n",
       "11  -0.031396   0.009367   0.036044  -0.021671  \n",
       "12  -0.005464   0.002068  -0.048962   0.011168  \n",
       "13  -0.005563  -0.004784   0.008854   0.003792  \n",
       "14  -0.003451  -0.010027  -0.028751  -0.016988  \n",
       "15   0.011555   0.001418   0.003535   0.004855  \n",
       "16  -0.026526   0.011625   0.041831   0.015975  \n",
       "17   0.007442  -0.013817   0.048549  -0.009979  \n",
       "18  -0.001617   0.007530   0.033261  -0.002497  \n",
       "19   0.010844   0.003780  -0.007497   0.024461  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fi_score_train_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fi_score_train_subset[:,:,1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01645106, -0.2746186 ,  0.18108225,  0.0119518 , -0.068272  ,\n",
       "        0.00145062, -0.01007098, -0.00809212, -0.03299942, -0.00196042])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fi_score_train_subset[:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fi_score_train_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10618995,  0.32264464,  0.21552725,  0.0988917 , -0.14106001,\n",
       "        0.046378  ,  0.01789238,  0.02558619,  0.03749313, -0.01384323])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fi_score_train_subset[:,:,1][1]*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10618995, 0.32264464, 0.21552725, 0.0988917 , 0.14106001,\n",
       "       0.046378  , 0.01789238, 0.02558619, 0.03749313, 0.01384323])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(local_fi_score_train_subset[1]),axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:39<00:00,  2.50it/s]\n"
     ]
    }
   ],
   "source": [
    "rf_plus_kernel_shap = RFPlusKernelSHAP(rf_plus_base)\n",
    "local_fi_score_train = None\n",
    "local_fi_score_train_subset = rf_plus_kernel_shap.explain(X_train=X_train, X_test=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10, 2)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fi_score_train_subset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.abs(local_fi_score_train_subset),axis=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.01645106, -0.2746186 ,  0.18108225,  0.0119518 , -0.068272  ,\n",
       "        0.00145062, -0.01007098, -0.00809212, -0.03299942, -0.00196042])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fi_score_train_subset[:,:,0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01645106,  0.2746186 , -0.18108225, -0.0119518 ,  0.068272  ,\n",
       "       -0.00145062,  0.01007098,  0.00809212,  0.03299942,  0.00196042])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_fi_score_train_subset[:,:,1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alo_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"oob\")\n",
    "rf_plus_lime = RFPlusLime(rf_plus_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_l2_norm_sign = np.abs(alo_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True))\n",
    "local_fi_score_train_l2_norm = np.abs(alo_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True))\n",
    "local_fi_score_train = np.abs(alo_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=False))\n",
    "lime_train = np.abs(rf_plus_lime.explain(X_train=X_train, X_test=X_train).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_norm_sign= []\n",
    "for i in range(local_fi_score_train.shape[0]):       \n",
    "    auroc_lmdi_norm_sign.append(roc_auc_score([1]*5+[0]*5, local_fi_score_train_l2_norm_sign[i]))\n",
    "print(np.mean(auroc_lmdi_norm_sign))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_norm= []\n",
    "for i in range(local_fi_score_train.shape[0]):       \n",
    "    auroc_lmdi_norm.append(roc_auc_score([1]*5+[0]*5, local_fi_score_train_l2_norm[i]))\n",
    "print(np.mean(auroc_lmdi_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi= []\n",
    "for i in range(local_fi_score_train.shape[0]):       \n",
    "    auroc_lmdi.append(roc_auc_score([1]*5+[0]*5, local_fi_score_train[i]))\n",
    "print(np.mean(auroc_lmdi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lime= []\n",
    "for i in range(local_fi_score_train.shape[0]):       \n",
    "    auroc_lime.append(roc_auc_score([1]*5+[0]*5, lime_train[i]))\n",
    "print(np.mean(auroc_lime))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### LIME assessment\n",
    "temp_lime = []\n",
    "for i in range(5):\n",
    "    indices_correct = np.argwhere(np.array(auroc_lime) == 1.0).flatten()\n",
    "    indices = np.argwhere((-1 * lime_train).argsort() == i)[:,1][indices_correct]\n",
    "    values = X_train[indices_correct][np.arange(indices_correct.shape[0]), indices]\n",
    "    mean_abs_values = np.mean(np.abs(values))\n",
    "    temp_lime.append(mean_abs_values)\n",
    "print(temp_lime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_lmdi = []\n",
    "for i in range(5):\n",
    "    indices_correct = np.argwhere(np.array(auroc_lmdi_norm) == 1.0).flatten()\n",
    "    indices = np.argwhere((-1 * local_fi_score_train_l2_norm).argsort() == i)[:,1][indices_correct]\n",
    "    values = X_train[indices_correct][np.arange(indices_correct.shape[0]), indices]\n",
    "    mean_abs_values = np.mean(np.abs(values))\n",
    "    temp_lmdi.append(mean_abs_values)\n",
    "print(temp_lmdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot temp_lmdi and temp_lime\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(temp_lmdi, label=\"lmdi\")\n",
    "plt.plot(temp_lime, label=\"lime\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argwhere((-1 * local_fi_score_train).argsort() == 0)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 0)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 1)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 2)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 3)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_correct = np.argwhere(np.array(auroc_lmdi) == 1.0)\n",
    "indices = np.argwhere((-1*local_fi_score_train).argsort() == 4)\n",
    "values = [X_train[tuple(indices[index])] for index in indices_correct]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in indices_correct:\n",
    "    print(tuple(indices[index]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere(np.array(auroc_lmdi) == 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*local_fi_score_train_l2_norm).argsort() == 1)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*local_fi_score_train_l2_norm).argsort() == 2)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*local_fi_score_train_l2_norm).argsort() == 3)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*local_fi_score_train_l2_norm).argsort() == 4)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 0)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 1)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 2)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 3)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.argwhere((-1*lime_train).argsort() == 4)\n",
    "values = [X_train[tuple(index)] for index in indices]\n",
    "np.mean(np.abs(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find mean of X_train of all index with 0 in lime_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi_train = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"all\")\n",
    "rf_plus_mdi_test = RFPlusMDI(rf_plus_base_oob, evaluate_on=\"all\")\n",
    "local_fi_score_train_lmdi_plus_method2 = np.abs(rf_plus_mdi_train.explain_linear_partial(X=X_train, y=y_train, leaf_average=False))\n",
    "local_fi_score_test_lmdi_plus_method2 = np.abs(rf_plus_mdi_test.explain_linear_partial(X=X_test, y=None))\n",
    "local_fi_score_train_lmdi_plus_method2_l2_norm = np.abs(rf_plus_mdi_train.explain_linear_partial(X=X_train, y=y_train, l2norm=True, leaf_average=False))\n",
    "local_fi_score_test_lmdi_plus_method2_l2_norm = np.abs(rf_plus_mdi_test.explain_linear_partial(X=X_test, y=None, l2norm=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(est)\n",
    "local_fi_score_train_shap = np.abs(explainer.shap_values(X_train, check_additivity=False))\n",
    "local_fi_score_test_shap = np.abs(explainer.shap_values(X_test, check_additivity=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_shap = []\n",
    "rbo_lst_09_shap = []\n",
    "num_captured_shap = []\n",
    "for i in range(local_fi_score_train_shap.shape[0]):\n",
    "    fi_data_i = local_fi_score_train_shap[i]\n",
    "    ground_truth_fi_i = np.abs(X_train)[i]\n",
    "    ground_truth_fi_i[support == 0] = 0\n",
    "    dict_predictions = dict(enumerate(fi_data_i))\n",
    "    dict_ground_truth = dict(enumerate(ground_truth_fi_i))      \n",
    "    num_signal_features = int(np.sum(support))            \n",
    "    auroc_shap.append(roc_auc_score(support, fi_data_i))\n",
    "    rbo_lst_09_shap.append(rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=0.9)[2])\n",
    "    sorted_indices = np.argsort(-fi_data_i)\n",
    "    top_indices = sorted_indices[:num_signal_features]\n",
    "    actual_signal_features = np.sum(support[top_indices])\n",
    "    num_captured_shap.append(actual_signal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_plus= []\n",
    "rbo_lst_09_lmdi_plus = []\n",
    "num_captured_lmdi_plus = []\n",
    "for i in range(local_fi_score_train_lmdi_plus_method2.shape[0]):\n",
    "    fi_data_i = local_fi_score_train_lmdi_plus_method2[i]\n",
    "    ground_truth_fi_i = np.abs(X_train)[i]\n",
    "    ground_truth_fi_i[support == 0] = 0\n",
    "    dict_predictions = dict(enumerate(fi_data_i))\n",
    "    dict_ground_truth = dict(enumerate(ground_truth_fi_i))      \n",
    "    num_signal_features = int(np.sum(support))            \n",
    "    auroc_lmdi_plus.append(roc_auc_score(support, fi_data_i))\n",
    "    rbo_lst_09_lmdi_plus.append(rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=0.9)[2])\n",
    "    sorted_indices = np.argsort(-fi_data_i)\n",
    "    top_indices = sorted_indices[:num_signal_features]\n",
    "    actual_signal_features = np.sum(support[top_indices])\n",
    "    num_captured_lmdi_plus.append(actual_signal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_plus_avg= []\n",
    "rbo_lst_09_lmdi_plus_avg = []\n",
    "num_captured_lmdi_plus_avg = []\n",
    "for i in range(local_fi_score_train_lmdi_plus_method2_l2_norm.shape[0]):\n",
    "    fi_data_i = local_fi_score_train_lmdi_plus_method2_l2_norm[i]\n",
    "    ground_truth_fi_i = np.abs(X_train)[i]\n",
    "    ground_truth_fi_i[support == 0] = 0\n",
    "    dict_predictions = dict(enumerate(fi_data_i))\n",
    "    dict_ground_truth = dict(enumerate(ground_truth_fi_i))      \n",
    "    num_signal_features = int(np.sum(support))            \n",
    "    auroc_lmdi_plus_avg.append(roc_auc_score(support, fi_data_i))\n",
    "    rbo_lst_09_lmdi_plus_avg.append(rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=0.9)[2])\n",
    "    sorted_indices = np.argsort(-fi_data_i)\n",
    "    top_indices = sorted_indices[:num_signal_features]\n",
    "    actual_signal_features = np.sum(support[top_indices])\n",
    "    num_captured_lmdi_plus_avg.append(actual_signal_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array(auroc_shap).mean(), np.array(rbo_lst_09_shap).mean(), np.array(num_captured_shap).mean())\n",
    "print(np.array(auroc_lmdi_plus).mean(), np.array(rbo_lst_09_lmdi_plus).mean(), np.array(num_captured_lmdi_plus).mean())\n",
    "print(np.array(auroc_lmdi_plus_avg).mean(), np.array(rbo_lst_09_lmdi_plus_avg).mean(), np.array(num_captured_lmdi_plus_avg).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_shap[5], rbo_lst_09_shap[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auroc_lmdi_plus[5], rbo_lst_09_lmdi_plus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_fi_i = np.abs(X_test)[5]\n",
    "ground_truth_fi_i[support == 0] = 0\n",
    "ground_truth_fi_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predictions = dict(enumerate(local_fi_score_test_shap[5]))\n",
    "dict_ground_truth = dict(enumerate(ground_truth_fi_i))\n",
    "rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=p, verbose=True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_test_lmdi_plus[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predictions = dict(enumerate(local_fi_score_test_lmdi_plus[5]))\n",
    "dict_ground_truth = dict(enumerate(ground_truth_fi_i))\n",
    "rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=p, verbose=True)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.array([0.30647695  , 0.17410994, 0.816055, 0.17842848, 0.10012125,\n",
    "       0.26276102, 0.26671546, 0.28039733, 0.23719995, 0.25739759])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_predictions = dict(enumerate(temp))#local_fi_score_test_lmdi_plus[5]))\n",
    "dict_ground_truth = dict(enumerate(ground_truth_fi_i))\n",
    "rbo_dict(dict1=dict_ground_truth, dict2=dict_predictions, p=p, verbose=True)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Debug two group setting with intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_normal_X_subgroups(n = 500, d=10, mean= [[0]*10,[0]*5+[0]*5], scale =[[1]*10,[1]*10])\n",
    "temp = linear_model(X, beta=1, sigma=None, heritability=0.6, s=5, return_support=True)\n",
    "y = temp[0]\n",
    "support = temp[1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model(X, beta=1, sigma=None, heritability=0.2, s=5, return_support=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base = RandomForestPlusRegressor(rf_model=rf)\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_base_oob = RandomForestPlusRegressor(rf_model=rf, fit_on=\"oob\")\n",
    "# rf_plus_base_oob.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_base_inbag = RandomForestPlusRegressor(rf_model=rf, include_raw=False, fit_on=\"inbag\", prediction_model=Ridge(alpha=1e-6))\n",
    "# rf_plus_base_inbag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "if X_train.shape[0] > 100:\n",
    "    indices_train = np.random.choice(X_train.shape[0], 100, replace=False)\n",
    "    X_train_subset = X_train[indices_train]\n",
    "    y_train_subset = y_train[indices_train]\n",
    "else:\n",
    "    indices_train = np.arange(X_train.shape[0])\n",
    "    X_train_subset = X_train\n",
    "    y_train_subset = y_train\n",
    "\n",
    "if X_test.shape[0] > 100:\n",
    "    indices_test = np.random.choice(X_test.shape[0], 100, replace=False)\n",
    "    X_test_subset = X_test[indices_test]\n",
    "    y_test_subset = y_test[indices_test]\n",
    "else:\n",
    "    indices_test = np.arange(X_test.shape[0])\n",
    "    X_test_subset = X_test\n",
    "    y_test_subset = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train_0 = np.where(X_train_subset[:, -1] == 0)[0]\n",
    "indices_test_0 = np.where(X_test_subset[:, -1] == 0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train_1 = np.where(X_train_subset[:, -1] == 1)[0]\n",
    "indices_test_1 = np.where(X_test_subset[:, -1] == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train, local_fi_score_train_subset, local_fi_score_test, local_fi_score_test_subset = tree_shap_evaluation_RF(X_train=X_train, y_train=y_train, X_train_subset = X_train_subset, y_train_subset=y_train_subset,X_test=X_test, y_test=y_test, X_test_subset=X_test_subset, y_test_subset=y_test_subset,fit=rf, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_support_train = np.abs(X_train_subset)\n",
    "new_support_test = np.abs(X_test)\n",
    "new_support_train[:, -5:] = 0\n",
    "new_support_test[:, -5:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset\n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(\"Treeshap Test\")\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_biased_overlap(list1, list2, p=0.9):\n",
    "    \"\"\"\n",
    "    Compute the Rank-Biased Overlap (RBO) between two ranked lists.\n",
    "\n",
    "    Parameters:\n",
    "    - list1: numpy array or list of the first ranked list\n",
    "    - list2: numpy array or list of the second ranked list\n",
    "    - p: the discount factor (default is 0.9, which is commonly used)\n",
    "\n",
    "    Returns:\n",
    "    - rbo: the Rank-Biased Overlap score\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert lists to numpy arrays if they're not already\n",
    "    list1 = np.asarray(list1)\n",
    "    list2 = np.asarray(list2)\n",
    "\n",
    "    # Get the indices that would sort the arrays in descending order\n",
    "    sorted_indices1 = np.argsort(-list1)\n",
    "    sorted_indices2 = np.argsort(-list2)\n",
    "\n",
    "    # Rank lists based on sorted indices\n",
    "    ranked_list1 = sorted_indices1\n",
    "    ranked_list2 = sorted_indices2\n",
    "\n",
    "    # Initialize the overlap\n",
    "    overlap = 0.0\n",
    "    min_len = min(len(ranked_list1), len(ranked_list2))\n",
    "    \n",
    "    # Compute the RBO\n",
    "    for i in range(min_len):\n",
    "        # Calculate the overlap at rank i\n",
    "        rank_i_overlap = len(set(ranked_list1[:i+1]) & set(ranked_list2[:i+1]))\n",
    "        \n",
    "        # Add the discounted overlap to the total\n",
    "        overlap += (rank_i_overlap / (i + 1)) * (p ** (i + 1))\n",
    "    \n",
    "    # Normalize the score\n",
    "    normalization = (1 - p) / (1 - p ** (min_len + 1))\n",
    "    rbo = overlap * normalization\n",
    "    \n",
    "    return rbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset\n",
    "rbo = []\n",
    "for i in range(data.shape[0]):\n",
    "        rbo.append(rank_biased_overlap(new_support_train[i], data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(rbo).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test\n",
    "rbo = []\n",
    "for i in range(data.shape[0]):\n",
    "        rbo.append(rank_biased_overlap(new_support_test[i], data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(rbo).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi_train = AloRFPlusMDI(rf_plus_base, evaluate_on=\"oob\")\n",
    "rf_plus_mdi_test = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "local_fi_score_train = np.abs(rf_plus_mdi_train.explain_subtract_intercept(X=X_train, y=y_train))\n",
    "local_fi_score_test = np.abs(rf_plus_mdi_test.explain_subtract_intercept(X=X_test, y=None))\n",
    "local_fi_score_test_subset = np.abs(rf_plus_mdi_test.explain_subtract_intercept(X=X_test_subset, y=None))\n",
    "local_fi_score_train_subset = local_fi_score_train[indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_support_train = np.abs(X_train_subset)\n",
    "new_support_test = np.abs(X_test)\n",
    "new_support_train[:, -5:] = 0\n",
    "new_support_test[:, -5:] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset\n",
    "rbo = []\n",
    "for i in range(data.shape[0]):\n",
    "        rbo.append(rank_biased_overlap(new_support_train[i], data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(rbo).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test\n",
    "rbo_lst = []\n",
    "for i in range(data.shape[0]):\n",
    "        rbo_lst.append(rbo.RankingSimilarity(new_support_test[i], data[i]).rbo())#rbo.append(rank_biased_overlap(new_support_test[i], data[i]))\n",
    "print(\"Treeshap Trainsubset\")\n",
    "print(np.array(rbo).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_support_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbo.RankingSimilarity(S, T).rbo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi_train = AloRFPlusMDI(rf_plus_base, evaluate_on=\"oob\")\n",
    "rf_plus_mdi_test = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "local_fi_score_train = np.abs(rf_plus_mdi_train.explain(X=X_train, y=y_train)[1])\n",
    "local_fi_score_test = np.abs(rf_plus_mdi_test.explain(X=X_test, y=None)[1])\n",
    "local_fi_score_test_subset = np.abs(rf_plus_mdi_test.explain(X=X_test_subset, y=None)[1])\n",
    "local_fi_score_train_subset = local_fi_score_train[indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_train_subset \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = local_fi_score_test \n",
    "auroc = []\n",
    "auprc = []\n",
    "for i in range(data.shape[0]):\n",
    "        auroc.append(roc_auc_score(support, data[i]))\n",
    "        auprc.append(average_precision_score(support, data[i]))\n",
    "print(np.array(auroc).mean())\n",
    "print(np.array(auprc).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
