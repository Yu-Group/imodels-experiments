{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV, ElasticNet\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import RandomForestPlusRegressor, RandomForestPlusClassifier\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"..\")\n",
    "sys.path.append(\"../..\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Bins whose width\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "import openml\n",
    "import shap\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import *\n",
    "from sklearn.base import RegressorMixin, ClassifierMixin\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn\n",
    "from scripts.competing_methods_local import *\n",
    "from scripts.simulations_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test MOE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_splitting_strategy(X: np.ndarray,\n",
    "                             y: np.ndarray,\n",
    "                             splitting_strategy: str,\n",
    "                             split_seed: str):\n",
    "    if splitting_strategy in {'train-test-lowdata', 'train-tune-test-lowdata'}:\n",
    "        test_size = 0.90\n",
    "    elif splitting_strategy == \"train-test\":\n",
    "        test_size = 0.33\n",
    "    else:\n",
    "        test_size = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=split_seed)\n",
    "    X_tune = None\n",
    "    y_tune = None\n",
    "\n",
    "    if splitting_strategy in {'train-tune-test', 'train-tune-test-lowdata'}:\n",
    "        X_train, X_tune, y_train, y_tune = model_selection.train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=split_seed)\n",
    "\n",
    "    return X_train, X_tune, X_test, y_train, y_tune, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = openml.tasks.get_task(361260) #361260 361259 361253 361254 361242\n",
    "dataset = task.get_dataset()\n",
    "X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")\n",
    "keep_idx = np.random.choice(X.shape[0], 2000, replace=False)\n",
    "X = X[keep_idx, :]\n",
    "y = y[keep_idx]\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 0)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.0min finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  4.5min finished\n"
     ]
    }
   ],
   "source": [
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_default = RandomForestPlusRegressor(rf_model=est)\n",
    "rf_plus_default.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_moe_elasticnet = SklearnRFPlusRegMOE(rfplus_model=rf_plus_elastic, checkpoint_path=\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tempcheckpoints\")\n",
    "# rf_plus_moe_elasticnet.fit(X_train,y_train)\n",
    "\n",
    "# rf_plus_moe_default = SklearnRFPlusRegMOE(rfplus_model=rf_plus_default, checkpoint_path=\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tempcheckpoints\")\n",
    "# rf_plus_moe_default.fit(X_train,y_train)\n",
    "\n",
    "# rf_plus_moe_default_loo = SklearnRFPlusRegMOE(rfplus_model=rf_plus_default, checkpoint_path=\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tempcheckpoints\", use_loo=True)\n",
    "# rf_plus_moe_default_loo.fit(X_train,y_train)\n",
    "\n",
    "est_r2 = r2_score(y_test, est.predict(X_test))\n",
    "rf_plus_elastic_r2 = r2_score(y_test, rf_plus_elastic.predict(X_test))\n",
    "rf_plus_default_r2 = r2_score(y_test, rf_plus_default.predict(X_test))\n",
    "# rf_plus_moe_elasticnet_r2 = r2_score(y_test, rf_plus_moe_elasticnet.predict(X_test))\n",
    "# rf_plus_moe_default_r2 = r2_score(y_test, rf_plus_moe_default.predict(X_test))\n",
    "# rf_plus_moe_default_loo_r2 = r2_score(y_test, rf_plus_moe_default_loo.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8392554548518385 0.45922955936080434 0.8652551201070563\n"
     ]
    }
   ],
   "source": [
    "print(est_r2, rf_plus_elastic_r2, rf_plus_default_r2)#, rf_plus_moe_elasticnet_r2, rf_plus_moe_default_r2, rf_plus_moe_default_loo_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184.94850081751116\n"
     ]
    }
   ],
   "source": [
    "alpha_elastic = []\n",
    "for i in range(100):\n",
    "    alpha_elastic.append(rf_plus_elastic.estimators_[i].alpha_)\n",
    "alpha_elastic = np.array(alpha_elastic)\n",
    "print(alpha_elastic.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112.94685509618063\n"
     ]
    }
   ],
   "source": [
    "alpha_loo = []\n",
    "for i in range(100):\n",
    "    alpha_loo.append(rf_plus_default.estimators_[i].alpha_)\n",
    "alpha_loo = np.array(alpha_loo)\n",
    "print(alpha_loo.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train=X_train, y_train=y_train, X_test=X_test, fit=rf_plus_elastic, mode=\"absolute\")\n",
    "LFI_evaluation_MDIRFPlus_all_ranking_default_retrain(X_train=X_train, y_train=y_train, X_test=X_test, fit=rf_plus_default, mode=\"absolute\")\n",
    "LFI_evaluation_MDIRFPlus_all_ranking_moe_retrain(X_train=X_train, y_train=y_train, X_test=X_test, fit=rf_plus_moe_elasticnet, mode=\"absolute\")\n",
    "LFI_evaluation_MDIRFPlus_all_ranking_moe_retrain(X_train=X_train, y_train=y_train, X_test=X_test, fit=rf_plus_moe_default, mode=\"absolute\")\n",
    "LFI_evaluation_MDIRFPlus_all_ranking_moe_default_retrain(X_train=X_train, y_train=y_train, X_test=X_test, fit=rf_plus_moe_default_loo, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_splitting_strategy(X: np.ndarray,\n",
    "                             y: np.ndarray,\n",
    "                             splitting_strategy: str,\n",
    "                             split_seed: str):\n",
    "    if splitting_strategy in {'train-test-lowdata', 'train-tune-test-lowdata'}:\n",
    "        test_size = 0.90\n",
    "    elif splitting_strategy == \"train-test\":\n",
    "        test_size = 0.33\n",
    "    else:\n",
    "        test_size = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=split_seed)\n",
    "    X_tune = None\n",
    "    y_tune = None\n",
    "\n",
    "    if splitting_strategy in {'train-tune-test', 'train-tune-test-lowdata'}:\n",
    "        X_train, X_tune, y_train, y_tune = model_selection.train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=split_seed)\n",
    "\n",
    "    return X_train, X_tune, X_test, y_train, y_tune, y_test\n",
    "\n",
    "def mask_unimportant_features(X, sorted_feature, mask, mask_values):\n",
    "    array = copy.deepcopy(X)\n",
    "    num_features = array.shape[1]\n",
    "    num_masked = int(np.ceil(num_features * mask))\n",
    "    selected_indices = sorted_feature[:, num_masked:]\n",
    "    for row_idx in range(array.shape[0]):\n",
    "        for col_idx in selected_indices[row_idx]:\n",
    "            if isinstance(mask_values[col_idx], (int, float, np.integer, np.floating)):\n",
    "                array[row_idx, col_idx] = mask_values[col_idx]\n",
    "            else:\n",
    "                unique_vals = mask_values[col_idx]\n",
    "                array[row_idx, col_idx] = unique_vals[1] if array[row_idx, col_idx] == unique_vals[0] else unique_vals[0] \n",
    "    \n",
    "    return num_masked, array\n",
    "\n",
    "def LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    assert isinstance(fit, RandomForestPlusRegressor) or isinstance(fit, RandomForestPlusClassifier)\n",
    "    rf_plus_mdi = RFPlusMDI(fit, mode = 'only_k', evaluate_on=\"all\")\n",
    "    local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "    local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test\n",
    "\n",
    "def tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Compute average treeshap value across observations.\n",
    "    Larger absolute values indicate more important features.\n",
    "    :param X: design matrix\n",
    "    :param y: response\n",
    "    :param fit: fitted model of interest (tree-based)\n",
    "    :return: dataframe of shape: (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(fit)\n",
    "    local_fi_score_train = explainer.shap_values(X_train, check_additivity=False)\n",
    "    local_fi_score_test = explainer.shap_values(X_test, check_additivity=False)\n",
    "    if isinstance(fit, GradientBoostingClassifier):\n",
    "        if mode == \"absolute\":\n",
    "            return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "        else:\n",
    "            return local_fi_score_train, local_fi_score_test\n",
    "    if sklearn.base.is_classifier(fit):\n",
    "        if mode == \"absolute\":\n",
    "            return np.abs(local_fi_score_train[:,:,1]), np.abs(local_fi_score_test[:,:,1])\n",
    "        else:\n",
    "            return local_fi_score_train[:,:,1], local_fi_score_test[:,:,1]\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = openml.tasks.get_task(361260) #361260 361259 361253 361254 361242\n",
    "dataset = task.get_dataset()\n",
    "X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")\n",
    "keep_idx = np.random.choice(X.shape[0], 2000, replace=False)\n",
    "X = X[keep_idx, :]\n",
    "y = y[keep_idx]\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 0)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_default = RandomForestPlusRegressor(rf_model=est)\n",
    "rf_plus_default.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_moe_elasticnet = SklearnRFPlusRegMOE(rfplus_model=rf_plus_elastic)\n",
    "rf_plus_moe_elasticnet.fit(X_train,y_train)\n",
    "\n",
    "rf_plus_moe_default = SklearnRFPlusRegMOE(rfplus_model=rf_plus_default)\n",
    "rf_plus_moe_default.fit(X_train,y_train)\n",
    "\n",
    "rf_plus_moe_default_loo = SklearnRFPlusRegMOE(rfplus_model=rf_plus_default)\n",
    "rf_plus_moe_default_loo.fit(X_train,y_train)\n",
    "\n",
    "est_r2 = r2_score(y_test, est.predict(X_test))\n",
    "rf_plus_elastic_r2 = r2_score(y_test, rf_plus_elastic.predict(X_test))\n",
    "rf_plus_default_r2 = r2_score(y_test, rf_plus_default.predict(X_test))\n",
    "rf_plus_moe_elasticnet_r2 = r2_score(y_test, rf_plus_moe_elasticnet.predict(X_test))\n",
    "rf_plus_moe_default_r2 = r2_score(y_test, rf_plus_moe_default.predict(X_test))\n",
    "rf_plus_moe_default_loo_r2 = r2_score(y_test, rf_plus_moe_default_loo.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_r2 = r2_score(y_test, est.predict(X_test))\n",
    "rf_plus_elastic_r2 = r2_score(y_test, rf_plus_elastic.predict(X_test))\n",
    "rf_plus_default_r2 = r2_score(y_test, rf_plus_default.predict(X_test))\n",
    "rf_plus_moe_elasticnet_r2 = r2_score(y_test, rf_plus_moe_elasticnet.predict(X_test))\n",
    "rf_plus_moe_default_r2 = r2_score(y_test, rf_plus_moe_default.predict(X_test))\n",
    "rf_plus_moe_default_loo_r2 = r2_score(y_test, rf_plus_moe_default_loo.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask_values = {}\n",
    "# for i in range(X_train.shape[1]):\n",
    "#     unique_values = np.unique(X_train[:, i])\n",
    "#     if len(unique_values) > 2:\n",
    "#         mask_values[i] = np.mean(X_train[:, i])\n",
    "#     else:\n",
    "#         mask_values[i] = list(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features=\"sqrt\", random_state=0)\n",
    "# est.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_elastic = RandomForestPlusClassifier(rf_model=est, prediction_model=LogisticRegressionCV(penalty='elasticnet', l1_ratios=[0.1,0.5,0.99], solver = 'saga', cv=3, n_jobs=-1, tol=5e-4, max_iter=2000, random_state=0))\n",
    "# rf_plus_elastic.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=0)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_default = RandomForestPlusRegressor(rf_model=est) #[0.1,0.5,0.99]\n",
    "rf_plus_default.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "rf_plus_ridge = RandomForestPlusRegressor(rf_model=est, prediction_model=RidgeCV())\n",
    "rf_plus_ridge.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_default, mode = 'only_k', evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, alphas=[0.1], l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get R2 for est, rf_plus_elastic, rf_plus_default\n",
    "y_pred = est.predict(X_test)\n",
    "r2_est = r2_score(y_test, y_pred)\n",
    "y_pred = rf_plus_elastic.predict(X_test)\n",
    "r2_rf_plus_elastic = r2_score(y_test, y_pred)\n",
    "y_pred = rf_plus_default.predict(X_test)\n",
    "r2_rf_plus_default = r2_score(y_test, y_pred)\n",
    "y_pred = rf_plus_ridge.predict(X_test)\n",
    "r2_rf_plus_ridge = r2_score(y_test, y_pred)\n",
    "print(r2_est, r2_rf_plus_elastic, r2_rf_plus_default, r2_rf_plus_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imodels.tree.rf_plus.rf_plus.MOE.rfplus_MOE import SklearnRFPlusRegMOE\n",
    "\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=0)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)\n",
    "\n",
    "sklearn_rfplus_moe = SklearnRFPlusRegMOE(rfplus_model=rf_plus_elastic)\n",
    "sklearn_rfplus_moe.fit(X_train,y_train)\n",
    "\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_elastic, mode = 'only_k', evaluate_on=\"all\")\n",
    "local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "local_fi_score_train_moe = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True, moe_weight=sklearn_rfplus_moe.get_weights(X_train))\n",
    "local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)\n",
    "local_fi_score_test_moe = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True, moe_weight=sklearn_rfplus_moe.get_weights(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_rfplus_moe.get_weights(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.expand_dims(sklearn_rfplus_moe.get_weights(X_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_rfplus_moe = SklearnRFPlusRegMOE(rfplus_model=rf_plus_default, use_loo=True)\n",
    "sklearn_rfplus_moe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(local_fi_score_test_moe, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(local_fi_score_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_elastic, mode = 'only_k', evaluate_on=\"all\")\n",
    "local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_moe_weight = np.expand_dims(moe_weight, axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_moe_weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_moe_weight = np.expand_dims(moe_weight, axis=1)  # Shape: (670, 1, 100)\n",
    "\n",
    "# Compute the weighted sum while ignoring NaNs\n",
    "local_fi_score_train = np.nansum(local_fi_score_train * expanded_moe_weight, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are NA in local_fi_score_train\n",
    "np.isnan(local_fi_score_train).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_moe_weight = np.expand_dims(moe_weight, axis=1) \n",
    "np.nansum(expanded_moe_weight, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_moe_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_moe_weight = np.expand_dims(moe_weight, axis=1) \n",
    "# Compute the weighted average along the last axis (-1)\n",
    "local_fi_score_train = np.nansum(local_fi_score_train * expanded_moe_weight, axis=-1) / np.nansum(expanded_moe_weight, axis=-1)\n",
    "\n",
    "# The resulting shape will be (670, 48)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic, mode=\"absolute\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get R2 for est, rf_plus_elastic, sklearn_rfplus_moe\n",
    "y_pred = est.predict(X_test)\n",
    "r2_est = r2_score(y_test, y_pred)\n",
    "y_pred = rf_plus_elastic.predict(X_test)\n",
    "r2_rf_plus_elastic = r2_score(y_test, y_pred)\n",
    "y_pred = sklearn_rfplus_moe.predict(X_test)\n",
    "r2_sklearn_rfplus_moe = r2_score(y_test, y_pred)\n",
    "\n",
    "print(r2_est, r2_rf_plus_elastic, r2_sklearn_rfplus_moe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get AUROC for est, rf_plus_elastic, sklearn_rfplus_moe\n",
    "y_pred = est.predict_proba(X_test)[:,1]\n",
    "print(\"AUROC for RF: \", roc_auc_score(y_test, y_pred))\n",
    "y_pred = rf_plus_elastic.predict_proba(X_test)[:,1]\n",
    "print(\"AUROC for RF+: \", roc_auc_score(y_test, y_pred))\n",
    "y_pred = sklearn_rfplus_moe.predict_proba(X_test)[:,1]\n",
    "print(\"AUROC for RF+MOE: \", roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_rfplus_moe.get_weights(X_test)[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_lmdi, _ = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic, mode=\"absolute\")\n",
    "local_fi_score_train_shap, _ = tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=est, mode=\"absolute\")\n",
    "\n",
    "sorted_feature_train_lmdi = np.argsort(-local_fi_score_train_lmdi)\n",
    "sorted_feature_train_shap = np.argsort(-local_fi_score_train_shap)\n",
    "ablation_models = {\"RF_Classifier\": RandomForestClassifier(random_state=0)}\n",
    "#ablation_models = {\"RF_Regressor\": RandomForestRegressor(random_state=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for mask in mask_ratio:\n",
    "    num_features_masked, X_train_masked = mask_unimportant_features(X_train, sorted_feature_train_lmdi, mask, mask_values)\n",
    "    for a_model in ablation_models:\n",
    "        ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "        y_pred = ablation_models[a_model].predict_proba(X_test)[:, 1]\n",
    "        print(roc_auc_score(y_test, y_pred))\n",
    "        # y_pred = ablation_models[a_model].predict(X_test)\n",
    "        # print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "for mask in mask_ratio:\n",
    "    num_features_masked, X_train_masked = mask_unimportant_features(X_train, sorted_feature_train_shap, mask, mask_values)\n",
    "    for a_model in ablation_models:\n",
    "        ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "        y_pred = ablation_models[a_model].predict_proba(X_test)[:, 1]\n",
    "        print(roc_auc_score(y_test, y_pred))\n",
    "        # y_pred = ablation_models[a_model].predict(X_test)\n",
    "        # print(r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
