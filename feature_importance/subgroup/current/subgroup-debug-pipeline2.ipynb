{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard data science packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# imodels imports\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import \\\n",
    "    RandomForestPlusRegressor, RandomForestPlusClassifier\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import \\\n",
    "    RFPlusMDI, AloRFPlusMDI\n",
    "\n",
    "# functions for subgroup experiments\n",
    "from subgroup_detection import *\n",
    "from subgroup_experiment import *\n",
    "import shap\n",
    "\n",
    "# sklearn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, f1_score, \\\n",
    "    accuracy_score, r2_score, f1_score, log_loss, root_mean_squared_error\n",
    "\n",
    "# pipeline imports\n",
    "from subgroup import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set inputs\n",
    "seed = 5\n",
    "dataids = [361247, 361243, 361242, 361251, 361253, 361260, 361259, 361256, 361254, 361622]\n",
    "dataid = 361617\n",
    "clustertype = \"hierarchical\"\n",
    "standardize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1091322/3355156882.py:2: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  X, y = get_openml_data(dataid, standardize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    9.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  52 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    2.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    4.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2\n",
      "Step 3\n",
      "Step 4\n",
      "Step 5\n",
      "Step 6\n",
      "Step 7\n",
      "Cluster 0 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 46 observations.\n",
      "Cluster 1 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 32 observations.\n",
      "Cluster 2 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 95 observations.\n",
      "Cluster 3 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 82 observations.\n",
      "Cluster 4 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 55 observations.\n",
      "Cluster 5 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 8 observations.\n",
      "Cluster 6 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 30 observations.\n",
      "Cluster 7 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 26 observations.\n",
      "Cluster 8 in variant lasso_l2_signed_nonnormed_noleafavg_rank has 10 observations.\n",
      "Step 8\n",
      "Step 9\n",
      "Cluster 0 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 0.11628180543355045\n",
      "model coef:\n",
      "[-1.22974173e-01 -1.59912510e+11  7.91999974e+10 -2.73711338e+11\n",
      "  2.89916992e-04  9.14573669e-04 -1.76807895e+12  1.88932419e-02]\n",
      "Cluster 1 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 0.056045607091507334\n",
      "model coef:\n",
      "[ 1.12334090e-02 -1.10164620e-02 -2.22433099e-02  6.42496085e-33\n",
      "  0.00000000e+00  3.55583381e-02  2.22138764e-01 -1.25431946e-02]\n",
      "Cluster 2 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 0.24392440398660797\n",
      "model coef:\n",
      "[ 1.16262642e+13  2.32420669e+11  7.71361464e+12  1.59716174e+13\n",
      "  1.62498372e+10  8.05664062e-03  2.23144531e-01 -2.51464844e-02]\n",
      "Cluster 3 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 0.13858139204322678\n",
      "model coef:\n",
      "[-2.26481630e-01  3.61990675e-02  7.30894437e-02 -5.27355937e-16\n",
      "  1.56125113e-17  3.34257771e-02  1.10454907e-01 -2.32625437e-02]\n",
      "Cluster 4 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 0.0792404806256198\n",
      "model coef:\n",
      "[ 1.91560334e+12 -3.19952035e+10  2.78972473e+12  7.64653182e+12\n",
      " -2.19278336e-01  1.96990967e-02  2.80479431e-01 -2.53963470e-02]\n",
      "Cluster 5 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 0.5836482050932429\n",
      "model coef:\n",
      "[ 0.19981527 -0.12630984  0.33367424 -0.28432012  0.         -0.0428721\n",
      "  0.          0.        ]\n",
      "Cluster 6 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 0.3698331396436467\n",
      "model coef:\n",
      "[ 6.64820879e+10  3.53473279e+10  2.72602484e+10  5.64443879e+10\n",
      " -8.96453857e-05 -1.05018616e-02  1.44816105e+11  1.60980225e-03]\n",
      "Cluster 7 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 0.04957384552380952\n",
      "model coef:\n",
      "[-1.35129599e+11 -2.18542290e+11  3.99939026e+10 -2.00611786e+11\n",
      "  1.22070312e-04 -1.19857788e-02  8.02447143e+11 -4.52423096e-02]\n",
      "Cluster 8 in variant lasso_l2_signed_nonnormed_noleafavg_rank has RMSE 43772178280.70682\n",
      "model coef:\n",
      "[ 5.97355416e+11  3.36645305e+11  3.43886893e+10 -3.05175781e-05\n",
      "  0.00000000e+00 -1.83105469e-03  0.00000000e+00  6.66538189e+11]\n"
     ]
    }
   ],
   "source": [
    "# get data\n",
    "X, y = get_openml_data(dataid, standardize)\n",
    "\n",
    "# split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5,\n",
    "                                                    random_state=seed)\n",
    "\n",
    "print(\"Step 1\")\n",
    "\n",
    "# check if task is regression or classification\n",
    "if len(np.unique(y)) == 2:\n",
    "    task = 'classification'\n",
    "else:\n",
    "    task = 'regression'\n",
    "    \n",
    "# fit the prediction models\n",
    "    rf, rf_plus_baseline, rf_plus_ridge, rf_plus_lasso, rf_plus_elastic = \\\n",
    "        fit_models(X_train, y_train, task)\n",
    "\n",
    "print(\"Step 2\")\n",
    "\n",
    "# obtain shap feature importances\n",
    "shap_explainer = shap.TreeExplainer(rf)\n",
    "shap_test_values, shap_test_rankings = get_shap(X_test, shap_explainer,\n",
    "                                                task)\n",
    "\n",
    "print(\"Step 3\")\n",
    "\n",
    "# get lime feature importances\n",
    "lime_test_values, lime_test_rankings = get_lime(X_test, rf, task)\n",
    "\n",
    "print(\"Step 4\")\n",
    "\n",
    "# create list of lmdi variants\n",
    "lmdi_variants = create_lmdi_variant_map()\n",
    "\n",
    "# obtain lmdi feature importances\n",
    "lmdi_explainers = get_lmdi_explainers(rf_plus_baseline, rf_plus_ridge,\n",
    "                                          rf_plus_lasso, rf_plus_elastic,\n",
    "                                          lmdi_variants)\n",
    "\n",
    "print(\"Step 5\")\n",
    "\n",
    "# we don't actually want to use the training values, but for leaf averaging\n",
    "# variants, we need to have the training data to compute the leaf averages\n",
    "lfi_train_values, lfi_train_rankings = get_lmdi(X_train, y_train,\n",
    "                                                lmdi_variants,\n",
    "                                                lmdi_explainers)\n",
    "lfi_test_values, lfi_test_rankings = get_lmdi(X_test, None,\n",
    "                                                lmdi_variants,\n",
    "                                                lmdi_explainers)\n",
    "\n",
    "print(\"Step 6\")\n",
    "\n",
    "# add shap to the dictionaries\n",
    "lfi_test_values[\"shap\"] = shap_test_values\n",
    "lfi_test_rankings[\"shap\"] = shap_test_rankings\n",
    "\n",
    "# add the raw data to the dictionaries as a baseline of comparison\n",
    "lfi_test_values[\"rawdata\"] = X_test\n",
    "\n",
    "# add lime to the dictionaries\n",
    "lfi_test_values[\"lime\"] = lime_test_values\n",
    "    \n",
    "# get the clusterings - while we are not doing this on the training values,\n",
    "# the get_train_clusters function still does what we want it to.\n",
    "clusters = get_train_clusters(lfi_test_values, clustertype)\n",
    "\n",
    "print(\"Step 7\")\n",
    "\n",
    "# for each cluster, assign half of the indices to the \"fitting\" set and\n",
    "# the other half to the \"evaluation\" set\n",
    "fitting_clusters = {}\n",
    "evaluation_clusters = {}\n",
    "for variant, nclust_map in clusters.items():\n",
    "    fitting_nclust_to_c = {}\n",
    "    evaluation_nclust_to_c = {}\n",
    "    for nclust, cluster_map in nclust_map.items():\n",
    "        fitting_c_to_idxs = {}\n",
    "        evaluation_c_to_idxs = {}\n",
    "        for c, idxs in cluster_map.items():\n",
    "            if nclust == 9 and variant == \"lasso_l2_signed_nonnormed_noleafavg_rank\":\n",
    "                print(f\"Cluster {c} in variant {variant} has {len(idxs)} \" + \\\n",
    "                    \"observations.\")\n",
    "            if len(idxs) < 3:\n",
    "                print(f\"For {nclust} clusters, cluster #{c} in \" + \\\n",
    "                    f\"variant {variant} has fewer than 3 observations.\")\n",
    "                # # warning message that the cluster is too small\n",
    "                # warnings.warn(f\"For {nclust} clusters, cluster #{c} in \" + \\\n",
    "                #     f\"variant {variant} has fewer than 3 observations.\",\n",
    "                #     Warning)\n",
    "                # continue\n",
    "            # shuffle the indices and split them in half\n",
    "            np.random.seed(1)\n",
    "            np.random.shuffle(idxs)\n",
    "            half = len(idxs) // 2\n",
    "            fitting_c_to_idxs[c] = idxs[half:]\n",
    "            evaluation_c_to_idxs[c] = idxs[:half]\n",
    "        fitting_nclust_to_c[nclust] = fitting_c_to_idxs\n",
    "        evaluation_nclust_to_c[nclust] = evaluation_c_to_idxs\n",
    "    fitting_clusters[variant] = fitting_nclust_to_c\n",
    "    evaluation_clusters[variant] = evaluation_nclust_to_c\n",
    "    \n",
    "print(\"Step 8\")\n",
    "    \n",
    "# obtain dataframes X_fit, y_fit, X_eval, y_eval\n",
    "# X_fit = []\n",
    "# y_fit = []\n",
    "# X_eval = []\n",
    "# y_eval = []\n",
    "# for variant, nclust_map in fitting_clusters.items():\n",
    "#     for nclust, cluster_map in nclust_map.items():\n",
    "#         for c, idxs in cluster_map.items():\n",
    "#             X_fit.append(X_test[idxs])\n",
    "#             y_fit.append(y_test[idxs])\n",
    "# for variant, nclust_map in evaluation_clusters.items():\n",
    "#     for nclust, cluster_map in nclust_map.items():\n",
    "#         for c, idxs in cluster_map.items():\n",
    "#             X_eval.append(X_test[idxs])\n",
    "#             y_eval.append(y_test[idxs])\n",
    "# X_fit = np.vstack(X_fit)\n",
    "# y_fit = np.hstack(y_fit)\n",
    "# X_eval = np.vstack(X_eval)\n",
    "# y_eval = np.hstack(y_eval)\n",
    "\n",
    "# print(\"X_fit shape\", X_fit.shape)\n",
    "# print(\"X_eval shape\", X_eval.shape)\n",
    "\n",
    "print(\"Step 9\")\n",
    "    \n",
    "# compute the performance - we are using test data for both, not an error\n",
    "metrics_to_scores = compute_performance(X_test, X_test, y_test, y_test,\n",
    "                                        fitting_clusters,\n",
    "                                        evaluation_clusters, task)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: 0.22644940353139587,\n",
       " 3: 0.16843560066612098,\n",
       " 4: 0.168237575339965,\n",
       " 5: 0.1644902141996583,\n",
       " 6: 0.1727456979236419,\n",
       " 7: 0.17394522700718568,\n",
       " 8: 0.17470725839037096,\n",
       " 9: 1145868541.5440714,\n",
       " 10: 1145868541.5421774}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_to_scores[\"rmse\"][\"lasso_l2_signed_nonnormed_noleafavg_rank\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {2: 0.22644940353139587,\n",
    "#  3: 0.19826779591905566,\n",
    "#  4: 0.1953203953041628,\n",
    "#  5: 0.18712289629518433,\n",
    "#  6: 0.1799813913000766,\n",
    "#  7: 0.18342879068896262,\n",
    "#  8: 0.17688507989749783,\n",
    "#  9: 0.18064867586887284,\n",
    "#  10: 0.1718511382385029}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
