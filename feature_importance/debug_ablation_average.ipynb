{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import RandomForestPlusRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, mean_squared_error, r2_score\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import openml\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "sys.path.append('.')\n",
    "sys.path.append('./scripts')\n",
    "from competing_methods_local import *\n",
    "from simulations_util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_real_data_X(source=\"uci\", data_id=189)\n",
    "y = sample_real_data_y(source=\"uci\", data_id=189, return_support=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    9.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   33.2s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=rf)\n",
    "rf_plus_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = LFI_evaluation_RFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_base, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13.16, 14.13,  5.62, 14.16,  9.41,  7.43,  6.22,  5.52,  7.24,\n",
       "        4.43,  5.65,  7.56,  4.37,  4.72,  9.56, 15.22, 11.59, 13.48,\n",
       "       11.53])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[15, 3, 1]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(-1*train_data[0])[:3].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example NumPy array\n",
    "data = LFI_evaluation_RFPlus_all_ranking_retrain(X_train, y_train, fit=rf_plus_base, mode=\"absolute\")\n",
    "data = np.argsort(data, axis=1)  # Sort the indices of the features\n",
    "\n",
    "# Adjust the figure size\n",
    "plt.figure(figsize=(12, 6))  # Width = 12 inches, Height = 6 inches\n",
    "plt.imshow(data, cmap='viridis', interpolation='nearest', aspect='auto')\n",
    "plt.colorbar()  # Add a color bar to show the scale\n",
    "plt.title(\"Heatmap of NumPy Array\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFI_evaluation_RFPlus_all_l2_norm_ranking_retrain(X_train, y_train, fit=rf_plus_base, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "temp1 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "temp_10 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, leaf_average=True)\n",
    "temp2 = rf_plus_mdi.explain_linear_partial_error_metric(X=X_train, y=y_train)\n",
    "temp3 = rf_plus_mdi.explain_linear_partial_error_metric(X=X_train, y=y_train, leaf_average=True)\n",
    "temp4 = rf_plus_mdi.explain_linear_partial_error_metric(X=X_train, y=y_train, ranking=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "leaf_indices = rf.apply(X_train).flatten()\n",
    "leaf_mapping = defaultdict(list)\n",
    "for sample_idx, leaf_idx in enumerate(leaf_indices):\n",
    "    leaf_mapping[leaf_idx].append(sample_idx)\n",
    "leaf_mapping[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3[148]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp3[82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train[0] - rf_plus_base.predict(X_train[0].reshape(1, -1)) + temp1[0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = (temp - y_train[:, np.newaxis, np.newaxis])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[:, np.newaxis, np.newaxis].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(0.1676066)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base = RandomForestPlusRegressor(rf_model=rf)\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "rf_plus_base.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "parkinsons_telemonitoring = fetch_ucirepo(id=189) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = parkinsons_telemonitoring.data.features \n",
    "y = parkinsons_telemonitoring.data.targets \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "numerical_cols = X.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "# Step 2: Handle missing values (if any)\n",
    "# Check if there are missing values in the numerical columns\n",
    "if X[numerical_cols].isnull().any().any():\n",
    "    # Impute missing values in numerical columns with the mean\n",
    "    num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "    X[numerical_cols] = num_imputer.fit_transform(X[numerical_cols])\n",
    "\n",
    "# Check if there are missing values in the categorical columns\n",
    "if len(categorical_cols) > 0 and X[categorical_cols].isnull().any().any():\n",
    "    # Convert categorical columns to string to ensure consistent types\n",
    "    X[categorical_cols] = X[categorical_cols].astype(str)\n",
    "\n",
    "    # Impute missing values in categorical columns with the most frequent value\n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    X[categorical_cols] = cat_imputer.fit_transform(X[categorical_cols])\n",
    "\n",
    "# Step 3: Encode categorical variables using OneHotEncoder (if any categorical columns)\n",
    "if len(categorical_cols) > 0:\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    X_categorical = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "    # Convert encoded categorical data back to DataFrame\n",
    "    X_categorical_df = pd.DataFrame(\n",
    "        X_categorical,\n",
    "        columns=encoder.get_feature_names_out(categorical_cols),\n",
    "        index=X.index\n",
    "    )\n",
    "\n",
    "    # Step 4: Concatenate numerical columns and the encoded categorical DataFrame\n",
    "    X = pd.concat([X[numerical_cols], X_categorical_df], axis=1)\n",
    "else:\n",
    "    # If no categorical columns, we just use the numerical columns\n",
    "    X = X[numerical_cols]\n",
    "X = X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y.to_numpy().shape[1] > 1:\n",
    "    y = y.iloc[:, 0].to_numpy().flatten()\n",
    "else:\n",
    "    y = y.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=5)\n",
    "rf.fit(X, y)\n",
    "rf.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base = RandomForestPlusRegressor(rf_model=rf)\n",
    "rf_plus_base.fit(X, y)\n",
    "rf_plus_base.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y, _ = imodels.get_clean_dataset(\"diabetes\")\n",
    "X, y, _ = imodels.get_clean_dataset(\"diabetes_regr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Debug\n",
    "# RF Regressor\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "# RFplus default(fit on all)\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=est)\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "temp = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0,0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score([y_train[0]]*100, temp[1,1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # RF Regressor\n",
    "# est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "# est.fit(X_train, y_train)\n",
    "\n",
    "# # RFplus default(fit on all)\n",
    "# rf_plus_base = RandomForestPlusRegressor(rf_model=est)\n",
    "# rf_plus_base.fit(X_train, y_train)\n",
    "\n",
    "# # RFplus oob \n",
    "# rf_plus_base_oob = RandomForestPlusRegressor(rf_model=est, fit_on=\"oob\")\n",
    "# rf_plus_base_oob.fit(X_train, y_train)\n",
    "\n",
    "# #RFplus inbag RF\n",
    "# rf_plus_base_inbag = RandomForestPlusRegressor(rf_model=est, include_raw=False, fit_on=\"inbag\", prediction_model=LinearRegression())\n",
    "# rf_plus_base_inbag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF Classifier\n",
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=3, max_features='sqrt', random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "# RFplus default(fit on all)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=est)\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "\n",
    "# RFplus oob \n",
    "rf_plus_base_oob = RandomForestPlusClassifier(rf_model=est, fit_on=\"oob\")\n",
    "rf_plus_base_oob.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_base_inbag = RandomForestPlusClassifier(rf_model=est, include_raw=False, fit_on=\"inbag\")\n",
    "rf_plus_base_inbag.fit(X_train, y_train)\n",
    "\n",
    "# #RFplus inbag RF\n",
    "# est_regressor = RandomForestRegressor(n_estimators=100, min_samples_leaf=3, max_features='sqrt', random_state=42)\n",
    "# est_regressor.fit(X_train, y_train)\n",
    "# rf_plus_base_inbag = RandomForestPlusRegressor(rf_model=est_regressor, include_raw=False, fit_on=\"inbag\", prediction_model=LinearRegression())\n",
    "# rf_plus_base_inbag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inbag LMDI+\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "\n",
    "# OOB LMDI+\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"oob\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "\n",
    "# ALL LMDI+\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "\n",
    "# Inbag LMDI+ l2 norm with sign\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True)\n",
    "\n",
    "# OOB LMDI+ l2 norm with sign\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"oob\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True)\n",
    "\n",
    "# ALL LMDI+ l2 norm with sign\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True)\n",
    "\n",
    "# Inbag LMDI+ l2 norm without sign\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=False)\n",
    "\n",
    "# OOB LMDI+ l2 norm without sign\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"oob\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=False)\n",
    "\n",
    "# ALL LMDI+ l2 norm without sign\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=False)\n",
    "\n",
    "# Inbag LMDI+ with ranking then average\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "\n",
    "# OOB LMDI+ with ranking then average\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"oob\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "\n",
    "# ALL LMDI+ with ranking then average\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inbag LMDI+ l2 norm with sign\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True)\n",
    "\n",
    "# OOB LMDI+ l2 norm with sign\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"oob\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True)\n",
    "\n",
    "# ALL LMDI+ l2 norm with sign\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inbag LMDI+ l2 norm without sign\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=False)\n",
    "\n",
    "# OOB LMDI+ l2 norm without sign\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"oob\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=False)\n",
    "\n",
    "# ALL LMDI+ l2 norm without sign\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inbag LMDI+ with ranking then average\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "\n",
    "# OOB LMDI+ with ranking then average\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"oob\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "\n",
    "# ALL LMDI+ with ranking then average\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base_oob, evaluate_on=\"oob\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, l2norm=True, sign=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF Classifier\n",
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=3, max_features='sqrt', random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "# RFplus default(fit on all)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=est)\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "\n",
    "# RFplus oob \n",
    "rf_plus_base_oob = RandomForestPlusClassifier(rf_model=est, fit_on=\"oob\")\n",
    "rf_plus_base_oob.fit(X_train, y_train)\n",
    "\n",
    "#RFplus inbag RF\n",
    "est_regressor = RandomForestRegressor(n_estimators=100, min_samples_leaf=3, max_features='sqrt', random_state=42)\n",
    "est_regressor.fit(X_train, y_train)\n",
    "rf_plus_base_inbag = RandomForestPlusRegressor(rf_model=est_regressor, include_raw=False, fit_on=\"inbag\", prediction_model=LinearRegression())\n",
    "rf_plus_base_inbag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred = est.predict(X_test)\n",
    "print(\"R2 score of RF: \", r2_score(y_test, X_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pred = rf_plus_base.predict(X_test)\n",
    "print(\"R2 score of RF+: \", r2_score(y_test, X_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if X_train.shape[0] > 100:\n",
    "    indices_train = np.random.choice(X_train.shape[0], 100, replace=False)\n",
    "    X_train_subset = X_train[indices_train]\n",
    "    y_train_subset = y_train[indices_train]\n",
    "else:\n",
    "    indices_train = np.arange(X_train.shape[0])\n",
    "    X_train_subset = X_train\n",
    "    y_train_subset = y_train\n",
    "\n",
    "if X_test.shape[0] > 100:\n",
    "    indices_test = np.random.choice(X_test.shape[0], 100, replace=False)\n",
    "    X_test_subset = X_test[indices_test]\n",
    "    y_test_subset = y_test[indices_test]\n",
    "else:\n",
    "    indices_test = np.arange(X_test.shape[0])\n",
    "    X_test_subset = X_test\n",
    "    y_test_subset = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"oob\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi.explain(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rf_plus_mdi.explain(X=X_train, y=y_train)[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = np.abs(temp)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(-1*temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(np.argsort(-1*temp), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi.explain(X=X_train, y=y_train)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base.estimators_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeshap_fi, _, _, _ = tree_shap_evaluation_RF(X_train, y_train, X_train_subset, y_train_subset, X_test, y_test, X_test_subset, y_test_subset, fit=est, mode=\"absolute\", train_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_fi, _, _, _ = LFI_evaluation_RFPlus_oob_l2_norm_sign(X_train, y_train, X_train_subset, y_train_subset, X_test, y_test, X_test_subset, y_test_subset,  fit=rf_plus_base, mode=\"absolute\", train_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_features(array, sorted_indices, percentage):\n",
    "    array = copy.deepcopy(array)\n",
    "    num_features = array.shape[1]\n",
    "    num_selected = int(np.ceil(num_features * percentage))\n",
    "    selected_indices = sorted_indices[:num_selected]\n",
    "    selected_array = array[:, selected_indices]\n",
    "    return num_selected, selected_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = [0.05, 0.1, 0.25, 0.5, 0.9]\n",
    "metric_results_shap_mse = []\n",
    "metric_results_shap_r2 = []\n",
    "train_fi_mean = np.mean(treeshap_fi, axis=0)\n",
    "sorted_feature = np.argsort(-train_fi_mean)\n",
    "for mask in mask_ratio:\n",
    "    print(X_train.shape)\n",
    "    num_features_masked, X_train_masked = select_top_features(X_train, sorted_feature, mask)\n",
    "    print(X_train_masked.shape)\n",
    "    num_features_masked, X_test_masked = select_top_features(X_test, sorted_feature, mask)\n",
    "    print(X_test_masked.shape)\n",
    "    ablation_models = {\"RF_Regressor\": RandomForestRegressor(n_estimators=100,min_samples_leaf=5,max_features=0.33,random_state=42)}\n",
    "                    #\"Linear\": LinearRegression(),\n",
    "                    #\"XGB_Regressor\": xgb.XGBRegressor(random_state=42),\n",
    "                    # 'Kernel_Ridge': KernelRidge(),\n",
    "                    #\"RF_Plus_Regressor\": RandomForestPlusRegressor(rf_model=RandomForestRegressor(n_estimators=100,min_samples_leaf=5,max_features=0.33,random_state=42))}\n",
    "    # for a_model in ablation_models:\n",
    "    #     ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "    rf = LinearRegression()# RandomForestRegressor(n_estimators=100,min_samples_leaf=5,max_features=0.33,random_state=42)\n",
    "    rf.fit(X_train_masked, y_train)\n",
    "    y_pred = rf.predict(X_test_masked)\n",
    "    metric_results_shap_mse.append(mean_squared_error(y_test, y_pred))\n",
    "    metric_results_shap_r2.append(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_top_features(X_train, sorted_feature, 0.01)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_top_features(X_test, sorted_feature, 0.01)[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.nonzero(np.isin(X_train[0], select_top_features(X_train, sorted_feature, 0.01)[1][0]))[0]\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.nonzero(np.isin(X_test[0], select_top_features(X_test, sorted_feature, 0.01)[1][0]))[0]\n",
    "\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_shap_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metric_results_shap_r2\n",
    "metric_results_shap_r2 = np.array(metric_results_shap_r2).reshape(len(mask_ratio), -1)\n",
    "plt.figure()\n",
    "plt.plot(mask_ratio, metric_results_shap_r2[:, 0], label=\"RF_Regressor\")\n",
    "plt.xlabel(\"Feature Ratio\")\n",
    "plt.ylabel(\"R2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ratio = [0.05, 0.1, 0.25, 0.5, 0.9]\n",
    "metric_results_lmdi_mse = []\n",
    "metric_results_lmdi_r2 = []\n",
    "train_fi_mean = np.mean(local_fi_score_train, axis=0)\n",
    "sorted_feature = np.argsort(-train_fi_mean)\n",
    "for mask in mask_ratio:\n",
    "    print(X_train.shape)\n",
    "    num_features_masked, X_train_masked = select_top_features(X_train, sorted_feature, mask)\n",
    "    print(X_train_masked.shape)\n",
    "    num_features_masked, X_test_masked = select_top_features(X_test, sorted_feature, mask)\n",
    "    print(X_test_masked.shape)\n",
    "    ablation_models = {\"RF_Regressor\": RandomForestRegressor(n_estimators=100,min_samples_leaf=5,max_features=0.33,random_state=42),\n",
    "                    \"Linear\": LinearRegression(),\n",
    "                    \"XGB_Regressor\": xgb.XGBRegressor(random_state=42),\n",
    "                    # 'Kernel_Ridge': KernelRidge(),\n",
    "                    \"RF_Plus_Regressor\": RandomForestPlusRegressor(rf_model=RandomForestRegressor(n_estimators=100,min_samples_leaf=5,max_features=0.33,random_state=42))}\n",
    "    for a_model in ablation_models:\n",
    "        ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "        y_pred = ablation_models[a_model].predict(X_test_masked)\n",
    "        metric_results_lmdi_mse.append(mean_squared_error(y_test, y_pred))\n",
    "        metric_results_lmdi_r2.append(r2_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
