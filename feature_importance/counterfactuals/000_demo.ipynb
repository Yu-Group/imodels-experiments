{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "from os.path import join as oj\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, ElasticNetCV\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import RandomForestPlusRegressor, RandomForestPlusClassifier\n",
    "# sys.path.append(\".\")\n",
    "# sys.path.append(\"..\")\n",
    "# sys.path.append(\"../..\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"Bins whose width\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection\n",
    "import openml\n",
    "import shap\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import *\n",
    "from sklearn.base import RegressorMixin, ClassifierMixin\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_splitting_strategy(X: np.ndarray,\n",
    "                             y: np.ndarray,\n",
    "                             splitting_strategy: str,\n",
    "                             split_seed: str):\n",
    "    if splitting_strategy in {'train-test-lowdata', 'train-tune-test-lowdata'}:\n",
    "        test_size = 0.90\n",
    "    elif splitting_strategy == \"train-test\":\n",
    "        test_size = 0.33\n",
    "    else:\n",
    "        test_size = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=split_seed)\n",
    "    X_tune = None\n",
    "    y_tune = None\n",
    "\n",
    "    if splitting_strategy in {'train-tune-test', 'train-tune-test-lowdata'}:\n",
    "        X_train, X_tune, y_train, y_tune = model_selection.train_test_split(\n",
    "            X_train, y_train, test_size=0.2, random_state=split_seed)\n",
    "\n",
    "    return X_train, X_tune, X_test, y_train, y_tune, y_test\n",
    "\n",
    "def mask_unimportant_features(X, sorted_feature, mask, mask_values):\n",
    "    array = copy.deepcopy(X)\n",
    "    num_features = array.shape[1]\n",
    "    num_masked = int(np.ceil(num_features * mask))\n",
    "    selected_indices = sorted_feature[:, num_masked:]\n",
    "    for row_idx in range(array.shape[0]):\n",
    "        for col_idx in selected_indices[row_idx]:\n",
    "            if isinstance(mask_values[col_idx], (int, float, np.integer, np.floating)):\n",
    "                array[row_idx, col_idx] = mask_values[col_idx]\n",
    "            else:\n",
    "                unique_vals = mask_values[col_idx]\n",
    "                array[row_idx, col_idx] = unique_vals[1] if array[row_idx, col_idx] == unique_vals[0] else unique_vals[0] \n",
    "    \n",
    "    return num_masked, array\n",
    "\n",
    "def LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    assert isinstance(fit, RandomForestPlusRegressor) or isinstance(fit, RandomForestPlusClassifier)\n",
    "    rf_plus_mdi = RFPlusMDI(fit, mode = 'only_k', evaluate_on=\"all\")\n",
    "    local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "    local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test\n",
    "\n",
    "def tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Compute average treeshap value across observations.\n",
    "    Larger absolute values indicate more important features.\n",
    "    :param X: design matrix\n",
    "    :param y: response\n",
    "    :param fit: fitted model of interest (tree-based)\n",
    "    :return: dataframe of shape: (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(fit)\n",
    "    local_fi_score_train = explainer.shap_values(X_train, check_additivity=False)\n",
    "    local_fi_score_test = explainer.shap_values(X_test, check_additivity=False)\n",
    "    if isinstance(fit, GradientBoostingClassifier):\n",
    "        if mode == \"absolute\":\n",
    "            return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "        else:\n",
    "            return local_fi_score_train, local_fi_score_test\n",
    "    if sklearn.base.is_classifier(fit):\n",
    "        if mode == \"absolute\":\n",
    "            return np.abs(local_fi_score_train[:,:,1]), np.abs(local_fi_score_test[:,:,1])\n",
    "        else:\n",
    "            return local_fi_score_train[:,:,1], local_fi_score_test[:,:,1]\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/zachrewolinski/conda/envs/mdi/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/scratch/users/zachrewolinski/conda/envs/mdi/lib/python3.10/site-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
      "/scratch/users/zachrewolinski/conda/envs/mdi/lib/python3.10/site-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return datasets.get_dataset(self.dataset_id)\n",
      "/tmp/ipykernel_3382347/562205791.py:3: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")\n"
     ]
    }
   ],
   "source": [
    "task = openml.tasks.get_task(43)\n",
    "dataset = task.get_dataset()\n",
    "X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")\n",
    "keep_idx = np.random.choice(X.shape[0], 1000, replace=False)\n",
    "X = X[keep_idx, :]\n",
    "y = y[keep_idx]\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 0)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_values = {}\n",
    "for i in range(X_train.shape[1]):\n",
    "    unique_values = np.unique(X_train[:, i])\n",
    "    if len(unique_values) > 2:\n",
    "        mask_values[i] = np.mean(X_train[:, i])\n",
    "    else:\n",
    "        mask_values[i] = list(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "/scratch/users/zachrewolinski/conda/envs/mdi/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/scratch/users/zachrewolinski/conda/envs/mdi/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/scratch/users/zachrewolinski/conda/envs/mdi/lib/python3.10/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  5.8min finished\n"
     ]
    }
   ],
   "source": [
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=1, max_features=\"sqrt\", random_state=0)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_elastic = RandomForestPlusClassifier(rf_model=est, prediction_model=LogisticRegressionCV(penalty='elasticnet', l1_ratios=[0.1,0.5,0.99], solver = 'saga', cv=3, n_jobs=-1, tol=5e-4, max_iter=2000, random_state=0))\n",
    "rf_plus_elastic.fit(X_train, y_train)\n",
    "\n",
    "# est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=0)\n",
    "# est.fit(X_train, y_train)\n",
    "\n",
    "# rf_plus_elastic = RandomForestPlusRegressor(rf_model=est, prediction_model=ElasticNetCV(cv=3, l1_ratio=[0.1,0.5,0.99], max_iter=2000,random_state=0))\n",
    "# rf_plus_elastic.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_lmdi, _ = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_elastic, mode=\"absolute\")\n",
    "local_fi_score_train_shap, _ = tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=est, mode=\"absolute\")\n",
    "\n",
    "sorted_feature_train_lmdi = np.argsort(-local_fi_score_train_lmdi)\n",
    "sorted_feature_train_shap = np.argsort(-local_fi_score_train_shap)\n",
    "ablation_models = {\"RF_Classifier\": RandomForestClassifier(random_state=0)}\n",
    "#ablation_models = {\"RF_Regressor\": RandomForestRegressor(random_state=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9771047307812013\n",
      "0.9859165888577652\n",
      "0.9908574540927483\n",
      "0.9915771864301276\n",
      "0.9830765639589168\n",
      "0.9877840024898847\n",
      "0.9873949579831932\n",
      "0.9934056956115779\n",
      "0.9929193899782135\n",
      "0.9914799253034547\n"
     ]
    }
   ],
   "source": [
    "mask_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "auroc_lmdi = []\n",
    "for mask in mask_ratio:\n",
    "    num_features_masked, X_train_masked = mask_unimportant_features(X_train, sorted_feature_train_lmdi, mask, mask_values)\n",
    "    for a_model in ablation_models:\n",
    "        ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "        y_pred = ablation_models[a_model].predict_proba(X_test)[:, 1]\n",
    "        auroc_lmdi.append(roc_auc_score(y_test, y_pred))\n",
    "        # y_pred = ablation_models[a_model].predict(X_test)\n",
    "        # print(r2_score(y_test, y_pred))\n",
    "auroc_lmdi = np.array(auroc_lmdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9861694677871149\n",
      "0.9784080298786181\n",
      "0.9239612511671333\n",
      "0.9347961406784936\n",
      "0.9627100840336135\n",
      "0.91328197945845\n",
      "0.9708605664488018\n",
      "0.9781551509492685\n",
      "0.9937947401182695\n",
      "0.9914799253034547\n"
     ]
    }
   ],
   "source": [
    "mask_ratio = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "auroc_shap = []\n",
    "for mask in mask_ratio:\n",
    "    num_features_masked, X_train_masked = mask_unimportant_features(X_train, sorted_feature_train_shap, mask, mask_values)\n",
    "    for a_model in ablation_models:\n",
    "        ablation_models[a_model].fit(X_train_masked, y_train)\n",
    "        y_pred = ablation_models[a_model].predict_proba(X_test)[:, 1]\n",
    "        auroc_shap.append(roc_auc_score(y_test, y_pred))\n",
    "        # print(roc_auc_score(y_test, y_pred))\n",
    "        # y_pred = ablation_models[a_model].predict(X_test)\n",
    "        # print(r2_score(y_test, y_pred))\n",
    "auroc_shap = np.array(auroc_shap)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
