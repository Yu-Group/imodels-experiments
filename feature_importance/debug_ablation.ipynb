{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import imodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import RandomForestPlusRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, mean_squared_error, r2_score\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import openml\n",
    "import openml\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "sys.path.append('.')\n",
    "sys.path.append('./scripts')\n",
    "from competing_methods_local import *\n",
    "from simulations_util import *\n",
    "from collections import Counter\n",
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2366509/3825509896.py:1: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  X = sample_real_data_X(source=\"openml\", task_id = 361242) #361243\n",
      "/scratch/users/zhongyuan_liang/conda/envs/mdi/lib/python3.10/site-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
      "/scratch/users/zhongyuan_liang/conda/envs/mdi/lib/python3.10/site-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return datasets.get_dataset(self.dataset_id)\n",
      "/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/./scripts/simulations_util.py:62: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, _, _, _ = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")\n",
      "/tmp/ipykernel_2366509/3825509896.py:2: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  y =  sample_real_data_y(source=\"openml\", task_id = 361242)[0]\n",
      "/scratch/users/zhongyuan_liang/conda/envs/mdi/lib/python3.10/site-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
      "/scratch/users/zhongyuan_liang/conda/envs/mdi/lib/python3.10/site-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return datasets.get_dataset(self.dataset_id)\n",
      "/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/./scripts/simulations_util.py:88: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  _, y, _, _ = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")\n"
     ]
    }
   ],
   "source": [
    "X = sample_real_data_X(source=\"openml\", task_id = 361242) #361243\n",
    "y =  sample_real_data_y(source=\"openml\", task_id = 361242)[0]\n",
    "\n",
    "#sample_real_data_y(source=\"openml\", task_id = 361243)[0] #361243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    6.7s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, bootstrap=True, max_features=0.33, random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=est, prediction_model=LinearRegression())\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "# rf_plus_base_inbag = RandomForestPlusRegressor(rf_model=est, include_raw=False, fit_on=\"inbag\", prediction_model=LinearRegression())\n",
    "# rf_plus_base_inbag.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_base, mode = 'only_k', evaluate_on=\"all\")\n",
    "score3 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_base, mode = 'only_k', evaluate_on=\"oob\")\n",
    "score4 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.8 , 63.61, 47.15, ..., 20.76, 28.15, 35.58],\n",
       "       [ 2.27, 55.05, 73.94, ..., 33.03, 32.96, 58.06],\n",
       "       [ 4.87, 54.87, 67.19, ..., 29.03, 15.94, 43.79],\n",
       "       ...,\n",
       "       [ 2.78, 49.87, 67.83, ..., 30.77, 32.88, 47.65],\n",
       "       [ 4.75, 54.46, 72.35, ..., 21.27, 19.01, 40.11],\n",
       "       [ 1.99, 63.04, 72.01, ..., 23.99, 22.33, 36.57]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.91, 59.8 , 53.57, ..., 20.7 , 36.41, 66.85],\n",
       "       [ 0.98, 55.  , 63.37, ..., 25.48, 39.09, 70.29],\n",
       "       [ 1.77, 55.02, 61.59, ..., 25.23, 27.98, 61.68],\n",
       "       ...,\n",
       "       [ 0.73, 53.7 , 59.64, ..., 24.37, 35.3 , 68.92],\n",
       "       [ 0.41, 56.31, 62.17, ..., 21.2 , 32.28, 66.18],\n",
       "       [ 0.66, 59.69, 61.35, ..., 21.83, 33.69, 65.35]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    sort_coef = np.argsort(-1 * np.argsort(np.argsort(np.abs(score3[i]))))\n",
    "    sort_loo_coefficients = np.argsort(-1 * np.argsort(np.argsort(np.abs(score4[i]))))\n",
    "    if np.array_equal(sort_coef[:5], sort_loo_coefficients[:5]):\n",
    "        sum += 1\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, bootstrap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK how many features are used in the random forest\n",
    "# Extract the unique features used in the tree\n",
    "tree = est.estimators_[0]\n",
    "features_used = set(tree.tree_.feature[tree.tree_.feature != -2])\n",
    "print(\"Indices of features used in the tree:\", features_used)\n",
    "print(\"Number of unique features used in the tree:\", len(features_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(est)\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\", mode=\"only_k\")\n",
    "shap_lfi = explainer.shap_values(X_train, check_additivity=False)\n",
    "lmdi_lfi= rf_plus_mdi.explain_linear_partial(X=X_train, y=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Data Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "sample = X_train[sample_index].reshape(1, -1)\n",
    "\n",
    "# Get the single tree\n",
    "tree = est.estimators_[0]\n",
    "\n",
    "# Find features used in the decision path\n",
    "used_features = set()\n",
    "node_indicator = tree.decision_path(sample)\n",
    "feature_index = tree.tree_.feature\n",
    "\n",
    "# Collect features used in the path for the sample\n",
    "path_nodes = node_indicator.indices\n",
    "for node in path_nodes:\n",
    "    if feature_index[node] != -2:  # Ignore leaf nodes\n",
    "        used_features.add(feature_index[node])\n",
    "\n",
    "# Print the feature indices used in the decision path\n",
    "print(\"Features used in the path for X_train[0]:\", sorted(used_features))\n",
    "print(\"Feature names used:\", [f\"feature_{i}\" for i in sorted(used_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_lfi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_lfi[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify whether positive beta*x leads to positive y_hat changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_shap_rank = np.argsort(shap_lfi)\n",
    "neg_lmdi_rank = np.argsort(lmdi_lfi)\n",
    "pos_shap_rank = np.argsort(-shap_lfi)\n",
    "pos_lmdi_rank = np.argsort(-lmdi_lfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(X_train, axis=0)\n",
    "#train_mean = np.zeros(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = est.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = neg_shap_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if shap_lfi[i, indices[i]] < 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_shap_neg = est.predict(data_copy)\n",
    "array = y_pred_train_shap_neg-y_pred_train\n",
    "print(\"sum:\", sum)\n",
    "np.sum(array != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = pos_shap_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if shap_lfi[i, indices[i]] > 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_shap_pos = est.predict(data_copy)\n",
    "array = y_pred_train-y_pred_train_shap_pos\n",
    "print(\"sum:\", sum)\n",
    "np.sum(array != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = neg_lmdi_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if lmdi_lfi[i, indices[i]] < 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_lmdi_neg = est.predict(data_copy)\n",
    "array = y_pred_train_lmdi_neg-y_pred_train\n",
    "print(f\"Sum: {sum}\")\n",
    "np.sum(array != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = pos_lmdi_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if lmdi_lfi[i, indices[i]] > 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "    else:\n",
    "        print(i)\n",
    "y_pred_train_lmdi_pos = est.predict(data_copy)\n",
    "array = y_pred_train-y_pred_train_lmdi_pos\n",
    "print(f\"Sum: {sum}\")\n",
    "np.sum(array != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = pos_shap_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if shap_lfi[i, indices[i]] > 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_shap_pos = est.predict(data_copy)\n",
    "array = y_pred_train-y_pred_train_shap_pos\n",
    "print(\"sum:\", sum)\n",
    "np.sum(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = neg_shap_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if shap_lfi[i, indices[i]] < 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_shap_neg = est.predict(data_copy)\n",
    "array = y_pred_train_shap_neg-y_pred_train\n",
    "print(\"sum:\", sum)\n",
    "np.sum(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = pos_lmdi_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if lmdi_lfi[i, indices[i]] > 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "    else:\n",
    "        print(i)\n",
    "y_pred_train_lmdi_pos = est.predict(data_copy)\n",
    "array = y_pred_train-y_pred_train_lmdi_pos\n",
    "print(f\"Sum: {sum}\")\n",
    "np.sum(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = neg_lmdi_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if lmdi_lfi[i, indices[i]] < 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_lmdi_neg = est.predict(data_copy)\n",
    "array = y_pred_train_lmdi_neg-y_pred_train\n",
    "print(f\"Sum: {sum}\")\n",
    "np.sum(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_lfi[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_lfi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\", mode=\"only_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base_inbag.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi1 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "lfi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi1 = rf_plus_mdi.explain_linear_partial(X=X_train, y=None)\n",
    "lfi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check how many rows in lfi1 have NaN values\n",
    "nan_rows = lfi1[np.isnan(lfi1).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(est)\n",
    "explainer.shap_values(X_train, check_additivity=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.shap_values(X_train, check_additivity=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_train[0]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[5] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.predict(np.array([temp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alo_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\", mode=\"only_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi2 = alo_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "lfi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi1[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi2 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "lfi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42) \n",
    "# data = np.random.randn(1000, 10)\n",
    "# n_groups = 2\n",
    "# group_indicator = np.random.choice(n_groups, size=1000)\n",
    "# y = np.zeros(1000)\n",
    "# coefficients = np.random.randn(n_groups, data.shape[1])\n",
    "# for group in range(n_groups):\n",
    "#     group_mask = group_indicator == group\n",
    "#     selected_features = data[group_mask]\n",
    "#     y[group_mask] = np.dot(selected_features, coefficients[group])\n",
    "# X = np.column_stack((data, group_indicator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y\n",
    "plt.hist(y, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the log transformation to y\n",
    "# y = np.log(y)\n",
    "# plt.hist(y, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y, _ = imodels.get_clean_dataset(\"diabetes_regr\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape)\n",
    "# standardize the data using sklearn's StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "# est.fit(X_train, y_train)\n",
    "# rf_plus_base = RandomForestPlusRegressor(rf_model=est)\n",
    "# rf_plus_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=3, max_features='sqrt', random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=est)\n",
    "rf_plus_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "sys.path.append('.')\n",
    "sys.path.append('./scripts')\n",
    "from competing_methods_local import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = LFI_evaluation_RFPlus_oob(X_train, y_train, X_train, y_train, X_test, y_test, X_test, y_test, fit=rf_plus_base, mode=\"absolute\", train_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_evaluation_RF(X_train, y_train, X_train, y_train, X_test, y_test, X_test, y_test, fit=est, mode=\"absolute\", train_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime = lime_evaluation_RF(X_train, y_train, None, None, X_test, y_test, None, None, fit=est, mode=\"absolute\", train_only=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeshap = tree_shap_evaluation_RF(X_train, y_train, X_train, y_train, X_test, y_test, X_test, y_test, fit=est, mode=\"absolute\", train_only=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi = LFI_evaluation_RFPlus_all(X_train, y_train, X_train, y_train, X_test, y_test, X_test, y_test, fit=rf_plus_base, mode=\"absolute\", train_only=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeshap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = np.mean(treeshap, axis=0)\n",
    "sorted = np.argsort(-column_means)\n",
    "sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_features(array, sorted_indices, percentage):\n",
    "    num_features = array.shape[1]\n",
    "    num_selected = int(np.ceil(num_features * percentage))\n",
    "    selected_indices = sorted_indices[:num_selected]\n",
    "    selected_array = array[:, selected_indices]\n",
    "    return num_selected, selected_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_top_features(X_test, sorted, 0.25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_top_features(X_train, sorted, 0.25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = np.mean(lime, axis=0)\n",
    "np.argsort(-column_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = np.mean(lmdi, axis=0)\n",
    "np.argsort(-column_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train,verbose=False,mode=\"regression\")\n",
    "result = np.zeros((X_train.shape[0], X_train.shape[1]))\n",
    "for i in range(X_train.shape[0]):\n",
    "    exp = explainer.explain_instance(X_train[i,:], est.predict, num_features=X_train.shape[1])\n",
    "    original_feature_importance = exp.as_map()[1]\n",
    "    sorted_feature_importance = sorted(original_feature_importance,key = lambda x: x[0])\n",
    "    for j in range(X_train.shape[1]):\n",
    "        result[i,j] = sorted_feature_importance[j][1] #abs(sorted_feature_importance[j][1])\n",
    "\n",
    "# Convert the array to a DataFrame\n",
    "lime_values = pd.DataFrame(result, columns=[f'Feature_{i}' for i in range(X_train.shape[1])])\n",
    "lime_values = lime_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train,verbose=False,mode=\"regression\")\n",
    "result = np.zeros((X_train.shape[0], X_train.shape[1]))\n",
    "i = 0\n",
    "exp = explainer.explain_instance(X_train[i,:], est.predict, num_features=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_map()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance = sorted(exp.as_map()[1],key = lambda x: x[0])\n",
    "sorted_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(self, X_train,X_test,num_features = 10): #For experiments change based on number of features we are ablating \n",
    "        \n",
    "        # get shape of X_test\n",
    "        if X_test is None: #assume we are explaining training set\n",
    "            X_to_explain = copy.deepcopy(X_train)   \n",
    "            n_samples, num_features = X_train.shape\n",
    "        else: #assume we are explaining test set\n",
    "            X_to_explain = copy.deepcopy(X_test)\n",
    "            n_samples, num_features = X_test.shape\n",
    "        \n",
    "        # create data structure to save scores in\n",
    "        result = np.zeros((n_samples, num_features))\n",
    "        \n",
    "        # initialize the LIME explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(X_train,verbose=False,mode=self.task)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            exp = explainer.explain_instance(X_to_explain[i,:], self.model_pred_func,num_features=num_features)\n",
    "            original_feature_importance = exp.as_map()[1]\n",
    "            sorted_feature_importance = sorted(original_feature_importance,key = lambda x: x[0])\n",
    "            for j in range(num_features):\n",
    "                result[i,j] = sorted_feature_importance[j][1] #abs(sorted_feature_importance[j][1])\n",
    "        \n",
    "        # Convert the array to a DataFrame\n",
    "        lime_values = pd.DataFrame(result, columns=[f'Feature_{i}' for i in range(num_features)])\n",
    "        lime_values = lime_values #abs(lime_values)\n",
    "        \n",
    "        return lime_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "est = KernelRidge()\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': [0.1, 0.01, 0.001, None]\n",
    "}\n",
    "grid_search = GridSearchCV(KernelRidge(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_est = grid_search.best_estimator_\n",
    "y_pred = best_est.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, min_samples_leaf= 3, max_features= 'sqrt', random_state= 42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=rf)\n",
    "rf_plus_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "partial_preds_subtract_intercept = rf_plus_mdi.explain_subtract_intercept(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_preds_subtract_intercept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_preds_subtract_intercept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rf_plus_mdi.explain(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=41, min_samples_leaf=5, max_features=0.33)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf))\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "test_all_mse_rf = mean_squared_error(y_test, rf.predict(X_test))\n",
    "test_all_r2_rf = r2_score(y_test, rf.predict(X_test))\n",
    "test_all_mse_rf_plus = mean_squared_error(y_test, rf_plus_base.predict(X_test))\n",
    "test_all_r2_rf_plus = r2_score(y_test, rf_plus_base.predict(X_test))\n",
    "print(\"Test MSE RF: \", test_all_mse_rf)\n",
    "print(\"Test R2 RF: \", test_all_r2_rf)\n",
    "print(\"Test MSE RF+: \", test_all_mse_rf_plus)\n",
    "print(\"Test R2 RF+: \", test_all_r2_rf_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shap values\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values_train = explainer.shap_values(X_train, check_additivity=True)\n",
    "# shap_values_train = np.abs(shap_values_train)\n",
    "shap_values_test = explainer.shap_values(X_test, check_additivity=True)\n",
    "# shap_values_test = np.abs(shap_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_removal(train_mean, data, feature_importance_rank, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    data_copy[np.arange(data.shape[0]), indices] = train_mean[indices]\n",
    "    return data_copy\n",
    "def ablation_removal_positive(train_mean, data, feature_importance_rank, feature_importance, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    sum = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        if feature_importance[i, indices[i]] > 0:\n",
    "            sum += 1\n",
    "            data_copy[i, indices[i]] = train_mean[indices[i]]\n",
    "    print(\"Remove sum: \", sum)\n",
    "    return data_copy\n",
    "def ablation_removal_negative(train_mean, data, feature_importance_rank, feature_importance, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    sum = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        if feature_importance[i, indices[i]] < 0:\n",
    "            sum += 1\n",
    "            data_copy[i, indices[i]] = train_mean[indices[i]]\n",
    "    print(\"Remove sum: \", sum)\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_models = {\"RF_Regressor\": rf,\n",
    "                    \"Linear\": LinearRegression(),\n",
    "                    \"RF_Plus_Regressor\": rf_plus_base}\n",
    "X_data = X_test\n",
    "y_data = y_test\n",
    "ablation_data=\"test\"\n",
    "ablation_models[\"Linear\"].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether sum to hat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(rf.predict(X_test)) == np.all(np.sum(shap_values_test, axis=1) + explainer.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get localMDI+\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "local_feature_importances_train, a = rf_plus_mdi.explain(X=X_train, y=y_train)\n",
    "local_feature_importances_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf), include_raw=False, fit_on=\"inbag\", prediction_model=Ridge(alpha=1e-6))\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base, evaluate_on=\"inbag\")\n",
    "local_feature_importances_train, _ = rf_plus_mdi.explain(X=X_train, y=y_train)\n",
    "local_feature_importances_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMDI+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data =local_feature_importances_train\n",
    "local_fi_score_data_rank = np.argsort(local_feature_importances_train)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data =local_feature_importances_train\n",
    "local_fi_score_data_rank = np.argsort(-1*local_feature_importances_train)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(local_feature_importances_train))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*local_feature_importances_train)#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*np.random.rand(X_train.shape[0], 10))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_before = metric_results['Linear_train_MSE_before_ablation']\n",
    "r2_before = metric_results['Linear_train_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'Linear_train_MSE_after_ablation_{i}'] for i in range(1, 10)]\n",
    "r2_after = [metric_results[f'Linear_train_R_2_after_ablation_{i}'] for i in range(1, 10)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*shap_values_train)#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_before = metric_results['Linear_train_MSE_before_ablation']\n",
    "r2_before = metric_results['Linear_train_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'Linear_train_MSE_after_ablation_{i}'] for i in range(1, 10)]\n",
    "r2_after = [metric_results[f'Linear_train_R_2_after_ablation_{i}'] for i in range(1, 10)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "var = []\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    # print(differences_per_col)\n",
    "    # print(np.array(differences_per_col).var())\n",
    "    var.append(np.array(differences_per_col).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_results_list_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = X_temp != X_train\n",
    "differences_per_row = np.sum(differences, axis=1)\n",
    "print(differences_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = X_temp != X_train\n",
    "differences_per_col = np.sum(differences, axis=0)\n",
    "print(differences_per_col)\n",
    "print(np.array(differences_per_col).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - y_train.mean())**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - ablation_est.predict(X_train))**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - ablation_est.predict(X_temp))**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_temp, y_train)\n",
    "r2_score(y_train, lm.predict(X_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_-ablation_est.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
