{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import imodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import RandomForestPlusRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, mean_squared_error, r2_score\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import openml\n",
    "import openml\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "sys.path.append('.')\n",
    "sys.path.append('./scripts')\n",
    "from competing_methods_local import *\n",
    "from simulations_util import *\n",
    "from collections import Counter\n",
    "from ucimlrepo import fetch_ucirepo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/zhongyuan_liang/conda/envs/mdi/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3577: FutureWarning: Starting from Version 0.15.0 `download_splits` will default to ``False`` instead of ``True`` and be independent from `download_data`. To disable this message until version 0.15 explicitly set `download_splits` to a bool.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/scratch/users/zhongyuan_liang/conda/envs/mdi/lib/python3.10/site-packages/openml/tasks/functions.py:442: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  dataset = get_dataset(task.dataset_id, *dataset_args, **get_dataset_kwargs)\n",
      "Could not download file from https://openml1.win.tue.nl/datasets/0004/44983/dataset_44983.pq: HTTPConnectionPool(host='openml1.win.tue.nl', port=80): Max retries exceeded with url: /datasets/0004/44983/dataset_44983.pq (Caused by ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))\n",
      "Failed to download parquet, fallback on ARFF.\n",
      "/scratch/users/zhongyuan_liang/conda/envs/mdi/lib/python3.10/site-packages/openml/tasks/task.py:150: FutureWarning: Starting from Version 0.15 `download_data`, `download_qualities`, and `download_features_meta_data` will all be ``False`` instead of ``True`` by default to enable lazy loading. To disable this message until version 0.15 explicitly set `download_data`, `download_qualities`, and `download_features_meta_data` to a bool while calling `get_dataset`.\n",
      "  return datasets.get_dataset(self.dataset_id)\n",
      "Could not download file from https://openml1.win.tue.nl/datasets/0004/44983/dataset_44983.pq: HTTPConnectionPool(host='openml1.win.tue.nl', port=80): Max retries exceeded with url: /datasets/0004/44983/dataset_44983.pq (Caused by ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')))\n",
      "Failed to download parquet, fallback on ARFF.\n",
      "/tmp/ipykernel_2185324/1659974347.py:3: FutureWarning: Support for `dataset_format='array'` will be removed in 0.15,start using `dataset_format='dataframe' to ensure your code will continue to work. You can use the dataframe's `to_numpy` function to continue using numpy arrays.\n",
      "  X, a, b, c = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")\n"
     ]
    }
   ],
   "source": [
    "task = openml.tasks.get_task(361260)\n",
    "dataset = task.get_dataset()\n",
    "X, a, b, c = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13932, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'LND_SQFOOT',\n",
       " 'TOT_LVG_AREA',\n",
       " 'SPEC_FEAT_VAL',\n",
       " 'RAIL_DIST',\n",
       " 'OCEAN_DIST',\n",
       " 'WATER_DIST',\n",
       " 'CNTR_DIST',\n",
       " 'SUBCNTR_DI',\n",
       " 'HWY_DIST',\n",
       " 'age',\n",
       " 'avno60plus',\n",
       " 'month_sold',\n",
       " 'structure_quality']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def apply_splitting_strategy(X: np.ndarray,\n",
    "                             y: np.ndarray,\n",
    "                             splitting_strategy: str,\n",
    "                             split_seed: str):\n",
    "    if splitting_strategy in {'train-test-lowdata', 'train-tune-test-lowdata'}:\n",
    "        test_size = 0.90  # X.shape[0] - X.shape[0] * 0.1\n",
    "    elif splitting_strategy == \"train-test\":\n",
    "        test_size = 0.33\n",
    "    else:\n",
    "        test_size = 0.2\n",
    "\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=test_size, random_state=split_seed)\n",
    "    X_tune = None\n",
    "    y_tune = None\n",
    "\n",
    "\n",
    "    return X_train, X_tune, X_test, y_train, y_tune, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "X = sample_real_data_X(source='openml', task_id=43, sample_row_n=150, seed=1)\n",
    "print(np.sum(np.isnan(X)))\n",
    "# y = linear_model_random_feature(X, beta=1, heritability=0.4, s=5, error_seed=1, feature_seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.90111574e-01, 2.31691875e+00, 4.06950262e-01, 1.00000000e+00,\n",
       "       5.88946936e-01, 1.95323595e-01, 3.85589309e-01, 3.98889926e-01,\n",
       "       2.65639898e-01, 6.37253133e-01, 1.47377429e-01, 8.56447186e-01,\n",
       "       1.98720172e-01, 1.99598486e-01, 3.81931122e-01, 7.26670058e-01,\n",
       "       5.68560463e-01, 4.16324660e-01, 1.84963948e+00, 5.90150700e-01,\n",
       "       1.25367383e+00, 8.42496723e-01, 3.79286465e-01, 1.93728837e-01,\n",
       "       2.04827038e+00, 5.31901094e-01, 1.44054315e+00, 5.67991721e-01,\n",
       "       8.38734719e-01, 2.65895961e-01, 1.75742501e-01, 1.64743788e-01,\n",
       "       3.85275365e-01, 2.99715154e-01, 2.63724848e-01, 5.23057915e-01,\n",
       "       5.06568412e-02, 4.30172286e-01, 2.73554577e-01, 3.79386294e-01,\n",
       "       6.25106910e-01, 3.06825205e-01, 3.92975029e-01, 1.83274439e+00,\n",
       "       4.65049527e-01, 1.42419974e-01, 2.02277796e-01, 6.09163175e-02,\n",
       "       1.95280004e-01, 5.18212848e-02, 3.41071276e-01, 1.90183416e-01,\n",
       "       9.09784895e-02, 2.53233198e+01, 1.24179933e+02, 3.82986062e+02])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.03600000e-01, 4.78533333e-01, 2.28533333e-01, 0.00000000e+00,\n",
       "       2.97800000e-01, 7.44000000e-02, 1.39533333e-01, 1.20400000e-01,\n",
       "       9.63333333e-02, 1.87333333e-01, 4.84000000e-02, 5.17133333e-01,\n",
       "       6.36000000e-02, 3.46666667e-02, 4.88666667e-02, 2.41400000e-01,\n",
       "       1.91000000e-01, 1.47333333e-01, 1.73266667e+00, 1.31466667e-01,\n",
       "       8.17066667e-01, 8.29333333e-02, 7.66666667e-02, 5.22666667e-02,\n",
       "       6.18666667e-01, 1.81600000e-01, 2.57666667e-01, 1.40266667e-01,\n",
       "       1.26933333e-01, 6.99333333e-02, 4.18000000e-02, 3.14666667e-02,\n",
       "       7.66000000e-02, 7.96000000e-02, 9.07333333e-02, 1.37466667e-01,\n",
       "       7.86666667e-03, 9.89333333e-02, 6.84000000e-02, 5.02000000e-02,\n",
       "       1.20133333e-01, 7.36000000e-02, 7.86000000e-02, 3.73466667e-01,\n",
       "       1.08733333e-01, 1.54666667e-02, 2.94000000e-02, 2.23400000e-02,\n",
       "       1.45653333e-01, 1.42333333e-02, 1.99773333e-01, 6.29600000e-02,\n",
       "       1.99666667e-02, 5.63996000e+00, 4.45866667e+01, 2.36420000e+02])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.90111574e-01, 2.31691875e+00, 4.06950262e-01, 0.00000000e+00,\n",
       "       5.88946936e-01, 1.95323595e-01, 3.85589309e-01, 3.98889926e-01,\n",
       "       2.65639898e-01, 6.37253133e-01, 1.47377429e-01, 8.56447186e-01,\n",
       "       1.98720172e-01, 1.99598486e-01, 3.81931122e-01, 7.26670058e-01,\n",
       "       5.68560463e-01, 4.16324660e-01, 1.84963948e+00, 5.90150700e-01,\n",
       "       1.25367383e+00, 8.42496723e-01, 3.79286465e-01, 1.93728837e-01,\n",
       "       2.04827038e+00, 5.31901094e-01, 1.44054315e+00, 5.67991721e-01,\n",
       "       8.38734719e-01, 2.65895961e-01, 1.75742501e-01, 1.64743788e-01,\n",
       "       3.85275365e-01, 2.99715154e-01, 2.63724848e-01, 5.23057915e-01,\n",
       "       5.06568412e-02, 4.30172286e-01, 2.73554577e-01, 3.79386294e-01,\n",
       "       6.25106910e-01, 3.06825205e-01, 3.92975029e-01, 1.83274439e+00,\n",
       "       4.65049527e-01, 1.42419974e-01, 2.02277796e-01, 6.09163175e-02,\n",
       "       1.95280004e-01, 5.18212848e-02, 3.41071276e-01, 1.90183416e-01,\n",
       "       9.09784895e-02, 2.53233198e+01, 1.24179933e+02, 3.82986062e+02])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if NA in X\n",
    "print(np.sum(np.isnan(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 2)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Fitting Models\")\n",
    "# fit RF model\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=1)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_baseline = RandomForestPlusRegressor(rf_model=est,\n",
    "                                             prediction_model=LinearRegression(),\n",
    "                                             fit_on=\"inbag\",\n",
    "                                             include_raw=False)\n",
    "rf_plus_baseline.fit(X_train, y_train, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = est.estimators_[57]\n",
    "tree_rules = export_text(tree)\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    assert isinstance(fit, RandomForestPlusRegressor) or isinstance(fit, RandomForestPlusClassifier)\n",
    "    rf_plus_mdi = RFPlusMDI(fit, mode = 'only_k', evaluate_on=\"all\")\n",
    "    local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "    local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_train, lmdi_test = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_baseline, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_361260.csv')\n",
    "y = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/y_361260.csv')\n",
    "\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 2)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Fitting Models\")\n",
    "# fit RF model\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=1)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_baseline = RandomForestPlusRegressor(rf_model=est,\n",
    "                                             prediction_model=LinearRegression(),\n",
    "                                             fit_on=\"inbag\",\n",
    "                                             include_raw=False)\n",
    "rf_plus_baseline.fit(X_train, y_train, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    assert isinstance(fit, RandomForestPlusRegressor) or isinstance(fit, RandomForestPlusClassifier)\n",
    "    rf_plus_mdi = RFPlusMDI(fit, mode = 'only_k', evaluate_on=\"all\")\n",
    "    local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "    local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test\n",
    "\n",
    "lmdi_train, lmdi_test = LFI_evaluation_MDIRFPlus_all_ranking_retrain(X_train, y_train, X_test, fit=rf_plus_baseline, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(np.abs(rf_plus_baseline.predict(X_train)-est.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = np.load(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tree_X_train_16.npy\")\n",
    "# y_train = np.load(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tree_y_train_16.npy\")\n",
    "# weight = np.load(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tree_sample_weight_16.npy\")\n",
    "# # fit linear model\n",
    "# # lr = LinearRegression()\n",
    "# # lr.fit(X_train, y_train, sample_weight=weight)\n",
    "# print(np.min(weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_361254.csv')\n",
    "y = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/y_361254.csv')\n",
    "\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Fitting Models\")\n",
    "# fit RF model\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=0)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_baseline = RandomForestPlusRegressor(rf_model=est,\n",
    "                                             prediction_model=LinearRegression(),\n",
    "                                             fit_on=\"inbag\",\n",
    "                                             include_raw=False)\n",
    "rf_plus_baseline.fit(X_train, y_train, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_361254.csv')\n",
    "y = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/y_361254.csv')\n",
    "\n",
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 1)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Fitting Models\")\n",
    "# fit RF model\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=0)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_baseline = RandomForestPlusRegressor(rf_model=est,\n",
    "                                             prediction_model=LinearRegression(),\n",
    "                                             fit_on=\"inbag\",\n",
    "                                             include_raw=False)\n",
    "rf_plus_baseline.fit(X_train, y_train, n_jobs=None)\n",
    "assert np.allclose(rf_plus_baseline.predict(X_train),est.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/X_361260.csv')\n",
    "y = pd.read_csv('/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/data_openml/y_361260.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_tune, X_test, y_train, y_tune, y_test = apply_splitting_strategy(X, y, \"train-test\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"Fitting Models\")\n",
    "# fit RF model\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=1)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_inbag = RandomForestPlusRegressor(rf_model=est, include_raw=False, fit_on=\"inbag\", prediction_model=LinearRegression())\n",
    "rf_plus_inbag.fit(X_train, y_train, n_jobs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(rf_plus_inbag.predict(X_test), est.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(rf_plus_inbag.predict(X_test) - est.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(rf_plus_inbag.predict(X_test) - est.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rf_plus_inbag.predict(X_test) - est.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.load(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tree_X_train_2.npy\")\n",
    "y_train = np.load(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tree_y_train_2.npy\")\n",
    "weight = np.load(\"/accounts/projects/binyu/zhongyuan_liang/local_MDI+/imodels-experiments/feature_importance/tree_sample_weight_2.npy\")\n",
    "# fit linear model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train, sample_weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit linear model\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train, sample_weight=weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"tree_X_train dtype:\", X_train.dtype)\n",
    "print(\"tree_y_train dtype:\", y_train.dtype)\n",
    "print(\"tree_sample_weight dtype:\", weight.dtype)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the smallest weight\n",
    "min_weight = np.min(weight)\n",
    "print(\"min weight:\", min_weight)\n",
    "max_weight = np.max(weight)\n",
    "print(\"max weight:\", max_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_16 = est.estimators_[16]\n",
    "# generate inbad indices for tree 16\n",
    "from sklearn.ensemble._forest import _generate_unsampled_indices, _generate_sample_indices\n",
    "unsampled_indices = _generate_unsampled_indices(tree_16.random_state, X_train.shape[0], X_train.shape[0])\n",
    "sample_indices = _generate_sample_indices(tree_16.random_state, X_train.shape[0], X_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_inbag_indices, counts_elements = np.unique(sample_indices, return_counts=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.min(counts_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if X_train is linearly independent\n",
    "print(np.linalg.matrix_rank(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(pd.DataFrame(X_train).corr() - np.eye(X_train.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_41 = est.estimators_[16]\n",
    "n_splits = tree_41.tree_.node_count - tree_41.tree_.n_leaves\n",
    "print(f\"The 41st tree has {n_splits} splits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.abs(pd.DataFrame(X_train).corr() - np.eye(X_train.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get diabetes_regr from imodels\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imodels import get_clean_dataset, HSTreeClassifierCV # import any imodels model here\n",
    "\n",
    "# prepare data (a sample clinical dataset)\n",
    "X, y, feature_names = get_clean_dataset('diabetes_regr')\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_ridge = RandomForestPlusRegressor(rf_model=est, prediction_model=RidgeCV(cv=5))\n",
    "rf_plus_ridge.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_ridge, mode = 'only_k', evaluate_on=\"all\")\n",
    "local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "local_fi_score_train_bootstrap = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, bootstrap=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.argsort(local_fi_score_train_bootstrap) == np.argsort(local_fi_score_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_train_bootstrap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate a random sample of 100 numbers from a normal distribution\n",
    "original_sample = np.random.normal(loc=50, scale=10, size=100)\n",
    "\n",
    "# Bootstrap settings\n",
    "n_bootstraps = 10000\n",
    "bootstrap_means = np.empty(n_bootstraps)\n",
    "\n",
    "# Perform bootstrap resampling\n",
    "for i in range(n_bootstraps):\n",
    "    bootstrap_sample = np.random.choice(original_sample, size=original_sample.size, replace=True)\n",
    "    bootstrap_means[i] = np.mean(bootstrap_sample)\n",
    "\n",
    "# Original sample mean\n",
    "original_sample_mean = np.mean(original_sample)\n",
    "\n",
    "# Mean of bootstrap means\n",
    "mean_of_bootstrap_means = np.mean(bootstrap_means)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(bootstrap_means, bins=30, alpha=0.7, color='blue', label='Bootstrap Means')\n",
    "plt.axvline(x=original_sample_mean, color='red', linestyle='--', label='Original Sample Mean')\n",
    "plt.axvline(x=mean_of_bootstrap_means, color='green', linestyle='-', label='Mean of Bootstrap Means')\n",
    "plt.title('Distribution of Bootstrap Means')\n",
    "plt.xlabel('Means')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Output the means for comparison\n",
    "original_sample_mean, mean_of_bootstrap_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(local_fi_score_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(local_fi_score_train_bootstrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = 361242\n",
    "task = openml.tasks.get_task(task_id)\n",
    "dataset = task.get_dataset()\n",
    "X, _, _, _ = dataset.get_data(target=dataset.default_target_attribute,dataset_format=\"array\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(4307)\n",
    "keep_idx = np.random.choice(X.shape[0], 2000, replace=False)\n",
    "X = X[keep_idx, :]\n",
    "X = (X - X.mean(axis=0)) / X.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_real_data_X(source=\"openml\", task_id = 361242, normalize=True)\n",
    "\n",
    "#sample_real_data_y(source=\"openml\", task_id = 361243)[0] #361243"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = linear_model_random_feature(X, beta=1, heritability=0.2, s=5, error_seed=3, feature_seed=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "\n",
    "rf_plus_lasso = RandomForestPlusRegressor(rf_model=est, prediction_model=LassoCV(cv=5, max_iter=10000, random_state=0))\n",
    "rf_plus_lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_lasso, mode = 'only_k', evaluate_on=\"all\")\n",
    "local_fi_score_train = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking = True)\n",
    "local_fi_score_test = rf_plus_mdi.explain_linear_partial(X=X_test, y=None, ranking = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1_rank.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot np.nanmean(score1_rank[:,2,:],axis=-1)\n",
    "plt.plot(np.nanmean(score1_rank[:,2,:],axis=-1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score1_rank[:,2,:].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot np.nanmean(score1_rank[:,2,:],axis=-1)\n",
    "plt.plot(score1_rank[:,2,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(-1*np.mean(np.nanmean(score1,axis=-1), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(-1*np.mean(np.nanmean(score1_rank,axis=-1), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=None, mode=\"absolute\"):\n",
    "    \"\"\"\n",
    "    Compute average treeshap value across observations.\n",
    "    Larger absolute values indicate more important features.\n",
    "    :param X: design matrix\n",
    "    :param y: response\n",
    "    :param fit: fitted model of interest (tree-based)\n",
    "    :return: dataframe of shape: (n_samples, n_features)\n",
    "    \"\"\"\n",
    "    explainer = shap.TreeExplainer(fit)\n",
    "    local_fi_score_train = explainer.shap_values(X_train, check_additivity=False)\n",
    "    local_fi_score_test = explainer.shap_values(X_test, check_additivity=False)\n",
    "    if sklearn.base.is_classifier(fit):\n",
    "        if mode == \"absolute\":\n",
    "            return np.abs(local_fi_score_train[:,:,1]), np.abs(local_fi_score_test[:,:,1])\n",
    "        else:\n",
    "            return local_fi_score_train[:,:,1], local_fi_score_test[:,:,1]\n",
    "    if mode == \"absolute\":\n",
    "        return np.abs(local_fi_score_train), np.abs(local_fi_score_test)\n",
    "    else:\n",
    "        return local_fi_score_train, local_fi_score_test\n",
    "\n",
    "score2, _ = tree_shap_evaluation_RF_retrain(X_train, y_train, X_test, fit=est, mode=\"absolute\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(-1*np.mean(score1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(-1*np.mean(score2[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest model on features 17, 2, 16\n",
    "est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=1)\n",
    "est.fit(X_train[:,[17,2,16]], y_train)\n",
    "\n",
    "#evalaute the model\n",
    "y_pred = est.predict(X_test[:,[17,2,16]])\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a linear model on X_train and print coefficients\n",
    "est = RidgeCV(cv=5)\n",
    "est.fit(X_train, y_train)\n",
    "est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print correlation of X_train as dataframe\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.DataFrame(X_train).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot score1[:, 2]\n",
    "plt.plot(score1[:, 2])\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(score1[:, 20])\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Feature importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(score1, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a random forest model on features 17, 2, 16\n",
    "est = RandomForestRegressor(random_state=1)\n",
    "est.fit(X_train[:,[2,16,17]], y_train)\n",
    "\n",
    "#evalaute the model\n",
    "y_pred = est.predict(X_test[:,[2,16,17]])\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_base, mode = 'only_k', evaluate_on=\"oob\")\n",
    "score4 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, ranking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    sort_coef = np.argsort(-1 * np.argsort(np.argsort(np.abs(score3[i]))))\n",
    "    sort_loo_coefficients = np.argsort(-1 * np.argsort(np.argsort(np.abs(score4[i]))))\n",
    "    if np.array_equal(sort_coef[:5], sort_loo_coefficients[:5]):\n",
    "        sum += 1\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, bootstrap=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train, bootstrap=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK how many features are used in the random forest\n",
    "# Extract the unique features used in the tree\n",
    "tree = est.estimators_[0]\n",
    "features_used = set(tree.tree_.feature[tree.tree_.feature != -2])\n",
    "print(\"Indices of features used in the tree:\", features_used)\n",
    "print(\"Number of unique features used in the tree:\", len(features_used))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(est)\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\", mode=\"only_k\")\n",
    "shap_lfi = explainer.shap_values(X_train, check_additivity=False)\n",
    "lmdi_lfi= rf_plus_mdi.explain_linear_partial(X=X_train, y=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Data Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "sample = X_train[sample_index].reshape(1, -1)\n",
    "\n",
    "# Get the single tree\n",
    "tree = est.estimators_[0]\n",
    "\n",
    "# Find features used in the decision path\n",
    "used_features = set()\n",
    "node_indicator = tree.decision_path(sample)\n",
    "feature_index = tree.tree_.feature\n",
    "\n",
    "# Collect features used in the path for the sample\n",
    "path_nodes = node_indicator.indices\n",
    "for node in path_nodes:\n",
    "    if feature_index[node] != -2:  # Ignore leaf nodes\n",
    "        used_features.add(feature_index[node])\n",
    "\n",
    "# Print the feature indices used in the decision path\n",
    "print(\"Features used in the path for X_train[0]:\", sorted(used_features))\n",
    "print(\"Feature names used:\", [f\"feature_{i}\" for i in sorted(used_features)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_lfi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_lfi[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify whether positive beta*x leads to positive y_hat changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_shap_rank = np.argsort(shap_lfi)\n",
    "neg_lmdi_rank = np.argsort(lmdi_lfi)\n",
    "pos_shap_rank = np.argsort(-shap_lfi)\n",
    "pos_lmdi_rank = np.argsort(-lmdi_lfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(X_train, axis=0)\n",
    "#train_mean = np.zeros(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = est.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = neg_shap_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if shap_lfi[i, indices[i]] < 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_shap_neg = est.predict(data_copy)\n",
    "array = y_pred_train_shap_neg-y_pred_train\n",
    "print(\"sum:\", sum)\n",
    "np.sum(array != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = pos_shap_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if shap_lfi[i, indices[i]] > 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_shap_pos = est.predict(data_copy)\n",
    "array = y_pred_train-y_pred_train_shap_pos\n",
    "print(\"sum:\", sum)\n",
    "np.sum(array != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = neg_lmdi_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if lmdi_lfi[i, indices[i]] < 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_lmdi_neg = est.predict(data_copy)\n",
    "array = y_pred_train_lmdi_neg-y_pred_train\n",
    "print(f\"Sum: {sum}\")\n",
    "np.sum(array != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = pos_lmdi_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if lmdi_lfi[i, indices[i]] > 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "    else:\n",
    "        print(i)\n",
    "y_pred_train_lmdi_pos = est.predict(data_copy)\n",
    "array = y_pred_train-y_pred_train_lmdi_pos\n",
    "print(f\"Sum: {sum}\")\n",
    "np.sum(array != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = pos_shap_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if shap_lfi[i, indices[i]] > 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_shap_pos = est.predict(data_copy)\n",
    "array = y_pred_train-y_pred_train_shap_pos\n",
    "print(\"sum:\", sum)\n",
    "np.sum(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = neg_shap_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if shap_lfi[i, indices[i]] < 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_shap_neg = est.predict(data_copy)\n",
    "array = y_pred_train_shap_neg-y_pred_train\n",
    "print(\"sum:\", sum)\n",
    "np.sum(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = pos_lmdi_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if lmdi_lfi[i, indices[i]] > 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "    else:\n",
    "        print(i)\n",
    "y_pred_train_lmdi_pos = est.predict(data_copy)\n",
    "array = y_pred_train-y_pred_train_lmdi_pos\n",
    "print(f\"Sum: {sum}\")\n",
    "np.sum(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = X_train.copy()\n",
    "indices = neg_lmdi_rank[:, 0]\n",
    "sum = 0\n",
    "for i in range(X_train.shape[0]):\n",
    "    if lmdi_lfi[i, indices[i]] < 0:\n",
    "        if lmdi_lfi[i, indices[i]] < 0:\n",
    "            data_copy[i, indices[i]] = 9999999\n",
    "        else:\n",
    "            data_copy[i, indices[i]] = -1*9999999\n",
    "        sum += 1\n",
    "y_pred_train_lmdi_neg = est.predict(data_copy)\n",
    "array = y_pred_train_lmdi_neg-y_pred_train\n",
    "print(f\"Sum: {sum}\")\n",
    "np.sum(array > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_lfi[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi_lfi[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = RFPlusMDI(rf_plus_base_inbag, evaluate_on=\"inbag\", mode=\"only_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base_inbag.predict(X_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi1 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "lfi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi1 = rf_plus_mdi.explain_linear_partial(X=X_train, y=None)\n",
    "lfi1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Check how many rows in lfi1 have NaN values\n",
    "nan_rows = lfi1[np.isnan(lfi1).any(axis=1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.TreeExplainer(est)\n",
    "explainer.shap_values(X_train, check_additivity=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.shap_values(X_train, check_additivity=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = X_train[0]\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[5] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est.predict(np.array([temp]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alo_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\", mode=\"only_k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi2 = alo_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "lfi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi1[0].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfi2 = rf_plus_mdi.explain_linear_partial(X=X_train, y=y_train)\n",
    "lfi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42) \n",
    "# data = np.random.randn(1000, 10)\n",
    "# n_groups = 2\n",
    "# group_indicator = np.random.choice(n_groups, size=1000)\n",
    "# y = np.zeros(1000)\n",
    "# coefficients = np.random.randn(n_groups, data.shape[1])\n",
    "# for group in range(n_groups):\n",
    "#     group_mask = group_indicator == group\n",
    "#     selected_features = data[group_mask]\n",
    "#     y[group_mask] = np.dot(selected_features, coefficients[group])\n",
    "# X = np.column_stack((data, group_indicator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot y\n",
    "plt.hist(y, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the log transformation to y\n",
    "# y = np.log(y)\n",
    "# plt.hist(y, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y, _ = imodels.get_clean_dataset(\"diabetes_regr\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape)\n",
    "# standardize the data using sklearn's StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# est = RandomForestRegressor(n_estimators=100, min_samples_leaf=5, max_features=0.33, random_state=42)\n",
    "# est.fit(X_train, y_train)\n",
    "# rf_plus_base = RandomForestPlusRegressor(rf_model=est)\n",
    "# rf_plus_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est = RandomForestClassifier(n_estimators=100, min_samples_leaf=3, max_features='sqrt', random_state=42)\n",
    "est.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=est)\n",
    "rf_plus_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../..')\n",
    "sys.path.append('.')\n",
    "sys.path.append('./scripts')\n",
    "from competing_methods_local import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c,d = LFI_evaluation_RFPlus_oob(X_train, y_train, X_train, y_train, X_test, y_test, X_test, y_test, fit=rf_plus_base, mode=\"absolute\", train_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_evaluation_RF(X_train, y_train, X_train, y_train, X_test, y_test, X_test, y_test, fit=est, mode=\"absolute\", train_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime = lime_evaluation_RF(X_train, y_train, None, None, X_test, y_test, None, None, fit=est, mode=\"absolute\", train_only=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeshap = tree_shap_evaluation_RF(X_train, y_train, X_train, y_train, X_test, y_test, X_test, y_test, fit=est, mode=\"absolute\", train_only=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmdi = LFI_evaluation_RFPlus_all(X_train, y_train, X_train, y_train, X_test, y_test, X_test, y_test, fit=rf_plus_base, mode=\"absolute\", train_only=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treeshap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = np.mean(treeshap, axis=0)\n",
    "sorted = np.argsort(-column_means)\n",
    "sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_top_features(array, sorted_indices, percentage):\n",
    "    num_features = array.shape[1]\n",
    "    num_selected = int(np.ceil(num_features * percentage))\n",
    "    selected_indices = sorted_indices[:num_selected]\n",
    "    selected_array = array[:, selected_indices]\n",
    "    return num_selected, selected_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_top_features(X_test, sorted, 0.25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_top_features(X_train, sorted, 0.25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = np.mean(lime, axis=0)\n",
    "np.argsort(-column_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_means = np.mean(lmdi, axis=0)\n",
    "np.argsort(-column_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train,verbose=False,mode=\"regression\")\n",
    "result = np.zeros((X_train.shape[0], X_train.shape[1]))\n",
    "for i in range(X_train.shape[0]):\n",
    "    exp = explainer.explain_instance(X_train[i,:], est.predict, num_features=X_train.shape[1])\n",
    "    original_feature_importance = exp.as_map()[1]\n",
    "    sorted_feature_importance = sorted(original_feature_importance,key = lambda x: x[0])\n",
    "    for j in range(X_train.shape[1]):\n",
    "        result[i,j] = sorted_feature_importance[j][1] #abs(sorted_feature_importance[j][1])\n",
    "\n",
    "# Convert the array to a DataFrame\n",
    "lime_values = pd.DataFrame(result, columns=[f'Feature_{i}' for i in range(X_train.shape[1])])\n",
    "lime_values = lime_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lime_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train,verbose=False,mode=\"regression\")\n",
    "result = np.zeros((X_train.shape[0], X_train.shape[1]))\n",
    "i = 0\n",
    "exp = explainer.explain_instance(X_train[i,:], est.predict, num_features=X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_map()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance = sorted(exp.as_map()[1],key = lambda x: x[0])\n",
    "sorted_feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_feature_importance[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(self, X_train,X_test,num_features = 10): #For experiments change based on number of features we are ablating \n",
    "        \n",
    "        # get shape of X_test\n",
    "        if X_test is None: #assume we are explaining training set\n",
    "            X_to_explain = copy.deepcopy(X_train)   \n",
    "            n_samples, num_features = X_train.shape\n",
    "        else: #assume we are explaining test set\n",
    "            X_to_explain = copy.deepcopy(X_test)\n",
    "            n_samples, num_features = X_test.shape\n",
    "        \n",
    "        # create data structure to save scores in\n",
    "        result = np.zeros((n_samples, num_features))\n",
    "        \n",
    "        # initialize the LIME explainer\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(X_train,verbose=False,mode=self.task)\n",
    "        \n",
    "        for i in range(n_samples):\n",
    "            exp = explainer.explain_instance(X_to_explain[i,:], self.model_pred_func,num_features=num_features)\n",
    "            original_feature_importance = exp.as_map()[1]\n",
    "            sorted_feature_importance = sorted(original_feature_importance,key = lambda x: x[0])\n",
    "            for j in range(num_features):\n",
    "                result[i,j] = sorted_feature_importance[j][1] #abs(sorted_feature_importance[j][1])\n",
    "        \n",
    "        # Convert the array to a DataFrame\n",
    "        lime_values = pd.DataFrame(result, columns=[f'Feature_{i}' for i in range(num_features)])\n",
    "        lime_values = lime_values #abs(lime_values)\n",
    "        \n",
    "        return lime_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "est = KernelRidge()\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': [0.1, 0.01, 0.001, None]\n",
    "}\n",
    "grid_search = GridSearchCV(KernelRidge(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_est = grid_search.best_estimator_\n",
    "y_pred = best_est.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, min_samples_leaf= 3, max_features= 'sqrt', random_state= 42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=rf)\n",
    "rf_plus_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "partial_preds_subtract_intercept = rf_plus_mdi.explain_subtract_intercept(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_preds_subtract_intercept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_preds_subtract_intercept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rf_plus_mdi.explain(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=41, min_samples_leaf=5, max_features=0.33)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf))\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "test_all_mse_rf = mean_squared_error(y_test, rf.predict(X_test))\n",
    "test_all_r2_rf = r2_score(y_test, rf.predict(X_test))\n",
    "test_all_mse_rf_plus = mean_squared_error(y_test, rf_plus_base.predict(X_test))\n",
    "test_all_r2_rf_plus = r2_score(y_test, rf_plus_base.predict(X_test))\n",
    "print(\"Test MSE RF: \", test_all_mse_rf)\n",
    "print(\"Test R2 RF: \", test_all_r2_rf)\n",
    "print(\"Test MSE RF+: \", test_all_mse_rf_plus)\n",
    "print(\"Test R2 RF+: \", test_all_r2_rf_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shap values\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values_train = explainer.shap_values(X_train, check_additivity=True)\n",
    "# shap_values_train = np.abs(shap_values_train)\n",
    "shap_values_test = explainer.shap_values(X_test, check_additivity=True)\n",
    "# shap_values_test = np.abs(shap_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_removal(train_mean, data, feature_importance_rank, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    data_copy[np.arange(data.shape[0]), indices] = train_mean[indices]\n",
    "    return data_copy\n",
    "def ablation_removal_positive(train_mean, data, feature_importance_rank, feature_importance, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    sum = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        if feature_importance[i, indices[i]] > 0:\n",
    "            sum += 1\n",
    "            data_copy[i, indices[i]] = train_mean[indices[i]]\n",
    "    print(\"Remove sum: \", sum)\n",
    "    return data_copy\n",
    "def ablation_removal_negative(train_mean, data, feature_importance_rank, feature_importance, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    sum = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        if feature_importance[i, indices[i]] < 0:\n",
    "            sum += 1\n",
    "            data_copy[i, indices[i]] = train_mean[indices[i]]\n",
    "    print(\"Remove sum: \", sum)\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_models = {\"RF_Regressor\": rf,\n",
    "                    \"Linear\": LinearRegression(),\n",
    "                    \"RF_Plus_Regressor\": rf_plus_base}\n",
    "X_data = X_test\n",
    "y_data = y_test\n",
    "ablation_data=\"test\"\n",
    "ablation_models[\"Linear\"].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether sum to hat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(rf.predict(X_test)) == np.all(np.sum(shap_values_test, axis=1) + explainer.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get localMDI+\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "local_feature_importances_train, a = rf_plus_mdi.explain(X=X_train, y=y_train)\n",
    "local_feature_importances_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf), include_raw=False, fit_on=\"inbag\", prediction_model=Ridge(alpha=1e-6))\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base, evaluate_on=\"inbag\")\n",
    "local_feature_importances_train, _ = rf_plus_mdi.explain(X=X_train, y=y_train)\n",
    "local_feature_importances_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMDI+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data =local_feature_importances_train\n",
    "local_fi_score_data_rank = np.argsort(local_feature_importances_train)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data =local_feature_importances_train\n",
    "local_fi_score_data_rank = np.argsort(-1*local_feature_importances_train)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(local_feature_importances_train))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*local_feature_importances_train)#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*np.random.rand(X_train.shape[0], 10))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_before = metric_results['Linear_train_MSE_before_ablation']\n",
    "r2_before = metric_results['Linear_train_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'Linear_train_MSE_after_ablation_{i}'] for i in range(1, 10)]\n",
    "r2_after = [metric_results[f'Linear_train_R_2_after_ablation_{i}'] for i in range(1, 10)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*shap_values_train)#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_before = metric_results['Linear_train_MSE_before_ablation']\n",
    "r2_before = metric_results['Linear_train_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'Linear_train_MSE_after_ablation_{i}'] for i in range(1, 10)]\n",
    "r2_after = [metric_results[f'Linear_train_R_2_after_ablation_{i}'] for i in range(1, 10)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "var = []\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    # print(differences_per_col)\n",
    "    # print(np.array(differences_per_col).var())\n",
    "    var.append(np.array(differences_per_col).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_results_list_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = X_temp != X_train\n",
    "differences_per_row = np.sum(differences, axis=1)\n",
    "print(differences_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = X_temp != X_train\n",
    "differences_per_col = np.sum(differences, axis=0)\n",
    "print(differences_per_col)\n",
    "print(np.array(differences_per_col).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - y_train.mean())**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - ablation_est.predict(X_train))**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - ablation_est.predict(X_temp))**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_temp, y_train)\n",
    "r2_score(y_train, lm.predict(X_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_-ablation_est.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
