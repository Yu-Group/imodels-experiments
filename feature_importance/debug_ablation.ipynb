{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imodels\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from imodels.tree.rf_plus.rf_plus.rf_plus_models import RandomForestPlusRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score, mean_squared_error, r2_score\n",
    "from imodels.tree.rf_plus.feature_importance.rfplus_explainer import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import openml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetching diabetes from sklearn\n"
     ]
    }
   ],
   "source": [
    "X, y, _ = imodels.get_clean_dataset(\"diabetes_regr\")\n",
    "# X = np.delete(X, 4,1)\n",
    "# dataset = openml.datasets.get_dataset(588)\n",
    "# X, y, _, _ = dataset.get_data(target=dataset.default_target_attribute, dataset_format=\"array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42) \n",
    "# data = np.random.randn(1000, 10)\n",
    "# n_groups = 2\n",
    "# group_indicator = np.random.choice(n_groups, size=1000)\n",
    "# y = np.zeros(1000)\n",
    "# coefficients = np.random.randn(n_groups, data.shape[1])\n",
    "# for group in range(n_groups):\n",
    "#     group_mask = group_indicator == group\n",
    "#     selected_features = data[group_mask]\n",
    "#     y[group_mask] = np.dot(selected_features, coefficients[group])\n",
    "# X = np.column_stack((data, group_indicator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.173737</td>\n",
       "      <td>0.185085</td>\n",
       "      <td>0.335428</td>\n",
       "      <td>0.260061</td>\n",
       "      <td>0.219243</td>\n",
       "      <td>-0.075181</td>\n",
       "      <td>0.203841</td>\n",
       "      <td>0.270774</td>\n",
       "      <td>0.301731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.173737</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>0.241010</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>-0.379090</td>\n",
       "      <td>0.332115</td>\n",
       "      <td>0.149916</td>\n",
       "      <td>0.208133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185085</td>\n",
       "      <td>0.088161</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.395411</td>\n",
       "      <td>0.249777</td>\n",
       "      <td>0.261170</td>\n",
       "      <td>-0.366811</td>\n",
       "      <td>0.413807</td>\n",
       "      <td>0.446157</td>\n",
       "      <td>0.388680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.335428</td>\n",
       "      <td>0.241010</td>\n",
       "      <td>0.395411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.242464</td>\n",
       "      <td>0.185548</td>\n",
       "      <td>-0.178762</td>\n",
       "      <td>0.257650</td>\n",
       "      <td>0.393480</td>\n",
       "      <td>0.390430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.260061</td>\n",
       "      <td>0.035277</td>\n",
       "      <td>0.249777</td>\n",
       "      <td>0.242464</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.896663</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>0.542207</td>\n",
       "      <td>0.515503</td>\n",
       "      <td>0.325717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.219243</td>\n",
       "      <td>0.142637</td>\n",
       "      <td>0.261170</td>\n",
       "      <td>0.185548</td>\n",
       "      <td>0.896663</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196455</td>\n",
       "      <td>0.659817</td>\n",
       "      <td>0.318357</td>\n",
       "      <td>0.290600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.075181</td>\n",
       "      <td>-0.379090</td>\n",
       "      <td>-0.366811</td>\n",
       "      <td>-0.178762</td>\n",
       "      <td>0.051519</td>\n",
       "      <td>-0.196455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.738493</td>\n",
       "      <td>-0.398577</td>\n",
       "      <td>-0.273697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.203841</td>\n",
       "      <td>0.332115</td>\n",
       "      <td>0.413807</td>\n",
       "      <td>0.257650</td>\n",
       "      <td>0.542207</td>\n",
       "      <td>0.659817</td>\n",
       "      <td>-0.738493</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>0.417212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.270774</td>\n",
       "      <td>0.149916</td>\n",
       "      <td>0.446157</td>\n",
       "      <td>0.393480</td>\n",
       "      <td>0.515503</td>\n",
       "      <td>0.318357</td>\n",
       "      <td>-0.398577</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.464669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.301731</td>\n",
       "      <td>0.208133</td>\n",
       "      <td>0.388680</td>\n",
       "      <td>0.390430</td>\n",
       "      <td>0.325717</td>\n",
       "      <td>0.290600</td>\n",
       "      <td>-0.273697</td>\n",
       "      <td>0.417212</td>\n",
       "      <td>0.464669</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6  \\\n",
       "0  1.000000  0.173737  0.185085  0.335428  0.260061  0.219243 -0.075181   \n",
       "1  0.173737  1.000000  0.088161  0.241010  0.035277  0.142637 -0.379090   \n",
       "2  0.185085  0.088161  1.000000  0.395411  0.249777  0.261170 -0.366811   \n",
       "3  0.335428  0.241010  0.395411  1.000000  0.242464  0.185548 -0.178762   \n",
       "4  0.260061  0.035277  0.249777  0.242464  1.000000  0.896663  0.051519   \n",
       "5  0.219243  0.142637  0.261170  0.185548  0.896663  1.000000 -0.196455   \n",
       "6 -0.075181 -0.379090 -0.366811 -0.178762  0.051519 -0.196455  1.000000   \n",
       "7  0.203841  0.332115  0.413807  0.257650  0.542207  0.659817 -0.738493   \n",
       "8  0.270774  0.149916  0.446157  0.393480  0.515503  0.318357 -0.398577   \n",
       "9  0.301731  0.208133  0.388680  0.390430  0.325717  0.290600 -0.273697   \n",
       "\n",
       "          7         8         9  \n",
       "0  0.203841  0.270774  0.301731  \n",
       "1  0.332115  0.149916  0.208133  \n",
       "2  0.413807  0.446157  0.388680  \n",
       "3  0.257650  0.393480  0.390430  \n",
       "4  0.542207  0.515503  0.325717  \n",
       "5  0.659817  0.318357  0.290600  \n",
       "6 -0.738493 -0.398577 -0.273697  \n",
       "7  1.000000  0.617859  0.417212  \n",
       "8  0.617859  1.000000  0.464669  \n",
       "9  0.417212  0.464669  1.000000  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1.,  8., 10., 17., 14., 17., 18., 11., 20., 18., 18.,  9.,\n",
       "        13., 10.,  9., 15., 11., 15., 12.,  6.,  9., 10., 13., 12.,  7.,\n",
       "         9., 12.,  5.,  8.,  8.,  5.,  8.,  8.,  9.,  4., 11.,  8., 10.,\n",
       "         9.,  3.,  3.,  3.,  3.,  5.,  1.,  1.,  1.,  1.,  2.]),\n",
       " array([ 25.  ,  31.42,  37.84,  44.26,  50.68,  57.1 ,  63.52,  69.94,\n",
       "         76.36,  82.78,  89.2 ,  95.62, 102.04, 108.46, 114.88, 121.3 ,\n",
       "        127.72, 134.14, 140.56, 146.98, 153.4 , 159.82, 166.24, 172.66,\n",
       "        179.08, 185.5 , 191.92, 198.34, 204.76, 211.18, 217.6 , 224.02,\n",
       "        230.44, 236.86, 243.28, 249.7 , 256.12, 262.54, 268.96, 275.38,\n",
       "        281.8 , 288.22, 294.64, 301.06, 307.48, 313.9 , 320.32, 326.74,\n",
       "        333.16, 339.58, 346.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot y\n",
    "plt.hist(y, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply the log transformation to y\n",
    "# y = np.log(y)\n",
    "# plt.hist(y, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(296, 10) (146, 10)\n"
     ]
    }
   ],
   "source": [
    "# X, y, _ = imodels.get_clean_dataset(\"diabetes_regr\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "print(X_train.shape, X_test.shape)\n",
    "# standardize the data using sklearn's StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# X_train = scaler.fit_transform(X_train)\n",
    "# X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27233.158339294056\n",
      "-4.437746325057651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.kernel_ridge import KernelRidge\n",
    "est = KernelRidge()\n",
    "est.fit(X_train, y_train)\n",
    "y_pred = est.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n",
      "/accounts/projects/binyu/zhongyuan_liang/.local/lib/python3.10/site-packages/sklearn/linear_model/_ridge.py:243: UserWarning: Singular matrix in solving dual problem. Using least-squares solution instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2892.2187159889345\n",
      "0.42249989890304185\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'gamma': [0.1, 0.01, 0.001, None]\n",
    "}\n",
    "grid_search = GridSearchCV(KernelRidge(), param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_est = grid_search.best_estimator_\n",
    "y_pred = best_est.predict(X_test)\n",
    "print(mean_squared_error(y_test, y_pred))\n",
    "print(r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  18 tasks      | elapsed:    5.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.7s finished\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, min_samples_leaf= 3, max_features= 'sqrt', random_state= 42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusClassifier(rf_model=rf)\n",
    "rf_plus_base.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'AloMDIPlusPartialPredictionModelClassifier' object has no attribute 'predict_partial_k_subtract_intercept'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m rf_plus_mdi \u001b[39m=\u001b[39m AloRFPlusMDI(rf_plus_base, evaluate_on\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m partial_preds_subtract_intercept \u001b[39m=\u001b[39m rf_plus_mdi\u001b[39m.\u001b[39;49mexplain_subtract_intercept(X\u001b[39m=\u001b[39;49mX_test)\n",
      "File \u001b[0;32m~/local_MDI+/imodels/imodels/tree/rf_plus/feature_importance/rfplus_explainer.py:282\u001b[0m, in \u001b[0;36mAloRFPlusMDI.explain_subtract_intercept\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    281\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mexplain_subtract_intercept\u001b[39m(\u001b[39mself\u001b[39m, X,y \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 282\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mexplain_subtract_intercept(X,y)\n",
      "File \u001b[0;32m~/local_MDI+/imodels/imodels/tree/rf_plus/feature_importance/rfplus_explainer.py:214\u001b[0m, in \u001b[0;36mRFPlusMDI.explain_subtract_intercept\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    211\u001b[0m local_feature_importances[local_feature_importances \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m    213\u001b[0m \u001b[39m# all_tree_LFI_scores has shape X.shape[0], X.shape[1], num_trees \u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m all_tree_LFI_scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_LFI_subtract_intercept(X,y)\n\u001b[1;32m    216\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    217\u001b[0m     evaluate_on \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/local_MDI+/imodels/imodels/tree/rf_plus/feature_importance/rfplus_explainer.py:305\u001b[0m, in \u001b[0;36mAloRFPlusMDI._get_LFI_subtract_intercept\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    303\u001b[0m blocked_data_ith_tree \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrf_plus_model\u001b[39m.\u001b[39mtransformers_[i]\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m    304\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 305\u001b[0m     ith_partial_preds \u001b[39m=\u001b[39m tree_explainer\u001b[39m.\u001b[39;49mpredict_partial_subtract_intercept(blocked_data_ith_tree, mode\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n\u001b[1;32m    306\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     ith_partial_preds \u001b[39m=\u001b[39m tree_explainer\u001b[39m.\u001b[39mpredict_partial_loo_subtract_intercept(blocked_data_ith_tree, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode)\n",
      "File \u001b[0;32m~/local_MDI+/imodels/imodels/tree/rf_plus/feature_importance/ppms/ppms.py:130\u001b[0m, in \u001b[0;36m_MDIPlusGenericPPM.predict_partial_subtract_intercept\u001b[0;34m(self, blocked_data, mode, zero_values)\u001b[0m\n\u001b[1;32m    128\u001b[0m         partial_preds[k] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredict_partial_k_subtract_intercept(blocked_data, k, mode, zero_value\u001b[39m=\u001b[39mzero_values[k])\n\u001b[1;32m    129\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 130\u001b[0m         partial_preds[k] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_partial_k_subtract_intercept(blocked_data, k, mode)\n\u001b[1;32m    131\u001b[0m \u001b[39mreturn\u001b[39;00m partial_preds\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'AloMDIPlusPartialPredictionModelClassifier' object has no attribute 'predict_partial_k_subtract_intercept'"
     ]
    }
   ],
   "source": [
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "partial_preds_subtract_intercept = rf_plus_mdi.explain_subtract_intercept(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_preds_subtract_intercept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_preds_subtract_intercept[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_plus_base.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = rf_plus_mdi.explain(X=X_test, y=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(n_estimators=100, random_state=41, min_samples_leaf=5, max_features=0.33)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf))\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "test_all_mse_rf = mean_squared_error(y_test, rf.predict(X_test))\n",
    "test_all_r2_rf = r2_score(y_test, rf.predict(X_test))\n",
    "test_all_mse_rf_plus = mean_squared_error(y_test, rf_plus_base.predict(X_test))\n",
    "test_all_r2_rf_plus = r2_score(y_test, rf_plus_base.predict(X_test))\n",
    "print(\"Test MSE RF: \", test_all_mse_rf)\n",
    "print(\"Test R2 RF: \", test_all_r2_rf)\n",
    "print(\"Test MSE RF+: \", test_all_mse_rf_plus)\n",
    "print(\"Test R2 RF+: \", test_all_r2_rf_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shap values\n",
    "import shap\n",
    "explainer = shap.TreeExplainer(rf)\n",
    "shap_values_train = explainer.shap_values(X_train, check_additivity=True)\n",
    "# shap_values_train = np.abs(shap_values_train)\n",
    "shap_values_test = explainer.shap_values(X_test, check_additivity=True)\n",
    "# shap_values_test = np.abs(shap_values_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ablation_removal(train_mean, data, feature_importance_rank, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    data_copy[np.arange(data.shape[0]), indices] = train_mean[indices]\n",
    "    return data_copy\n",
    "def ablation_removal_positive(train_mean, data, feature_importance_rank, feature_importance, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    sum = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        if feature_importance[i, indices[i]] > 0:\n",
    "            sum += 1\n",
    "            data_copy[i, indices[i]] = train_mean[indices[i]]\n",
    "    print(\"Remove sum: \", sum)\n",
    "    return data_copy\n",
    "def ablation_removal_negative(train_mean, data, feature_importance_rank, feature_importance, feature_index):\n",
    "    data_copy = data.copy()\n",
    "    indices = feature_importance_rank[:, feature_index]\n",
    "    sum = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        if feature_importance[i, indices[i]] < 0:\n",
    "            sum += 1\n",
    "            data_copy[i, indices[i]] = train_mean[indices[i]]\n",
    "    print(\"Remove sum: \", sum)\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_models = {\"RF_Regressor\": rf,\n",
    "                    \"Linear\": LinearRegression(),\n",
    "                    \"RF_Plus_Regressor\": rf_plus_base}\n",
    "X_data = X_test\n",
    "y_data = y_test\n",
    "ablation_data=\"test\"\n",
    "ablation_models[\"Linear\"].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    print(f\"enter i: {i}\")\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data =shap_values_test\n",
    "local_fi_score_data_rank = np.argsort(-1*shap_values_test)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"RF_Plus_Regressor\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(shap_values_test))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check whether sum to hat_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(rf.predict(X_test)) == np.all(np.sum(shap_values_test, axis=1) + explainer.expected_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer.expected_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get localMDI+\n",
    "rf_plus_mdi = AloRFPlusMDI(rf_plus_base, evaluate_on=\"all\")\n",
    "local_feature_importances_train, a = rf_plus_mdi.explain(X=X_train, y=y_train)\n",
    "local_feature_importances_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "rf_plus_base = RandomForestPlusRegressor(rf_model=copy.deepcopy(rf), include_raw=False, fit_on=\"inbag\", prediction_model=Ridge(alpha=1e-6))\n",
    "rf_plus_base.fit(X_train, y_train)\n",
    "rf_plus_mdi = RFPlusMDI(rf_plus_base, evaluate_on=\"inbag\")\n",
    "local_feature_importances_train, _ = rf_plus_mdi.explain(X=X_train, y=y_train)\n",
    "local_feature_importances_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMDI+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data =local_feature_importances_train\n",
    "local_fi_score_data_rank = np.argsort(local_feature_importances_train)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_negative(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data =local_feature_importances_train\n",
    "local_fi_score_data_rank = np.argsort(-1*local_feature_importances_train)\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, local_fi_score_data_rank, local_fi_score_data, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_model = \"Linear\"\n",
    "ablation_est = ablation_models[a_model]\n",
    "X_data = X_train\n",
    "y_data = y_train\n",
    "ablation_data=\"test\"\n",
    "metric_results = {}\n",
    "local_fi_score_data_rank = np.argsort(-1*np.abs(local_feature_importances_train))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "num_ablate_features = X_train.shape[1]\n",
    "train_mean = np.mean(X_train, axis=0)\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal(train_mean, X_temp, local_fi_score_data_rank, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]\n",
    "\n",
    "mse_before = metric_results[a_model + f'_{ablation_data}_MSE_before_ablation']\n",
    "r2_before = metric_results[a_model + f'_{ablation_data}_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "r2_after = [metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i}'] for i in range(1, num_ablate_features)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*local_feature_importances_train)#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*np.random.rand(X_train.shape[0], 10))#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_before = metric_results['Linear_train_MSE_before_ablation']\n",
    "r2_before = metric_results['Linear_train_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'Linear_train_MSE_after_ablation_{i}'] for i in range(1, 10)]\n",
    "r2_after = [metric_results[f'Linear_train_R_2_after_ablation_{i}'] for i in range(1, 10)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_fi_score_data = np.argsort(-1*shap_values_train)#np.argsort(-1*local_feature_importances_train) #np.argsort(-1*shap_values_train) #np.argsort(-1*np.random.rand(X_train.shape[0], 10))\n",
    "\n",
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    print(differences_per_col)\n",
    "    lm = LinearRegression()\n",
    "    lm.fit(X_temp, y_train)\n",
    "    print(r2_score(y_train, lm.predict(X_temp)))\n",
    "for i in range(num_ablate_features):\n",
    "    metric_results[f'{a_model}_{ablation_data}_MSE_after_ablation_{i+1}'] = ablation_results_list[i]\n",
    "    metric_results[f'{a_model}_{ablation_data}_R_2_after_ablation_{i+1}'] = ablation_results_list_r2[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_before = metric_results['Linear_train_MSE_before_ablation']\n",
    "r2_before = metric_results['Linear_train_R_2_before_ablation']\n",
    "\n",
    "mse_after = [metric_results[f'Linear_train_MSE_after_ablation_{i}'] for i in range(1, 10)]\n",
    "r2_after = [metric_results[f'Linear_train_R_2_after_ablation_{i}'] for i in range(1, 10)]\n",
    "\n",
    "# Plotting MSE\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, 10)], [mse_before] + mse_after, color='tab:red', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('MSE')\n",
    "plt.title(f'{a_model} MSE Before and After Ablation')\n",
    "plt.show()\n",
    "\n",
    "# Plotting R^2\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(['Before'] + [f'After {i}' for i in range(1, num_ablate_features)], [r2_before] + r2_after, color='tab:blue', marker='o')\n",
    "plt.xlabel('Ablation Step')\n",
    "plt.ylabel('R^2')\n",
    "plt.title(f'{a_model} R^2 Before and After Ablation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ablation_est.predict(X_data)\n",
    "metric_results[a_model + f'_{ablation_data}_MSE_before_ablation'] = mean_squared_error(y_data, y_pred)\n",
    "metric_results[a_model + f'_{ablation_data}_R_2_before_ablation'] = r2_score(y_data, y_pred)\n",
    "imp_vals = copy.deepcopy(local_fi_score_data)\n",
    "ablation_results_list = [0] * num_ablate_features\n",
    "ablation_results_list_r2 = [0] * num_ablate_features\n",
    "X_temp = X_data.copy()\n",
    "var = []\n",
    "for i in range(num_ablate_features):\n",
    "    ablation_X_data = ablation_removal_positive(train_mean, X_temp, imp_vals, i)\n",
    "    ablation_results_list[i] = mean_squared_error(y_data, ablation_est.predict(ablation_X_data))\n",
    "    ablation_results_list_r2[i] = r2_score(y_data, ablation_est.predict(ablation_X_data))\n",
    "    X_temp = ablation_X_data\n",
    "    differences = X_temp != X_train\n",
    "    differences_per_col = np.sum(differences, axis=0)\n",
    "    # print(differences_per_col)\n",
    "    # print(np.array(differences_per_col).var())\n",
    "    var.append(np.array(differences_per_col).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_results_list_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = X_temp != X_train\n",
    "differences_per_row = np.sum(differences, axis=1)\n",
    "print(differences_per_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = X_temp != X_train\n",
    "differences_per_col = np.sum(differences, axis=0)\n",
    "print(differences_per_col)\n",
    "print(np.array(differences_per_col).var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - y_train.mean())**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - ablation_est.predict(X_train))**2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((y_train - ablation_est.predict(X_temp))**2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LinearRegression()\n",
    "lm.fit(X_temp, y_train)\n",
    "r2_score(y_train, lm.predict(X_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ablation_est.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm.coef_-ablation_est.coef_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
